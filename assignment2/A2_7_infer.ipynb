{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b16f877d-0d29-4147-9972-dd70462356d4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b439a3c"
      },
      "outputs": [],
      "source": [
        "with open(r'data/ATE_Test.json', 'r') as f:\n",
        "    ATE_test_data = json.load(f)\n",
        "with open(r'data/NER_Test.json', 'r') as f:\n",
        "    NER_test_data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "739b1baf"
      },
      "source": [
        "## word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bff4090a-d0ce-4fd1-a8ea-e69d512c93b7",
        "outputId": "8b9eb307-6c78-45fa-aae8-1ff1df9c41ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4765/2692264229.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845868/work/torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  input_ids = torch.tensor(padded_embeddings)\n"
          ]
        }
      ],
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "def convert_data_to_tensors_word2vec(data, word_vectors):\n",
        "    texts = [data[key]['text'] for key in data]\n",
        "\n",
        "    # Convert texts to word embeddings\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        embedding = []\n",
        "        for word in text.split():\n",
        "            if word in word_vectors:\n",
        "                embedding.append(word_vectors[word])\n",
        "            else:\n",
        "                embedding.append([0] * len(word_vectors['hello']))  # Use a zero vector for unknown words\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    # Pad sequences to have the same length\n",
        "    max_len = 83 # maximum length of word in 1 text\n",
        "    padded_embeddings = []\n",
        "    for embedding in embeddings:\n",
        "        padded_embedding = embedding + [[0] * len(word_vectors['hello'])] * (max_len - len(embedding))\n",
        "        padded_embeddings.append(padded_embedding)\n",
        "\n",
        "    input_ids = torch.tensor(padded_embeddings)\n",
        "\n",
        "    return input_ids\n",
        "x_test_ATE_word2vec = convert_data_to_tensors_word2vec(ATE_test_data, word_vectors)\n",
        "x_test_NER_word2vec = convert_data_to_tensors_word2vec(NER_test_data, word_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bae2f0c"
      },
      "source": [
        "## Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8bcc6ae-0f9c-4195-a9fd-8e846278ab6e",
        "outputId": "238f6cfb-df2d-4046-9b24-c77baa738fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "400000 words loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_glove_model(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    glove_model = {}\n",
        "    with open(File,'r') as f:\n",
        "        for line in f:\n",
        "            split_line = line.split()\n",
        "            word = split_line[0]\n",
        "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
        "            glove_model[word] = embedding\n",
        "    print(f\"{len(glove_model)} words loaded!\")\n",
        "    return glove_model\n",
        "\n",
        "# Path to your GloVe pre-trained embeddings file\n",
        "glove_file_path = 'glove.6B.300d.txt'\n",
        "\n",
        "# Load GloVe embeddings\n",
        "model_glove = load_glove_model(glove_file_path)\n",
        "\n",
        "def convert_data_to_tensors_glove(data, model):\n",
        "    texts = [data[key]['text'] for key in data]\n",
        "\n",
        "    # Convert texts to word embeddings\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        embedding = []\n",
        "        for word in text.split():\n",
        "            # Check if word exists in the model's vocabulary\n",
        "            if word in model:\n",
        "                embedding.append(model[word])\n",
        "            else:\n",
        "                # If word not found, use zero vector\n",
        "                embedding.append([0] * model[\"hello\"].size)\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    # Pad sequences to have the same length\n",
        "    max_len = 83  # maximum length of word in a text\n",
        "    padded_embeddings = []\n",
        "    for embedding in embeddings:\n",
        "        padded_embedding = embedding + [[0] * model[\"hello\"].size] * (max_len - len(embedding))\n",
        "        padded_embeddings.append(padded_embedding)\n",
        "\n",
        "    # Filter out None values\n",
        "    padded_embeddings = [embedding for embedding in padded_embeddings if embedding is not None]\n",
        "\n",
        "    # Convert to tensor\n",
        "    input_ids = torch.tensor(padded_embeddings, dtype=torch.float32)\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "x_test_ATE_glove = convert_data_to_tensors_glove(ATE_test_data, model_glove)\n",
        "x_test_NER_glove = convert_data_to_tensors_glove(NER_test_data, model_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ba54d12"
      },
      "source": [
        "## Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77a94a3d",
        "outputId": "5c0af938-72a9-4aea-b9bd-bb2ada8a22c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "model_fasttext = fasttext.load_model(\"cc.en.300.bin\")\n",
        "def convert_data_to_tensors_fasttext(data, model):\n",
        "    texts = [data[key]['text'] for key in data]\n",
        "\n",
        "    # Convert texts to word embeddings\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        embedding = []\n",
        "        for word in text.split():\n",
        "                embedding.append(model.get_word_vector(word))\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    # Pad sequences to have the same length\n",
        "    max_len = 83 # maximum length of word in 1 text\n",
        "    padded_embeddings = []\n",
        "    for embedding in embeddings:\n",
        "        padded_embedding = embedding + [[0] * len(model.get_word_vector(\"Hello\"))] * (max_len - len(embedding))\n",
        "        padded_embeddings.append(padded_embedding)\n",
        "\n",
        "    input_ids = torch.tensor(padded_embeddings)\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "x_test_ATE_fasttext = convert_data_to_tensors_fasttext(ATE_test_data, model_fasttext)\n",
        "x_test_NER_fasttext = convert_data_to_tensors_fasttext(NER_test_data, model_fasttext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7a1a1be"
      },
      "source": [
        "## label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82118b89"
      },
      "outputs": [],
      "source": [
        "def convert_labels_to_fixed_length_ATE(labels, max_length):\n",
        "    new_list=[]\n",
        "    label_to_index_t2 = {'B': 0, 'I': 1, 'O': 2,'<pad>':3}\n",
        "    fixed_length_labels = np.zeros((len(labels), max_length))\n",
        "    for i, example_labels in enumerate(labels):\n",
        "        for j, label in enumerate(example_labels[:max_length]):\n",
        "            fixed_length_labels[i, j] = label_to_index_t2[label]\n",
        "        for k in range(len(example_labels[:max_length]),max_length):\n",
        "            fixed_length_labels[i, k] = 3\n",
        "        new_list.append(len(example_labels[:max_length]))\n",
        "    return fixed_length_labels,new_list\n",
        "\n",
        "def convert_labels_to_fixed_length_NER(labels, max_length):\n",
        "    new_list=[]\n",
        "    label_to_index_t1 = {'I_WITNESS': 0, 'B_JUDGE': 1, 'I_CASE_NUMBER': 2, 'B_CASE_NUMBER': 3, 'I_PROVISION': 4, 'B_STATUTE': 5, 'I_DATE': 6, 'I_STATUTE': 7, 'B_WITNESS': 8, 'B_DATE': 9, 'I_RESPONDENT': 10, 'B_PRECEDENT': 11, 'B_GPE': 12, 'I_ORG': 13, 'I_PETITIONER': 14, 'B_PROVISION': 15, 'B_ORG': 16, 'I_JUDGE': 17, 'I_OTHER_PERSON': 18, 'B_COURT': 19, 'B_PETITIONER': 20, 'B_RESPONDENT': 21, 'I_PRECEDENT': 22, 'I_COURT': 23, 'I_GPE': 24, 'B_OTHER_PERSON': 25, 'O': 26, '<pad>':27}\n",
        "    fixed_length_labels = np.zeros((len(labels), max_length))\n",
        "    for i, example_labels in enumerate(labels):\n",
        "        for j, label in enumerate(example_labels[:max_length]):\n",
        "            fixed_length_labels[i, j] = label_to_index_t1[label]\n",
        "        for k in range(len(example_labels[:max_length]),max_length):\n",
        "            fixed_length_labels[i, k] = 27\n",
        "        new_list.append(len(example_labels[:max_length]))\n",
        "    return fixed_length_labels,new_list\n",
        "\n",
        "max_length_ATE = 83\n",
        "test_labels_ATE = [ATE_test_data[key]['labels'] for key in ATE_test_data]\n",
        "test_lab_ATE,length_test_ATE = convert_labels_to_fixed_length_ATE(test_labels_ATE, max_length_ATE)\n",
        "y_test_ATE = torch.tensor(test_lab_ATE)\n",
        "\n",
        "max_length_NER = 70\n",
        "test_labels_NER = [NER_test_data[key]['labels'] for key in NER_test_data]\n",
        "test_lab_NER,length_test_NER = convert_labels_to_fixed_length_NER(test_labels_NER, max_length_NER)\n",
        "y_test_NER = torch.tensor(test_lab_NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b597ef2",
        "outputId": "e35b0b2b-ad63-41ba-9eb7-5bce209fd3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b69977c2",
        "outputId": "ce569390-ddb6-4c55-896b-e3e39addd139"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4765/4135077071.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_ATE_word2vec_tensor = torch.tensor(x_test_ATE_word2vec, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_ATE_glove_tensor = torch.tensor(x_test_ATE_glove, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_ATE_fasttext_tensor = torch.tensor(x_test_ATE_fasttext, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_NER_word2vec_tensor = torch.tensor(x_test_NER_word2vec, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_NER_glove_tensor = torch.tensor(x_test_NER_glove, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_NER_fasttext_tensor = torch.tensor(x_test_NER_fasttext, dtype=torch.float32)\n",
            "/tmp/ipykernel_4765/4135077071.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_ATE_tensor = torch.tensor(y_test_ATE, dtype=torch.long)\n",
            "/tmp/ipykernel_4765/4135077071.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_NER_tensor = torch.tensor(y_test_NER, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "x_test_ATE_word2vec_tensor = torch.tensor(x_test_ATE_word2vec, dtype=torch.float32)\n",
        "x_test_ATE_glove_tensor = torch.tensor(x_test_ATE_glove, dtype=torch.float32)\n",
        "x_test_ATE_fasttext_tensor = torch.tensor(x_test_ATE_fasttext, dtype=torch.float32)\n",
        "\n",
        "x_test_NER_word2vec_tensor = torch.tensor(x_test_NER_word2vec, dtype=torch.float32)\n",
        "x_test_NER_glove_tensor = torch.tensor(x_test_NER_glove, dtype=torch.float32)\n",
        "x_test_NER_fasttext_tensor = torch.tensor(x_test_NER_fasttext, dtype=torch.float32)\n",
        "\n",
        "y_test_ATE_tensor = torch.tensor(y_test_ATE, dtype=torch.long)\n",
        "y_test_NER_tensor = torch.tensor(y_test_NER, dtype=torch.long)\n",
        "\n",
        "length_test_ATE_tensor = torch.tensor(length_test_ATE)\n",
        "length_test_NER_tensor = torch.tensor(length_test_NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "d8BvDEevtm1F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa651052"
      },
      "outputs": [],
      "source": [
        "# Define the RNN model\n",
        "class RNNTagger(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNTagger, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "#define the LSTM model\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0,c0))\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "#define the GRU model\n",
        "class GRUTagger(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRUTagger, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.gru.hidden_size).to(x.device)\n",
        "        out, _ = self.gru(x, h0)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = 300\n",
        "hidden_size = 128\n",
        "output_size_ATE = 4\n",
        "output_size_NER = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16ff687c",
        "outputId": "e842fdee-471a-4d9d-9a74-49d7fc14df24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_t1_model1_word2vec = RNNTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model1_word2vec.load_state_dict(torch.load(\"t1_model1_word2vec.pth\"))\n",
        "model_t2_model1_word2vec = RNNTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model1_word2vec.load_state_dict(torch.load(\"t2_model1_word2vec.pth\"))\n",
        "model_t1_model1_glove = RNNTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model1_glove.load_state_dict(torch.load(\"t1_model1_glove.pth\"))\n",
        "model_t2_model1_glove = RNNTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model1_glove.load_state_dict(torch.load(\"t2_model1_glove.pth\"))\n",
        "model_t1_model1_fasttext = RNNTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model1_fasttext.load_state_dict(torch.load(\"t1_model1_fasttext.pth\"))\n",
        "model_t2_model1_fasttext = RNNTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model1_fasttext.load_state_dict(torch.load(\"t2_model1_fasttext.pth\"))\n",
        "\n",
        "model_t1_model2_word2vec = LSTMTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model2_word2vec.load_state_dict(torch.load(\"t1_model2_word2vec.pth\"))\n",
        "model_t2_model2_word2vec = LSTMTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model2_word2vec.load_state_dict(torch.load(\"t2_model2_word2vec.pth\"))\n",
        "model_t1_model2_glove = LSTMTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model2_glove.load_state_dict(torch.load(\"t1_model2_glove.pth\"))\n",
        "model_t2_model2_glove = LSTMTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model2_glove.load_state_dict(torch.load(\"t2_model2_glove.pth\"))\n",
        "model_t1_model2_fasttext = LSTMTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model2_fasttext.load_state_dict(torch.load(\"t1_model2_fasttext.pth\"))\n",
        "model_t2_model2_fasttext = LSTMTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model2_fasttext.load_state_dict(torch.load(\"t2_model2_fasttext.pth\"))\n",
        "\n",
        "model_t1_model3_word2vec = GRUTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model3_word2vec.load_state_dict(torch.load(\"t1_model3_word2vec.pth\"))\n",
        "model_t2_model3_word2vec = GRUTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model3_word2vec.load_state_dict(torch.load(\"t2_model3_word2vec.pth\"))\n",
        "model_t1_model3_glove = GRUTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model3_glove.load_state_dict(torch.load(\"t1_model3_glove.pth\"))\n",
        "model_t2_model3_glove = GRUTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model3_glove.load_state_dict(torch.load(\"t2_model3_glove.pth\"))\n",
        "model_t1_model3_fasttext = GRUTagger(input_size, hidden_size, output_size_NER)\n",
        "model_t1_model3_fasttext.load_state_dict(torch.load(\"t1_model3_fasttext.pth\"))\n",
        "model_t2_model3_fasttext = GRUTagger(input_size, hidden_size, output_size_ATE)\n",
        "model_t2_model3_fasttext.load_state_dict(torch.load(\"t2_model3_fasttext.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "36Gt13_EtuWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "848c6cf8"
      },
      "outputs": [],
      "source": [
        "def eval_score(model,test_input,test_output,length_tensor,name):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        outputs = model(test_input)\n",
        "        predictions = torch.argmax(outputs, dim=2)\n",
        "\n",
        "        y_pred_padd = [row[:index] for row, index in zip(predictions, length_tensor)]\n",
        "        y_pred_flat = torch.cat(y_pred_padd)\n",
        "        y_padd_tensor =  [row[:index] for row, index in zip(test_output, length_tensor)]\n",
        "        y_labels_flat = torch.cat(y_padd_tensor)\n",
        "        f1 = f1_score(y_labels_flat, y_pred_flat, average='macro')\n",
        "        accuracy = accuracy_score(y_labels_flat, y_pred_flat)\n",
        "        print(f\"Name of model:-{name}, \\t f1 score: {f1},\\t accuracy score: {accuracy} \\n\" )\n",
        "#     return f1,accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef70252d",
        "outputId": "033c9334-0f91-4d47-ac57-c2d6a099c520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 1 NER\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset 1 NER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f702d51",
        "outputId": "b40e81b5-8f5a-4cb0-805f-5dd78ba8b3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of model:-t1_model1_word2vec, \t f1 score: 0.3558189079041109,\t accuracy score: 0.861878287002254 \n",
            "\n",
            "Name of model:-t1_model1_glove, \t f1 score: 0.23224886162702643,\t accuracy score: 0.8491960931630353 \n",
            "\n",
            "Name of model:-t1_model1_fasttext, \t f1 score: 0.4028700936231574,\t accuracy score: 0.8789181066867018 \n",
            "\n",
            "Name of model:-t1_model2_word2vec, \t f1 score: 0.3547655557172286,\t accuracy score: 0.8634410217881292 \n",
            "\n",
            "Name of model:-t1_model2_glove, \t f1 score: 0.2362976720430671,\t accuracy score: 0.8332381667918858 \n",
            "\n",
            "Name of model:-t1_model2_fasttext, \t f1 score: 0.3948665838914022,\t accuracy score: 0.8756423741547709 \n",
            "\n",
            "Name of model:-t1_model3_word2vec, \t f1 score: 0.32748062060098565,\t accuracy score: 0.8446882043576258 \n",
            "\n",
            "Name of model:-t1_model3_glove, \t f1 score: 0.21406890878378082,\t accuracy score: 0.8307738542449287 \n",
            "\n",
            "Name of model:-t1_model3_fasttext, \t f1 score: 0.3819970956544048,\t accuracy score: 0.8627798647633358 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_score(model_t1_model1_word2vec,x_test_NER_word2vec_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model1_word2vec\")\n",
        "eval_score(model_t1_model1_glove,x_test_NER_glove_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model1_glove\")\n",
        "eval_score(model_t1_model1_fasttext,x_test_NER_fasttext_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model1_fasttext\")\n",
        "\n",
        "eval_score(model_t1_model2_word2vec,x_test_NER_word2vec_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model2_word2vec\")\n",
        "eval_score(model_t1_model2_glove,x_test_NER_glove_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model2_glove\")\n",
        "eval_score(model_t1_model2_fasttext,x_test_NER_fasttext_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model2_fasttext\")\n",
        "\n",
        "eval_score(model_t1_model3_word2vec,x_test_NER_word2vec_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model3_word2vec\")\n",
        "eval_score(model_t1_model3_glove,x_test_NER_glove_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model3_glove\")\n",
        "eval_score(model_t1_model3_fasttext,x_test_NER_fasttext_tensor,y_test_NER_tensor,length_test_NER_tensor,\"t1_model3_fasttext\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c62e6fd",
        "outputId": "62d6d78e-2e0f-4827-c183-bfc4cca14aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 2 ATE\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset 2 ATE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3df1e0",
        "outputId": "b6278258-232a-4950-c760-f4955b43a9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of model:-t2_model1_word2vec, \t f1 score: 0.6999402532919099,\t accuracy score: 0.9062076967704505 \n",
            "\n",
            "Name of model:-t2_model1_glove, \t f1 score: 0.6017197129354663,\t accuracy score: 0.8849352156256043 \n",
            "\n",
            "Name of model:-t2_model1_fasttext, \t f1 score: 0.688587030489776,\t accuracy score: 0.9098820344227422 \n",
            "\n",
            "Name of model:-t2_model2_word2vec, \t f1 score: 0.709729054763831,\t accuracy score: 0.914910075420615 \n",
            "\n",
            "Name of model:-t2_model2_glove, \t f1 score: 0.6708463379432797,\t accuracy score: 0.9021465867337072 \n",
            "\n",
            "Name of model:-t2_model2_fasttext, \t f1 score: 0.7154978149353443,\t accuracy score: 0.9143299168439374 \n",
            "\n",
            "Name of model:-t2_model3_word2vec, \t f1 score: 0.7199227729549523,\t accuracy score: 0.9135563720750338 \n",
            "\n",
            "Name of model:-t2_model3_glove, \t f1 score: 0.6610621281734312,\t accuracy score: 0.9038870624637401 \n",
            "\n",
            "Name of model:-t2_model3_fasttext, \t f1 score: 0.7335586703984592,\t accuracy score: 0.9191645716495842 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_score(model_t2_model1_word2vec,x_test_ATE_word2vec_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model1_word2vec\")\n",
        "eval_score(model_t2_model1_glove,x_test_ATE_glove_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model1_glove\")\n",
        "eval_score(model_t2_model1_fasttext,x_test_ATE_fasttext_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model1_fasttext\")\n",
        "\n",
        "eval_score(model_t2_model2_word2vec,x_test_ATE_word2vec_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model2_word2vec\")\n",
        "eval_score(model_t2_model2_glove,x_test_ATE_glove_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model2_glove\")\n",
        "eval_score(model_t2_model2_fasttext,x_test_ATE_fasttext_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model2_fasttext\")\n",
        "\n",
        "eval_score(model_t2_model3_word2vec,x_test_ATE_word2vec_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model3_word2vec\")\n",
        "eval_score(model_t2_model3_glove,x_test_ATE_glove_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model3_glove\")\n",
        "eval_score(model_t2_model3_fasttext,x_test_ATE_fasttext_tensor,y_test_ATE_tensor,length_test_ATE_tensor,\"t2_model3_fasttext\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-model4-fasttext"
      ],
      "metadata": {
        "id": "4CBObkEYCE96"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRrg2TndBxo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        # for i in range(1, sent_len):\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "tag_to_ix ={'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext.util\n",
        "import json\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "            return FastText(language='en')\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}                               # bind it to self__________________________\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "model_state_dict = torch.load('t2_model4_fasttext.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'ATE_test.json'\n",
        "embedding_type = 'fasttext'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-model4-Glove"
      ],
      "metadata": {
        "id": "qQj8jEz7CLin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        # for i in range(1, sent_len):\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "tag_to_ix ={'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe\n",
        "# import fasttext\n",
        "import numpy as np\n",
        "# import fasttext.util\n",
        "import json\n",
        "\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "            ft = fasttext.load_model('cc.en.300.bin')\n",
        "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "            embeddings = [self.embedding_model[word]  for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}                               # bind it to self__________________________\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "model_state_dict = torch.load('t2_model4_glove.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'ATE_test.json'\n",
        "embedding_type = 'glove'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
      ],
      "metadata": {
        "id": "4sNlUnNcCO30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-model4-word2vec"
      ],
      "metadata": {
        "id": "Kcmj6KoQCYMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        # for i in range(1, sent_len):\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "tag_to_ix ={'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe\n",
        "# import fasttext\n",
        "import numpy as np\n",
        "# import fasttext.util\n",
        "import json\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "            ft = fasttext.load_model('cc.en.300.bin')\n",
        "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B': 1, 'I':2,'<START>':3,'<STOP>':4,'<PAD>':5}                               # bind it to self__________________________\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "model_state_dict = torch.load('t2_model4_word2vec.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'ATE_test.json'\n",
        "embedding_type = 'word2vec'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
      ],
      "metadata": {
        "id": "pOcClBr-CX5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#t1_model4_fasttext"
      ],
      "metadata": {
        "id": "h97_FGt4CgIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "\n",
        "            return FastText(language='en')\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "\n",
        "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        text,labels = preprocess_text(text,labels)\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "#         print(labels)\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "#         print(labels)\n",
        "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "#         print(numerical_labels)\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "import json\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text,label):\n",
        "    # Remove punctuation\n",
        "    text_no_punct = ''\n",
        "    for char in text:\n",
        "        if char not in string.punctuation:\n",
        "            text_no_punct += char\n",
        "\n",
        "    # Check if the text length is zero after removing punctuation\n",
        "    if len(text_no_punct.strip()) == 0:\n",
        "        return text\n",
        "\n",
        "    # Lowercase the text\n",
        "    text_lower = text_no_punct.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = text_lower.split()\n",
        "\n",
        "    text_no_stopwords = ''\n",
        "    labels =[]\n",
        "    for word in range(len(tokens)):\n",
        "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
        "            text_no_stopwords += tokens[word] + ' '\n",
        "            labels.append(label[word])\n",
        "\n",
        "    return text_no_stopwords.strip(),labels\n",
        "\n",
        "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model_state_dict = torch.load('t1_model4_fasttext.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'NER_test.json'\n",
        "embedding_type = 'fasttext'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n",
        "print(f1_score(traget_r, predictions_r, average=None))"
      ],
      "metadata": {
        "id": "mrvm_qIbCRGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#t1_model4_Glove"
      ],
      "metadata": {
        "id": "se-IUJrfCpzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "# import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe\n",
        "# import fasttext\n",
        "import numpy as np\n",
        "#import fasttext.util\n",
        "import json\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "            ft = fasttext.load_model('cc.en.300.bin')\n",
        "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "\n",
        "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        text,labels = preprocess_text(text,labels)\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "#         print(labels)\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "#         print(labels)\n",
        "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "#         print(numerical_labels)\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "import json\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text,label):\n",
        "    # Remove punctuation\n",
        "    text_no_punct = ''\n",
        "    for char in text:\n",
        "        if char not in string.punctuation:\n",
        "            text_no_punct += char\n",
        "\n",
        "    # Check if the text length is zero after removing punctuation\n",
        "    if len(text_no_punct.strip()) == 0:\n",
        "        return text\n",
        "\n",
        "    # Lowercase the text\n",
        "    text_lower = text_no_punct.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = text_lower.split()\n",
        "\n",
        "    text_no_stopwords = ''\n",
        "    labels =[]\n",
        "    for word in range(len(tokens)):\n",
        "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
        "            text_no_stopwords += tokens[word] + ' '\n",
        "            labels.append(label[word])\n",
        "\n",
        "    return text_no_stopwords.strip(),labels\n",
        "\n",
        "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model_state_dict = torch.load('t1_model4_glove.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'NER_test.json'\n",
        "embedding_type = 'glove'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n",
        "\n"
      ],
      "metadata": {
        "id": "vLMRNfzQCuGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#t1_model4_word2vec"
      ],
      "metadata": {
        "id": "FOWDUVouDI7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe,FastText\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "# import gensim.downloader as api\n",
        "from torchtext.vocab import GloVe\n",
        "# import fasttext\n",
        "import numpy as np\n",
        "#import fasttext.util\n",
        "import json\n",
        "class SentimentAnalysisDataset(Dataset):\n",
        "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
        "        with open(json_path, 'r') as file:\n",
        "            self.data = json.load(file)\n",
        "\n",
        "        self.embedding_type = embedding_type\n",
        "        if load:\n",
        "          self.embedding_model =self.load_embedding_model()\n",
        "        else:\n",
        "          self.embedding_model = None\n",
        "\n",
        "    def load_embedding_model(self):\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Download the pre-trained Word2Vec model\n",
        "            return api.load('word2vec-google-news-300')\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
        "            return GloVe(name='6B', dim=300)\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # Load the pre-trained FastText model\n",
        "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "            ft = fasttext.load_model('cc.en.300.bin')\n",
        "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "\n",
        "    def text_to_embeddings(self, text):\n",
        "        maxlen = 100\n",
        "        if self.embedding_type == 'word2vec':\n",
        "            # Word2Vec embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
        "\n",
        "\n",
        "        elif self.embedding_type == 'glove':\n",
        "            # GloVe embeddings\n",
        "\n",
        "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "\n",
        "        elif self.embedding_type == 'fasttext':\n",
        "            # FastText embeddings\n",
        "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
        "            # print(np.stack(embeddings).shape)\n",
        "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
        "\n",
        "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
        "\n",
        "            for i in range(100-len(embeddings)):\n",
        "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
        "        # print()\n",
        "        return np.stack(embeddings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        index = str(index)\n",
        "        text = self.data[index][\"text\"]\n",
        "        labels = self.data[index][\"labels\"]\n",
        "\n",
        "        text,labels = preprocess_text(text,labels)\n",
        "        # Convert text to embeddings\n",
        "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
        "\n",
        "        # print(text_embeddings.shape)\n",
        "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
        "        current_length = len(labels)\n",
        "#         print(labels)\n",
        "        labels = ['<START>'] + labels + ['<STOP>']\n",
        "#         print(labels)\n",
        "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
        "        sent_lengths =torch.tensor(len(labels))\n",
        "        max_length = 100\n",
        "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
        "\n",
        "        # Convert labels to numerical format if needed\n",
        "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
        "        numerical_labels = [label_mapping[label] for label in labels ]\n",
        "#         print(numerical_labels)\n",
        "\n",
        "        # Pad the sequence to the maximum length\n",
        "\n",
        "        # Convert labels to PyTorch tensor\n",
        "        labels_tensor = torch.tensor(numerical_labels)\n",
        "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
        "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
        "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class BiLSTMCRF(nn.Module):\n",
        "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
        "        \"\"\" Initialize the model\n",
        "        Args:\n",
        "            sent_vocab (Vocab): vocabulary of words\n",
        "            tag_vocab (Vocab): vocabulary of tags\n",
        "            embed_size (int): embedding size\n",
        "            hidden_size (int): hidden state size\n",
        "        \"\"\"\n",
        "        super(BiLSTMCRF, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.sent_vocab = sent_vocab\n",
        "        self.tag_vocab = tag_vocab\n",
        "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
        "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
        "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
        "\n",
        "    def forward(self, sentences,mask, tags, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            tags (tensor): corresponding tags, shape (b, len)\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            loss (tensor): loss on the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
        "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
        "        # print(\"forword--1\",sentences.shape)\n",
        "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
        "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
        "        # print(\"forword--2\",sentences.shape)\n",
        "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "    def encode(self, sentences, sent_lengths):\n",
        "        \"\"\" BiLSTM Encoder\n",
        "        Args:\n",
        "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "            sent_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            emit_score (tensor): emit score, shape (b, len, K)\n",
        "        \"\"\"\n",
        "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
        "        hidden_states, _ = self.encoder(sentences)\n",
        "        # print(hidden_states.shape,\"(((())))\")\n",
        "        hidden_states = hidden_states.permute(1,0,2)\n",
        "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "        # print(hidden_states.shape)\n",
        "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "        return emit_score\n",
        "\n",
        "    # def encode(self, sentences, sent_lengths):\n",
        "    #   \"\"\" BiLSTM Encoder\n",
        "    #   Args:\n",
        "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
        "    #       sent_lengths (list): sentence lengths\n",
        "    #   Returns:\n",
        "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
        "    #   \"\"\"\n",
        "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
        "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
        "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
        "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
        "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
        "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
        "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
        "    #   return emit_score\n",
        "\n",
        "    def cal_loss(self, tags, mask, emit_score):\n",
        "        \"\"\" Calculate CRF loss\n",
        "        Args:\n",
        "            tags (tensor): a batch of tags, shape (b, len)\n",
        "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
        "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
        "        Returns:\n",
        "            loss (tensor): loss of the batch, shape (b,)\n",
        "        \"\"\"\n",
        "        batch_size, sent_len = tags.shape\n",
        "        # calculate score for the tags\n",
        "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
        "        # calculate the scaling factor\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "        fix_length = 100\n",
        "        for i in range(1, fix_length):\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
        "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
        "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
        "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
        "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
        "        llk = total_score - d  # shape: (b,)\n",
        "        loss = -llk  # shape: (b,)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def predict(self, sentences, mask, sen_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
        "                                of the longest sentence\n",
        "            sen_lengths (list): sentence lengths\n",
        "        Returns:\n",
        "            tags (list[list[str]]): predicted tags for the batch\n",
        "        \"\"\"\n",
        "        batch_size = sentences.shape[0]\n",
        "\n",
        "        w = mask\n",
        "        sentences = sentences.transpose(0, 1)\n",
        "\n",
        "        emit_score = self.encode(sentences, sen_lengths)\n",
        "\n",
        "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
        "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
        "\n",
        "        # Initialize the first column of the dynamic programming matrix\n",
        "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
        "\n",
        "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
        "        fixed_length = 100\n",
        "\n",
        "        # Iterate over the remaining columns of the dynamic programming matrix\n",
        "        for i in range(1, fixed_length):\n",
        "            # Calculate the number of unfinished sentences at the current position\n",
        "            n_unfinished = mask[:, i].sum()\n",
        "\n",
        "            # Slice the dynamic programming matrix for the unfinished sentences\n",
        "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
        "\n",
        "            # Compute emission and transition scores for the current position\n",
        "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
        "\n",
        "            # Compute the new values for the dynamic programming matrix\n",
        "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
        "\n",
        "            # Update the dynamic programming matrix and get the indices of maximum values\n",
        "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
        "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
        "\n",
        "            # Update the tags for the unfinished sentences\n",
        "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
        "\n",
        "            # Concatenate the new values to the dynamic programming matrix\n",
        "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
        "\n",
        "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
        "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
        "\n",
        "        # Get the indices of the maximum values in the final column of the matrix\n",
        "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
        "        max_idx = max_idx.tolist()\n",
        "\n",
        "        # Extract the predicted tags based on the maximum indices\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
        "\n",
        "        # Print the predicted tags and sentence lengths for debugging\n",
        "        # print(tags, sen_lengths, '((()))')\n",
        "\n",
        "        return tags\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "import torch\n",
        "\n",
        "def calculate_accuracy(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]+1]\n",
        "        trex = target[i][:sen_lengths[i]+1]\n",
        "        acc += torch.sum(prex == trex)\n",
        "\n",
        "    # Move the division outside the loop to calculate the average accuracy\n",
        "    acc = acc.float() / (sum(sen_lengths)+10)\n",
        "    # print(acc)\n",
        "    return acc\n",
        "\n",
        "def aggregater(predictions, targets, sen_lengths):\n",
        "    ranges = targets.shape[0]\n",
        "    target = targets.cpu()\n",
        "    predictions = torch.tensor(predictions).cpu()\n",
        "    acc = 0\n",
        "    aggr_pred = []\n",
        "    aggr_targ = []\n",
        "    for i in range(ranges):\n",
        "        prex = predictions[i][:sen_lengths[i]]\n",
        "        trex = target[i][:sen_lengths[i]]\n",
        "        aggr_pred.extend(prex)\n",
        "        aggr_targ.extend(trex)\n",
        "    return aggr_pred,aggr_targ\n",
        "import json\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text,label):\n",
        "    # Remove punctuation\n",
        "    text_no_punct = ''\n",
        "    for char in text:\n",
        "        if char not in string.punctuation:\n",
        "            text_no_punct += char\n",
        "\n",
        "    # Check if the text length is zero after removing punctuation\n",
        "    if len(text_no_punct.strip()) == 0:\n",
        "        return text\n",
        "\n",
        "    # Lowercase the text\n",
        "    text_lower = text_no_punct.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = text_lower.split()\n",
        "\n",
        "    text_no_stopwords = ''\n",
        "    labels =[]\n",
        "    for word in range(len(tokens)):\n",
        "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
        "            text_no_stopwords += tokens[word] + ' '\n",
        "            labels.append(label[word])\n",
        "\n",
        "    return text_no_stopwords.strip(),labels\n",
        "\n",
        "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
        "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model_state_dict = torch.load('t1_model4_word2vec.pt')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "json_path = 'NER_test.json'\n",
        "embedding_type = 'word2vec'\n",
        "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
        "sentiment_dataset =sentiment_dataset_test\n",
        "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
        "batch_size  = 512\n",
        "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "model.eval()\n",
        "correct_predictions_val = 0\n",
        "total_sentences_val = 0\n",
        "predictions_r = []\n",
        "traget_r = []\n",
        "epoch=1\n",
        "device='cuda'\n",
        "with torch.no_grad():\n",
        "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
        "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
        "\n",
        "        # Prediction\n",
        "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
        "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
        "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
        "        predictions_r.extend(temp_pred)\n",
        "        traget_r.extend(temp_trag)\n",
        "\n",
        "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
        "print()\n",
        "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
        "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
      ],
      "metadata": {
        "id": "cIFq27RtC5dL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}