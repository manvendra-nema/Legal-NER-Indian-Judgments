{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTExoSN2ShWl",
    "outputId": "ed7eb4df-8c10-442d-cd12-f17da071a3d8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# for i in [\"TRAIN\", \"TEST\"]:\n",
    "#     with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#         raw_data = json.load(json_file)\n",
    "\n",
    "#     # Convert to BILOU format\n",
    "#     bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#     if i == \"TRAIN\":\n",
    "#         # Extract indices from bilou_data\n",
    "#         indices = list(bilou_data.keys())\n",
    "\n",
    "#         # Calculate the number of samples for training\n",
    "#         total_samples = len(indices)\n",
    "#         train_size = int(0.85 * total_samples)\n",
    "\n",
    "#         # Set a fixed seed for reproducibility\n",
    "#         np.random.seed(42)\n",
    "\n",
    "#         # Shuffle the indices\n",
    "#         np.random.shuffle(indices)\n",
    "\n",
    "#         # Split indices into training and validation sets\n",
    "#         train_indices = indices[:train_size]\n",
    "#         val_indices = indices[train_size:]\n",
    "\n",
    "#         # Create training and validation datasets in BILOU format with reset indices\n",
    "#         train_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(train_indices)\n",
    "#         }\n",
    "#         val_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(val_indices)\n",
    "#         }\n",
    "\n",
    "#         # Save the output to JSON files for training\n",
    "#         with open(f'bilou_data_TRAIN.json', 'w') as json_file:\n",
    "#             json.dump(train_bilou_data, json_file, indent=2)\n",
    "\n",
    "#         with open(f'bilou_data_VAL.json', 'w') as json_file:\n",
    "#             json.dump(val_bilou_data, json_file, indent=2)\n",
    "#     elif i == \"TEST\":\n",
    "#         # Save the output to a JSON file for testing\n",
    "#         with open(f'bilou_data_TEST.json', 'w') as json_file:\n",
    "#             json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1JXz9D9SEdxy"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "            \n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import re\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Lowercasing\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # Remove special characters and escape sequences\n",
    "#     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     # Tokenize the text and lemmatize each word\n",
    "#     words = nltk.word_tokenize(text)\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "#     return ' '.join(lemmatized_words)\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         text = preprocess_text(text)  # Apply lowercasing and remove special characters\n",
    "#         text = lemmatize_text(text)   # Apply lemmatization\n",
    "\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Eym7hCkbtYO",
    "outputId": "00a8ff0b-818a-47ea-f438-005230c5afa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B_COURT', 'I_COURT', 'B_PETITIONER', 'I_PETITIONER', 'B_RESPONDENT', 'I_RESPONDENT', 'B_JUDGE', 'I_JUDGE', 'B_LAWYER', 'I_LAWYER', 'B_DATE', 'I_DATE', 'B_ORG', 'I_ORG', 'B_GPE', 'I_GPE', 'B_STATUTE', 'I_STATUTE', 'B_PROVISION', 'I_PROVISION', 'B_PRECEDENT', 'I_PRECEDENT', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'B_WITNESS', 'I_WITNESS', 'B_OTHER_PERSON', 'I_OTHER_PERSON', '<START>', '<STOP>', '<PAD>']\n",
      "{'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n"
     ]
    }
   ],
   "source": [
    "named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER', 'DATE', 'ORG', 'GPE', 'STATUTE', 'PROVISION', 'PRECEDENT', 'CASE_NUMBER', 'WITNESS', 'OTHER_PERSON']\n",
    "# named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER']\n",
    "\n",
    "named_entity_combinations = ['O']\n",
    "\n",
    "for entity in named_entities:\n",
    "    b_entity = \"B_\" + entity\n",
    "    i_entity = \"I_\" + entity\n",
    "    named_entity_combinations.extend([b_entity, i_entity])\n",
    "named_entity_combinations.append('<START>')\n",
    "named_entity_combinations.append('<STOP>')\n",
    "named_entity_combinations.append('<PAD>')\n",
    "print(named_entity_combinations)\n",
    "\n",
    "named_entity_encoding = {entity: idx for idx, entity in enumerate(named_entity_combinations)}\n",
    "\n",
    "print(named_entity_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lQkdf-XdEnfJ"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWR6lMXiEpYS",
    "outputId": "a95c7dbc-6a41-45df-b306-2cf0a3d6a731",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "# import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "#import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# sentiment_dataset.embedding_model= temp.embedding_model\n",
    "# Accessing a sample from the dataset\n",
    "# sample_text_embeddings, sample_labels, mask,s_len = sentiment_dataset[0]\n",
    "# print(\"Sample Text Embeddings:\", sample_text_embeddings)\n",
    "# print(\"Sample Labels:\", sample_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sentiment_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sentiment_dataset)):\n",
    "#     print(sentiment_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xV1g4_jteXTp"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # Set a seed for reproducibility\n",
    "# torch.manual_seed(42)  # You can choose any seed value\n",
    "\n",
    "# total_size = len(sentiment_dataset)\n",
    "# indices = list(range(total_size))\n",
    "\n",
    "# # Define the split sizes\n",
    "# train_size = int(0.85 * total_size)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# # Use the seed for reproducibility when shuffling\n",
    "# torch.randperm(total_size)\n",
    "\n",
    "# # Split the indices\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "\n",
    "# # Create Subset datasets using the indices\n",
    "# train_dataset = torch.utils.data.Subset(sentiment_dataset, train_indices)\n",
    "# val_dataset = torch.utils.data.Subset(sentiment_dataset, val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_dataset[0])\n",
    "# val_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "__2DRx7cZCHc"
   },
   "outputs": [],
   "source": [
    "z = set()\n",
    "for i in range(len(sentiment_dataset)):\n",
    "    a,b,c,d = (sentiment_dataset[i])\n",
    "    for j in b:\n",
    "        z.add(j.item())\n",
    "#     for j in range(len(sentiment_dataset[i])):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QOxk1a5sTXtN"
   },
   "outputs": [],
   "source": [
    "batch_size  = 512\n",
    "json_path = \"NER_TRAIN.json\"\n",
    "embedding_type = 'glove'\n",
    "sentiment_dataset = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "dataloader = DataLoader(sentiment_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wdA2HAHVqBrT"
   },
   "outputs": [],
   "source": [
    "json_path = \"bilou_data_VAL.json\"\n",
    "sentiment_dataset_val = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_val.embedding_model = sentiment_dataset.embedding_model\n",
    "dataloader_val = DataLoader(sentiment_dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'bilou_data_TEST.json'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7PRU5YYtEtqs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "    # def predict(self, sentences,mask, sen_lengths):\n",
    "    #     \"\"\"\n",
    "    #     Args:\n",
    "    #         sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "    #                             of the longest sentence\n",
    "    #         sen_lengths (list): sentence lengths\n",
    "    #     Returns:\n",
    "    #         tags (list[list[str]]): predicted tags for the batch\n",
    "    #     \"\"\"\n",
    "    #     batch_size = sentences.shape[0]\n",
    "    #     # w = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)\n",
    "    #     w = mask\n",
    "    #     sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "    #     # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "    #     emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "    #     tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "    #     d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "    #     for i in range(1, sen_lengths[0]):\n",
    "    #         n_unfinished = mask[:, i].sum()\n",
    "    #         d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "    #         emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "    #         new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "    #         d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "    #         max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "    #         tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "    #         d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "    #     d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "    #     _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "    #     max_idx = max_idx.tolist()\n",
    "    #     tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "    #     print(tags,sen_lengths,'((()))')\n",
    "    #     return tags\n",
    "\n",
    "    # def save(self, filepath):\n",
    "    #     params = {\n",
    "    #         'sent_vocab': self.sent_vocab,\n",
    "    #         'tag_vocab': self.tag_vocab,\n",
    "    #         'args': dict(dropout_rate=self.dropout_rate, embed_size=self.embed_size, hidden_size=self.hidden_size),\n",
    "    #         'state_dict': self.state_dict()\n",
    "    #     }\n",
    "    #     torch.save(params, filepath)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     sent_vocab = Vocab.load('./vocab/sent_vocab.json')\n",
    "#     tag_vocab = Vocab.load('./vocab/tag_vocab.json')\n",
    "#     train_data, dev_data = utils.generate_train_dev_dataset('./data/train.txt', sent_vocab, tag_vocab)\n",
    "#     device = torch.device('cpu')\n",
    "#     model = BiLSTMCRF(sent_vocab, tag_vocab)\n",
    "#     model.to(device)\n",
    "#     model.save('./model/model.pth')\n",
    "#     model = model.load('./model/model.pth', device)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "argnny6HH0Tu"
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9  # Optional: You can adjust the momentum term\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oHr2iehwItKL"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Check predictions before training\n",
    "# for epoch in range(300):\n",
    "#     total_loss = 0\n",
    "#     correct_predictions = 0\n",
    "#     total_sentences = 0\n",
    "\n",
    "#     # Wrap your dataloader with tqdm for a progress bar\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         # Move input data to GPU\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         total_sentences += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss for the epoch\n",
    "#     average_loss = total_loss / total_sentences\n",
    "\n",
    "#     # Print loss for each epoch\n",
    "#     print(f'Epoch {epoch + 1}/{300}, Loss: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8465903IIQiP",
    "outputId": "59fc2395-654e-4f03-e9f2-6d821084fef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])==torch.tensor([1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2mAtfLRzkl3",
    "outputId": "c8c91803-9f7b-4d97-8972-dec9ac4651d4"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fed62b3a309a402dba270a79ae613fec",
      "4e627c3c18f7453d843197124428d4e3",
      "a41f20afb91441ebb9d824625a4280e1",
      "126562022a634f218a533eb2d0cb68ce",
      "9dab3d6fa9be463b81add125fc796b1b",
      "f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "0befd16ce747402b8fd074f82ac58bef",
      "5c0c4e0669724ef0a85788b9e1d372b4"
     ]
    },
    "id": "5tA2FjdzzM4R",
    "outputId": "c35f5f15-59c2-4ce8-dc71-731ffef8e94f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanvendra\u001b[0m (\u001b[33miiitd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Manvendra Nema\\Notebooks\\Untitled Folder\\wandb\\run-20240309_130531-1i1jg30w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/1i1jg30w' target=\"_blank\">GV-oo-3</a></strong> to <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/1i1jg30w' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/1i1jg30w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64931136 0.00149365 0.00673401 0.         0.00127267 0.\n",
      " 0.00305111 0.00197433 0.00339751 0.         0.         0.01530055\n",
      " 0.01427756 0.00286738 0.00606796 0.00788333 0.         0.00961538\n",
      " 0.01048427 0.00953895 0.01814672 0.00299401 0.08168903 0.00379747\n",
      " 0.01864297 0.00440529 0.00803213 0.01207815 0.00613497 0.41344069\n",
      " 0.55459195 0.28665001]\n",
      "Training Epoch 1/300, Loss: 17.1950, Accuracy: 0.4309, F1: 0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84933045 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16426513 0.         0.01340034 0.\n",
      " 0.         0.         0.02173913 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 1/300, Loss: 5.2316, Accuracy: 0.7578, F1: 0.1349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79840423 0.00793126 0.02817711 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.03800905\n",
      " 0.00316706 0.01212121 0.01896296 0.00470588 0.         0.05750529\n",
      " 0.02527574 0.05126429 0.04759825 0.02813128 0.22122265 0.01283226\n",
      " 0.01529052 0.00397219 0.         0.02332004 0.05705925 0.80429434\n",
      " 0.80108393 0.35329104]\n",
      "Training Epoch 2/300, Loss: 7.0650, Accuracy: 0.6066, F1: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87597433 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01342282 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52951432 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 2/300, Loss: 2.9611, Accuracy: 0.7837, F1: 0.1472\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84875379 0.06502986 0.05665722 0.00386847 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15301455\n",
      " 0.16739236 0.04750594 0.03528374 0.03834511 0.00506329 0.07731247\n",
      " 0.04087737 0.15431888 0.12657736 0.06204906 0.36385941 0.00844595\n",
      " 0.04065959 0.00603622 0.0433213  0.06954282 0.07884151 0.81972038\n",
      " 0.830372   0.46714436]\n",
      "Training Epoch 3/300, Loss: 3.8486, Accuracy: 0.6733, F1: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9001042  0.01030928 0.00573066 0.         0.         0.\n",
      " 0.         0.         0.         0.05536332 0.0861244  0.\n",
      " 0.         0.         0.         0.         0.         0.28715365\n",
      " 0.18373494 0.         0.46252889 0.         0.         0.\n",
      " 0.04545455 0.10212766 0.06876791 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 3/300, Loss: 1.6004, Accuracy: 0.7852, F1: 0.1735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86278533 0.13195343 0.12886259 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29705506\n",
      " 0.33101232 0.05008945 0.04466945 0.031688   0.         0.11243612\n",
      " 0.07146503 0.18922559 0.20861678 0.1047619  0.42780829 0.02099237\n",
      " 0.08323699 0.01197605 0.1046892  0.09375    0.09577677 0.80519303\n",
      " 0.82567095 0.58896111]\n",
      "Training Epoch 4/300, Loss: 1.8815, Accuracy: 0.6970, F1: 0.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92518079 0.4379562  0.36897275 0.         0.         0.\n",
      " 0.         0.         0.         0.64770241 0.51636364 0.01970443\n",
      " 0.00956938 0.         0.         0.36016949 0.21799747 0.58186739\n",
      " 0.44572526 0.43559719 0.61339268 0.         0.02118644 0.\n",
      " 0.11851852 0.27795527 0.26242545 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 4/300, Loss: 0.7240, Accuracy: 0.8261, F1: 0.3086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88732527 0.23354839 0.20990099 0.01247401 0.01584158 0.\n",
      " 0.00934579 0.         0.00458716 0.         0.         0.41397154\n",
      " 0.39125561 0.07274969 0.07473651 0.06515957 0.         0.1938873\n",
      " 0.20924034 0.39496782 0.33300258 0.18568894 0.49819523 0.04334975\n",
      " 0.1465284  0.036452   0.1171459  0.14325581 0.11638591 0.81134121\n",
      " 0.80052681 0.77115051]\n",
      "Training Epoch 5/300, Loss: 0.9944, Accuracy: 0.7449, F1: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93265091 0.49056604 0.37554585 0.         0.         0.\n",
      " 0.         0.         0.         0.54892601 0.48507463 0.0372093\n",
      " 0.03532009 0.         0.         0.34764826 0.41295117 0.58313817\n",
      " 0.45898923 0.46017699 0.66736227 0.         0.         0.\n",
      " 0.01724138 0.27880512 0.24489796 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 5/300, Loss: 0.5394, Accuracy: 0.8260, F1: 0.3125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90124586 0.38670695 0.31660232 0.01856148 0.00488998 0.\n",
      " 0.         0.         0.00593472 0.         0.         0.4614094\n",
      " 0.44911882 0.0926045  0.11732356 0.0599047  0.         0.23325527\n",
      " 0.25703369 0.44478528 0.39367638 0.35281837 0.64574646 0.08856089\n",
      " 0.19334187 0.06683168 0.14       0.20834485 0.19843697 0.88197939\n",
      " 0.89120912 0.92061257]\n",
      "Training Epoch 6/300, Loss: 0.6345, Accuracy: 0.7809, F1: 0.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93424908 0.66871166 0.52886406 0.         0.         0.\n",
      " 0.         0.         0.         0.59688196 0.60273973 0.23492063\n",
      " 0.26004228 0.03389831 0.         0.45945946 0.52908068 0.71253823\n",
      " 0.5660019  0.58479532 0.73969849 0.29508197 0.39849151 0.\n",
      " 0.03418803 0.35294118 0.30838323 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 6/300, Loss: 0.4307, Accuracy: 0.8445, F1: 0.3946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89525416 0.39189189 0.32830725 0.00973236 0.         0.\n",
      " 0.         0.         0.         0.         0.51494768 0.51030928\n",
      " 0.12733645 0.1512761  0.09850374 0.         0.23195661 0.24697609\n",
      " 0.53502155 0.46529081 0.42358722 0.65279255 0.08148148 0.14164795\n",
      " 0.08490566 0.17519909 0.22767971 0.21567472 0.82604958 0.92925764\n",
      " 0.94460049]\n",
      "Training Epoch 7/300, Loss: 0.5741, Accuracy: 0.7757, F1: 0.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89836613 0.61754386 0.43076923 0.         0.         0.\n",
      " 0.         0.         0.         0.65671642 0.67069486 0.13548387\n",
      " 0.14864865 0.04571429 0.         0.30588235 0.2415043  0.73253833\n",
      " 0.5978706  0.4688172  0.68491433 0.06802721 0.13412229 0.\n",
      " 0.0173913  0.33692722 0.26604069 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 7/300, Loss: 0.4706, Accuracy: 0.7699, F1: 0.3485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9002375  0.3722488  0.30261102 0.01474201 0.01895735 0.\n",
      " 0.         0.00468384 0.0125     0.         0.         0.55407407\n",
      " 0.54820798 0.11870101 0.11074633 0.11169284 0.         0.22057461\n",
      " 0.2356823  0.52426069 0.43794466 0.37847697 0.58580559 0.18996139\n",
      " 0.37175883 0.07226107 0.13333333 0.21361372 0.21453287 0.89140763\n",
      " 0.92711189 0.94312099]\n",
      "Training Epoch 8/300, Loss: 0.5782, Accuracy: 0.7829, F1: 0.2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94014224 0.65972222 0.47368421 0.         0.         0.\n",
      " 0.         0.         0.         0.75746269 0.72829132 0.\n",
      " 0.         0.25484765 0.         0.5516129  0.60129776 0.81178396\n",
      " 0.68927589 0.62086514 0.80238501 0.43307087 0.63147974 0.09271523\n",
      " 0.09722222 0.31229236 0.30894309 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 8/300, Loss: 0.3982, Accuracy: 0.8690, F1: 0.4255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91438621 0.41675854 0.36069174 0.02891566 0.004662   0.\n",
      " 0.         0.00484262 0.00647249 0.         0.         0.54281099\n",
      " 0.59255583 0.17647059 0.18148488 0.1277533  0.         0.3647541\n",
      " 0.41878517 0.58496915 0.54626961 0.4462963  0.69874477 0.21967213\n",
      " 0.4027173  0.12581345 0.15664018 0.23536198 0.22673108 0.96396055\n",
      " 0.92574134 0.94207586]\n",
      "Training Epoch 9/300, Loss: 0.4939, Accuracy: 0.8136, F1: 0.3318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94101845 0.77837838 0.69985359 0.         0.         0.\n",
      " 0.         0.         0.         0.71551724 0.70552147 0.23188406\n",
      " 0.16091954 0.27385892 0.         0.55892256 0.56921087 0.80135823\n",
      " 0.6835443  0.52765957 0.71306306 0.         0.         0.07633588\n",
      " 0.07936508 0.27829314 0.26168224 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 9/300, Loss: 0.3704, Accuracy: 0.8602, F1: 0.4018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91819575 0.49605055 0.42879337 0.04326923 0.02803738 0.\n",
      " 0.         0.         0.         0.         0.         0.5523886\n",
      " 0.60536398 0.18777293 0.23080637 0.13882353 0.00668896 0.35910653\n",
      " 0.46567968 0.60793695 0.5556647  0.48110599 0.70837271 0.26212121\n",
      " 0.4057676  0.13938754 0.18609865 0.25710969 0.2561415  0.96721728\n",
      " 0.92568579 0.94369184]\n",
      "Training Epoch 10/300, Loss: 0.4468, Accuracy: 0.8210, F1: 0.3487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94444444 0.75842697 0.68064516 0.         0.         0.\n",
      " 0.         0.         0.         0.73390558 0.73684211 0.1991342\n",
      " 0.1656051  0.2972973  0.         0.59148936 0.6089613  0.81184669\n",
      " 0.65010352 0.64379947 0.81362398 0.32492997 0.40729167 0.07692308\n",
      " 0.096      0.4140625  0.40123457 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 10/300, Loss: 0.3330, Accuracy: 0.8663, F1: 0.4451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91822844 0.54186667 0.48705205 0.06132075 0.0372093  0.\n",
      " 0.         0.00480769 0.00641026 0.         0.         0.58855799\n",
      " 0.60038241 0.23516484 0.30526067 0.16756433 0.00671141 0.38874459\n",
      " 0.48312402 0.63085777 0.57365347 0.4703042  0.71647094 0.26506024\n",
      " 0.44507142 0.17347956 0.22978723 0.28278087 0.27200529 0.96973165\n",
      " 0.92528377 0.94571902]\n",
      "Training Epoch 11/300, Loss: 0.4265, Accuracy: 0.8274, F1: 0.3666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92790909 0.75884244 0.6368932  0.         0.         0.\n",
      " 0.         0.         0.         0.64678899 0.75659824 0.3785489\n",
      " 0.40398293 0.28125    0.         0.65454545 0.69582119 0.80672269\n",
      " 0.68249258 0.62686567 0.74276206 0.36756757 0.59736457 0.08695652\n",
      " 0.09090909 0.37518464 0.4        0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 11/300, Loss: 0.3558, Accuracy: 0.8686, F1: 0.4639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90551201 0.50552923 0.46100174 0.0990991  0.0372093  0.\n",
      " 0.         0.         0.         0.         0.         0.5666534\n",
      " 0.55575868 0.18885942 0.19266875 0.14110787 0.01980198 0.3485342\n",
      " 0.39422916 0.62784248 0.56297741 0.43021033 0.64661507 0.19375\n",
      " 0.32946636 0.18853256 0.23045267 0.26772115 0.26952625 0.96690849\n",
      " 0.92495789 0.94324738]\n",
      "Training Epoch 12/300, Loss: 0.4773, Accuracy: 0.8034, F1: 0.3437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94736592 0.71465296 0.6537931  0.         0.         0.\n",
      " 0.         0.         0.         0.75       0.74210526 0.14814815\n",
      " 0.08018868 0.29166667 0.         0.61693548 0.62411348 0.82747604\n",
      " 0.73356401 0.46728972 0.67542762 0.         0.         0.13513514\n",
      " 0.15277778 0.3877551  0.39261745 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 12/300, Loss: 0.4056, Accuracy: 0.8639, F1: 0.4113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9129635  0.46742057 0.35664166 0.09251101 0.05128205 0.\n",
      " 0.00510204 0.02267574 0.01246106 0.         0.         0.564022\n",
      " 0.5722248  0.21047065 0.22525276 0.14354644 0.02572347 0.35169158\n",
      " 0.40809859 0.57861288 0.49717332 0.37977099 0.67100237 0.07306712\n",
      " 0.14514534 0.15249267 0.21496312 0.25674931 0.25956535 0.96864509\n",
      " 0.92968458 0.94665878]\n",
      "Training Epoch 13/300, Loss: 0.5156, Accuracy: 0.8066, F1: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9297448  0.74598071 0.61932939 0.         0.         0.\n",
      " 0.         0.         0.         0.76734694 0.75956284 0.00995025\n",
      " 0.0097561  0.30909091 0.         0.48846676 0.46046743 0.79041916\n",
      " 0.69644485 0.21487603 0.29018075 0.         0.         0.04918033\n",
      " 0.05172414 0.4034749  0.36976744 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 13/300, Loss: 0.4206, Accuracy: 0.8339, F1: 0.3655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91892637 0.49764767 0.44782826 0.10337079 0.07407407 0.00746269\n",
      " 0.01038961 0.02690583 0.01223242 0.         0.         0.55799373\n",
      " 0.58534406 0.16904501 0.1943128  0.18393624 0.01286174 0.34154777\n",
      " 0.39140134 0.62795221 0.57978981 0.45414847 0.75558905 0.23413996\n",
      " 0.39467273 0.1798419  0.21267454 0.27255065 0.28426698 0.97127275\n",
      " 0.93215266 0.94913446]\n",
      "Training Epoch 14/300, Loss: 0.4490, Accuracy: 0.8232, F1: 0.3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9462709  0.79591837 0.73024523 0.         0.         0.\n",
      " 0.         0.         0.         0.74782609 0.76608187 0.16143498\n",
      " 0.10383747 0.33088235 0.         0.55433071 0.5276273  0.8373591\n",
      " 0.75535714 0.66853933 0.83348122 0.01408451 0.01698514 0.07936508\n",
      " 0.08333333 0.45210728 0.43285528 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 14/300, Loss: 0.3272, Accuracy: 0.8738, F1: 0.4279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92433522 0.57805907 0.50310057 0.06971678 0.04835165 0.02857143\n",
      " 0.03686636 0.04149378 0.04359673 0.         0.         0.61254902\n",
      " 0.66815742 0.25596529 0.30644766 0.19165197 0.02424242 0.41934139\n",
      " 0.49562001 0.64742717 0.60432346 0.50283554 0.74432438 0.29524485\n",
      " 0.468107   0.25043178 0.29899727 0.28374738 0.29391138 0.97007814\n",
      " 0.9265586  0.94514967]\n",
      "Training Epoch 15/300, Loss: 0.3962, Accuracy: 0.8349, F1: 0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95077739 0.84468665 0.79525223 0.         0.         0.\n",
      " 0.         0.         0.         0.78787879 0.74935401 0.38993711\n",
      " 0.40460948 0.30414747 0.         0.61382799 0.6212211  0.79407407\n",
      " 0.71773637 0.62915601 0.83840749 0.45192308 0.69297164 0.22459893\n",
      " 0.21978022 0.46153846 0.44600281 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 15/300, Loss: 0.2879, Accuracy: 0.8824, F1: 0.4979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92596554 0.57571059 0.54797917 0.11538462 0.07048458 0.\n",
      " 0.         0.01797753 0.01812689 0.         0.         0.59315895\n",
      " 0.63825929 0.25177112 0.33185404 0.19354839 0.0625     0.47289408\n",
      " 0.58092429 0.64934339 0.62481512 0.52186732 0.78678103 0.3615495\n",
      " 0.5691602  0.22490706 0.278      0.31491077 0.31930693 0.97392959\n",
      " 0.93108824 0.94832791]\n",
      "Training Epoch 16/300, Loss: 0.3690, Accuracy: 0.8446, F1: 0.4031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95020298 0.85714286 0.80256822 0.         0.         0.\n",
      " 0.         0.         0.         0.77731092 0.78453039 0.4805492\n",
      " 0.5028665  0.31304348 0.         0.67782427 0.7637051  0.85807504\n",
      " 0.7880387  0.58653846 0.77873563 0.49514563 0.74226804 0.13333333\n",
      " 0.13793103 0.40995608 0.43558282 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 16/300, Loss: 0.2883, Accuracy: 0.8872, F1: 0.5091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92779232 0.57544225 0.5606778  0.0877193  0.05633803 0.00735294\n",
      " 0.01023018 0.04329004 0.02873563 0.         0.59764515 0.64084832\n",
      " 0.29374337 0.36723029 0.23803967 0.07250755 0.46102263 0.57159976\n",
      " 0.66795794 0.6370902  0.53636813 0.7987488  0.40149254 0.61644582\n",
      " 0.23769731 0.28514851 0.30405989 0.32740214 0.97561285 0.93298423\n",
      " 0.95173069]\n",
      "Training Epoch 17/300, Loss: 0.3586, Accuracy: 0.8485, F1: 0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94954237 0.86980609 0.82165605 0.         0.         0.\n",
      " 0.         0.         0.         0.77052632 0.77966102 0.47619048\n",
      " 0.54744526 0.30508475 0.         0.65970772 0.75830258 0.85049834\n",
      " 0.73623188 0.66666667 0.83651069 0.51937984 0.66257669 0.08759124\n",
      " 0.09160305 0.43220339 0.47159091 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 17/300, Loss: 0.2813, Accuracy: 0.8910, F1: 0.5097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92830006 0.59147609 0.57120663 0.11612903 0.0896861  0.02857143\n",
      " 0.03448276 0.07377049 0.03814714 0.         0.         0.57986252\n",
      " 0.64136974 0.29220779 0.38055166 0.22700815 0.06606607 0.49225617\n",
      " 0.6086094  0.66666667 0.64396887 0.53943525 0.79065597 0.37518685\n",
      " 0.61359082 0.21838035 0.26129666 0.31462634 0.32832157 0.97500951\n",
      " 0.92802794 0.94837182]\n",
      "Training Epoch 18/300, Loss: 0.3499, Accuracy: 0.8494, F1: 0.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94461797 0.87331536 0.81155015 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.78838174 0.80108992 0.48253968\n",
      " 0.57483444 0.36363636 0.         0.71624266 0.79963735 0.8548124\n",
      " 0.78268711 0.64225352 0.80592503 0.54545455 0.75480769 0.11034483\n",
      " 0.11510791 0.45062587 0.4491654  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 18/300, Loss: 0.2790, Accuracy: 0.8945, F1: 0.5247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92753358 0.58804865 0.56516129 0.11860941 0.08189655 0.01428571\n",
      " 0.0345679  0.04415011 0.01169591 0.         0.61297889 0.66364461\n",
      " 0.32553076 0.40067421 0.24150059 0.04863222 0.48601974 0.60963391\n",
      " 0.67271228 0.64797809 0.55740922 0.80048502 0.385377   0.60451671\n",
      " 0.25420561 0.31959799 0.34428613 0.36020688 0.97544572 0.92979174\n",
      " 0.95059019]\n",
      "Training Epoch 19/300, Loss: 0.3457, Accuracy: 0.8513, F1: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9386898  0.80473373 0.73883162 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.72160356 0.73846154 0.34558824\n",
      " 0.36678201 0.35555556 0.         0.70930233 0.76376554 0.83849918\n",
      " 0.76164384 0.6440678  0.78324671 0.53881279 0.76792224 0.11188811\n",
      " 0.11678832 0.45454545 0.43302181 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 19/300, Loss: 0.2958, Accuracy: 0.8851, F1: 0.5003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9284109  0.63814052 0.609469   0.10901468 0.09610984 0.00732601\n",
      " 0.0049505  0.05073996 0.03899721 0.         0.         0.6328125\n",
      " 0.65723131 0.31478537 0.39554185 0.26060968 0.10315186 0.47733888\n",
      " 0.6035225  0.68783931 0.64799491 0.54705882 0.78537393 0.37683284\n",
      " 0.60556522 0.27678571 0.33460076 0.32964473 0.34524167 0.97616331\n",
      " 0.92302894 0.94286051]\n",
      "Training Epoch 20/300, Loss: 0.3452, Accuracy: 0.8505, F1: 0.4283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95270287 0.82233503 0.74906367 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.781893   0.75338753 0.44897959\n",
      " 0.54945055 0.3362069  0.         0.70930233 0.78403756 0.83489097\n",
      " 0.77803558 0.63366337 0.82361809 0.52765957 0.72708963 0.16\n",
      " 0.16551724 0.46480744 0.43229167 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 20/300, Loss: 0.2689, Accuracy: 0.8915, F1: 0.5170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9317642  0.59865355 0.59281588 0.08064516 0.06794055 0.00711744\n",
      " 0.01503759 0.07755102 0.04324324 0.         0.         0.63520309\n",
      " 0.65989848 0.35508021 0.43342292 0.27626919 0.10285714 0.505\n",
      " 0.62449684 0.69292649 0.66018788 0.55734505 0.80998947 0.40148148\n",
      " 0.61151212 0.27443946 0.32916266 0.32607416 0.3506533  0.97924576\n",
      " 0.93425649 0.95190536]\n",
      "Training Epoch 21/300, Loss: 0.3341, Accuracy: 0.8568, F1: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94929064 0.86666667 0.82515337 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.79338843 0.78551532 0.5171504\n",
      " 0.56940223 0.33043478 0.         0.71146245 0.81468531 0.85350318\n",
      " 0.79530201 0.65352113 0.82774566 0.55263158 0.74019088 0.14666667\n",
      " 0.13793103 0.43902439 0.45689655 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 21/300, Loss: 0.2665, Accuracy: 0.8962, F1: 0.5280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93284397 0.63009404 0.61844485 0.09465021 0.06493506 0.02857143\n",
      " 0.02444988 0.06464646 0.04712042 0.64222308 0.6716141  0.35816165\n",
      " 0.42132457 0.25825826 0.07887324 0.50604419 0.62426614 0.69293924\n",
      " 0.67865097 0.55342196 0.80877458 0.41120118 0.63560732 0.28245614\n",
      " 0.32703214 0.3241462  0.35268414 0.97893338 0.93083016 0.94909026]\n",
      "Training Epoch 22/300, Loss: 0.3268, Accuracy: 0.8586, F1: 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95233121 0.87262873 0.82978723 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.81059063 0.77956989 0.51327434\n",
      " 0.59375    0.38367347 0.03703704 0.704      0.80473373 0.84676145\n",
      " 0.79329609 0.67231638 0.82977461 0.56502242 0.77977528 0.22093023\n",
      " 0.24852071 0.47776366 0.45229682 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 22/300, Loss: 0.2597, Accuracy: 0.8992, F1: 0.5414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93102658 0.61687265 0.60497091 0.13414634 0.0861678  0.03597122\n",
      " 0.04522613 0.08747515 0.07387863 0.61135723 0.640553   0.33475936\n",
      " 0.40681219 0.26782609 0.07799443 0.49440994 0.60906136 0.67791077\n",
      " 0.65469126 0.56003937 0.80199651 0.4115899  0.61895343 0.26555246\n",
      " 0.33131313 0.33118783 0.34499845 0.97863194 0.92802794 0.94663353]\n",
      "Training Epoch 23/300, Loss: 0.3268, Accuracy: 0.8548, F1: 0.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95487334 0.87709497 0.82670906 0.1        0.11764706 0.\n",
      " 0.         0.         0.         0.80566802 0.78074866 0.51648352\n",
      " 0.57468643 0.35964912 0.03703704 0.72764228 0.81558442 0.86217949\n",
      " 0.80226904 0.61538462 0.81875792 0.57657658 0.75645342 0.22360248\n",
      " 0.25477707 0.50066578 0.45089903 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 23/300, Loss: 0.2549, Accuracy: 0.9002, F1: 0.5451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93243909 0.62787136 0.62475442 0.14901961 0.10615711 0.02105263\n",
      " 0.01445783 0.11451943 0.08196721 0.6297906  0.68064228 0.35779325\n",
      " 0.44788934 0.27692308 0.05865103 0.49709061 0.63046815 0.6956047\n",
      " 0.66559278 0.56830601 0.8089214  0.43168605 0.61854211 0.27140255\n",
      " 0.33009709 0.32609971 0.34198473 0.97746265 0.93034857 0.94883941]\n",
      "Training Epoch 24/300, Loss: 0.3254, Accuracy: 0.8578, F1: 0.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95186156 0.87027027 0.82602118 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.80961924 0.79665738 0.53521127\n",
      " 0.5915493  0.39344262 0.03703704 0.72349272 0.82026769 0.85528455\n",
      " 0.78858162 0.66852368 0.82914137 0.5907173  0.75607181 0.18181818\n",
      " 0.17567568 0.48302872 0.44840764 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 24/300, Loss: 0.2580, Accuracy: 0.9001, F1: 0.5402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93281098 0.64576803 0.62693498 0.11854685 0.0969697  0.02666667\n",
      " 0.0501139  0.096      0.07672634 0.64064915 0.67693702 0.36563646\n",
      " 0.47212503 0.27233518 0.08791209 0.50805452 0.64431885 0.71382289\n",
      " 0.68249258 0.57297297 0.81799037 0.4239291  0.65939349 0.26532479\n",
      " 0.31795878 0.33304119 0.34847542 0.97853208 0.92386357 0.94434619]\n",
      "Training Epoch 25/300, Loss: 0.3187, Accuracy: 0.8602, F1: 0.4774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95466615 0.85333333 0.81481481 0.09677419 0.11320755 0.\n",
      " 0.         0.         0.         0.79513185 0.78125    0.52048193\n",
      " 0.54577778 0.34234234 0.         0.71848739 0.80379147 0.85805423\n",
      " 0.81451613 0.640625   0.83608247 0.55696203 0.74658254 0.13043478\n",
      " 0.13636364 0.50649351 0.47028424 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 25/300, Loss: 0.2549, Accuracy: 0.8979, F1: 0.5345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93272312 0.62632696 0.63876537 0.13333333 0.11764706 0.02112676\n",
      " 0.01477833 0.12109375 0.10796915 0.         0.63001949 0.65921788\n",
      " 0.38367347 0.45698555 0.28823529 0.10410959 0.53513072 0.64093113\n",
      " 0.70497238 0.69142209 0.58481262 0.80983888 0.42553191 0.65276519\n",
      " 0.26023658 0.34307992 0.33896331 0.36053812 0.97974684 0.92827741\n",
      " 0.94717539]\n",
      "Training Epoch 26/300, Loss: 0.3160, Accuracy: 0.8601, F1: 0.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9532334  0.86740331 0.82716049 0.13114754 0.11538462 0.\n",
      " 0.         0.         0.         0.78701826 0.76649746 0.50753769\n",
      " 0.5509434  0.31818182 0.03636364 0.70703125 0.78904992 0.86129032\n",
      " 0.80232558 0.62886598 0.83277849 0.56326531 0.74215033 0.20481928\n",
      " 0.225      0.49263722 0.46013072 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 26/300, Loss: 0.2559, Accuracy: 0.8955, F1: 0.5389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93545671 0.66838577 0.65782764 0.14919355 0.12738854 0.03267974\n",
      " 0.04545455 0.11985019 0.1294964  0.         0.6367538  0.69092543\n",
      " 0.37925616 0.46554582 0.28824572 0.09577465 0.53537443 0.65302911\n",
      " 0.70021299 0.67521501 0.60127513 0.83419953 0.44362018 0.64425042\n",
      " 0.2807971  0.34892788 0.35007429 0.3855573  0.977882   0.93552812\n",
      " 0.95312872]\n",
      "Training Epoch 27/300, Loss: 0.3100, Accuracy: 0.8653, F1: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95457362 0.87052342 0.82594937 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.81048387 0.77866667 0.51497006\n",
      " 0.57907543 0.41004184 0.07272727 0.7257384  0.83022388 0.86035313\n",
      " 0.80645161 0.6119403  0.78765248 0.58558559 0.78343195 0.14084507\n",
      " 0.14705882 0.48906049 0.45544554 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 27/300, Loss: 0.2537, Accuracy: 0.8993, F1: 0.5372\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93611674 0.65269775 0.66786911 0.17647059 0.15578947 0.06164384\n",
      " 0.07079646 0.10305344 0.08888889 0.         0.64166989 0.67525544\n",
      " 0.35508021 0.44272221 0.30557151 0.08629442 0.52553542 0.6560744\n",
      " 0.70772555 0.70052042 0.57662083 0.82209643 0.42455621 0.64841022\n",
      " 0.30457746 0.37416904 0.35465116 0.38230839 0.97986322 0.93158715\n",
      " 0.95124993]\n",
      "Training Epoch 28/300, Loss: 0.3097, Accuracy: 0.8645, F1: 0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95433713 0.86908078 0.821875   0.06779661 0.08       0.\n",
      " 0.         0.         0.         0.80163599 0.77572559 0.52892562\n",
      " 0.58913043 0.38297872 0.03703704 0.72475248 0.81281619 0.8576\n",
      " 0.80431177 0.60487805 0.80286561 0.5645933  0.76885043 0.18666667\n",
      " 0.19444444 0.50543478 0.45919779 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 28/300, Loss: 0.2520, Accuracy: 0.8988, F1: 0.5398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93574593 0.64536082 0.63576494 0.1592233  0.1399177  0.04761905\n",
      " 0.0477327  0.10093458 0.07881773 0.63816557 0.67938576 0.3736952\n",
      " 0.46554149 0.30520646 0.11049724 0.55447154 0.65885066 0.69337694\n",
      " 0.68536819 0.60675273 0.83196973 0.43781095 0.6329588  0.283054\n",
      " 0.34808853 0.34648868 0.37039257 0.97780596 0.92946679 0.94772364]\n",
      "Training Epoch 29/300, Loss: 0.3051, Accuracy: 0.8635, F1: 0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95402024 0.85945946 0.82089552 0.1        0.11764706 0.04545455\n",
      " 0.04878049 0.05797101 0.07017544 0.78762887 0.77044855 0.54341737\n",
      " 0.61401557 0.40458015 0.07272727 0.71345029 0.78850758 0.85897436\n",
      " 0.81031614 0.6557377  0.84514142 0.57017544 0.76889849 0.27807487\n",
      " 0.2967033  0.49307479 0.48459384 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 29/300, Loss: 0.2467, Accuracy: 0.9018, F1: 0.5610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93522818 0.64850707 0.66476979 0.13980583 0.156      0.04635762\n",
      " 0.03644647 0.10505837 0.09571788 0.64059445 0.68481772 0.39978735\n",
      " 0.45513281 0.30429594 0.15104167 0.5379538  0.65574402 0.71824104\n",
      " 0.68910206 0.61173049 0.82264529 0.41891892 0.65064282 0.2921147\n",
      " 0.35203095 0.3637946  0.37172932 0.97993798 0.92795209 0.9473124 ]\n",
      "Training Epoch 30/300, Loss: 0.3054, Accuracy: 0.8637, F1: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9547223  0.86021505 0.79885057 0.09677419 0.11320755 0.04444444\n",
      " 0.04878049 0.08571429 0.10169492 0.81656805 0.78010471 0.5297619\n",
      " 0.5825     0.41269841 0.10526316 0.71290944 0.78655199 0.84848485\n",
      " 0.80562448 0.65591398 0.83512249 0.55793991 0.73025641 0.29896907\n",
      " 0.32804233 0.48554913 0.45512821 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 30/300, Loss: 0.2432, Accuracy: 0.9011, F1: 0.5610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93425528 0.63022176 0.61413732 0.11860941 0.11889597 0.02033898\n",
      " 0.02358491 0.12734082 0.1037037  0.         0.63875598 0.68522676\n",
      " 0.36297071 0.45467836 0.29938787 0.09550562 0.53572887 0.65344995\n",
      " 0.72249589 0.70011256 0.5727003  0.81959126 0.44157815 0.64316682\n",
      " 0.29223744 0.36470588 0.33899297 0.35736291 0.98114401 0.93063007\n",
      " 0.94993475]\n",
      "Training Epoch 31/300, Loss: 0.3025, Accuracy: 0.8629, F1: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95090305 0.87179487 0.82295082 0.03448276 0.04081633 0.\n",
      " 0.         0.         0.         0.79268293 0.79775281 0.54599407\n",
      " 0.60204082 0.38709677 0.03636364 0.73663366 0.83065954 0.85668277\n",
      " 0.78961504 0.60606061 0.79854621 0.56338028 0.7680798  0.18791946\n",
      " 0.20833333 0.47633136 0.43157895 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 31/300, Loss: 0.2589, Accuracy: 0.8998, F1: 0.5378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93565365 0.6642562  0.66070059 0.15537849 0.14675052 0.01369863\n",
      " 0.049217   0.121673   0.11594203 0.         0.62602579 0.67021277\n",
      " 0.38692946 0.46361186 0.33196961 0.11518325 0.55461507 0.68176713\n",
      " 0.71563597 0.69802924 0.57675331 0.80585787 0.46848138 0.66487359\n",
      " 0.3312444  0.39805825 0.35840836 0.38649382 0.97947028 0.92964072\n",
      " 0.94962321]\n",
      "Training Epoch 32/300, Loss: 0.3021, Accuracy: 0.8641, F1: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95420013 0.87466667 0.84319527 0.09677419 0.11320755 0.04444444\n",
      " 0.04878049 0.05882353 0.07017544 0.81941748 0.7755102  0.54358974\n",
      " 0.56906077 0.34677419 0.10526316 0.73939394 0.82133333 0.85350318\n",
      " 0.80952381 0.64516129 0.82926829 0.52873563 0.65353038 0.27586207\n",
      " 0.30769231 0.49719101 0.48275862 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 32/300, Loss: 0.2453, Accuracy: 0.8979, F1: 0.5569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93633256 0.67717336 0.67387478 0.15537849 0.15157895 0.02622951\n",
      " 0.03539823 0.14339623 0.14       0.66666667 0.6929982  0.40963855\n",
      " 0.48275862 0.3429229  0.12834225 0.55793298 0.66718386 0.73234899\n",
      " 0.70502687 0.57637173 0.82731578 0.44642857 0.67446177 0.30384272\n",
      " 0.38204394 0.3525641  0.35729713 0.97934094 0.92951597 0.95024935]\n",
      "Training Epoch 33/300, Loss: 0.2981, Accuracy: 0.8670, F1: 0.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95328225 0.87362637 0.8375     0.09677419 0.11320755 0.08510638\n",
      " 0.04651163 0.05970149 0.07142857 0.79678068 0.78010471 0.54636591\n",
      " 0.57195915 0.31111111 0.03703704 0.74524715 0.8        0.84944532\n",
      " 0.80557834 0.67613636 0.83882149 0.56540084 0.69990593 0.23225806\n",
      " 0.26666667 0.49728261 0.49100257 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 33/300, Loss: 0.2450, Accuracy: 0.8985, F1: 0.5549\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93775418 0.6998993  0.68866286 0.16603774 0.14566929 0.04487179\n",
      " 0.0661157  0.12062257 0.13533835 0.         0.64584147 0.69167429\n",
      " 0.42386185 0.49768236 0.29154169 0.12041885 0.56831923 0.68237548\n",
      " 0.70802721 0.69632746 0.59032577 0.83607313 0.44362018 0.65961788\n",
      " 0.28926353 0.36153846 0.33880422 0.38144644 0.97979606 0.92746211\n",
      " 0.94546098]\n",
      "Training Epoch 34/300, Loss: 0.2909, Accuracy: 0.8688, F1: 0.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95574208 0.86792453 0.82647059 0.06896552 0.08163265 0.13043478\n",
      " 0.2173913  0.05797101 0.07017544 0.8097166  0.78453039 0.55014327\n",
      " 0.59854015 0.4214876  0.03636364 0.77354709 0.84093023 0.8672\n",
      " 0.81318681 0.59512195 0.81055276 0.5840708  0.78372093 0.19736842\n",
      " 0.23287671 0.51303155 0.47765794 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 34/300, Loss: 0.2453, Accuracy: 0.9041, F1: 0.5655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93800523 0.68852459 0.68243071 0.18943534 0.18761726 0.05660377\n",
      " 0.07835052 0.15564202 0.14795918 0.         0.65585168 0.68452111\n",
      " 0.43899949 0.49608355 0.32739805 0.13471503 0.54227642 0.68960302\n",
      " 0.72678331 0.69601276 0.60673029 0.8354797  0.43956044 0.67027027\n",
      " 0.30980752 0.38476562 0.38364964 0.40024631 0.97923525 0.9315376\n",
      " 0.95261905]\n",
      "Training Epoch 35/300, Loss: 0.2901, Accuracy: 0.8703, F1: 0.4971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9525359  0.87567568 0.82978723 0.03508772 0.04166667 0.04545455\n",
      " 0.04878049 0.05797101 0.07017544 0.80816327 0.80337079 0.57534247\n",
      " 0.63193658 0.45669291 0.14035088 0.77290837 0.83738318 0.8585209\n",
      " 0.80353982 0.68555241 0.82824088 0.58723404 0.75184794 0.25\n",
      " 0.28220859 0.50659631 0.47988506 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 35/300, Loss: 0.2417, Accuracy: 0.9041, F1: 0.5672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93832308 0.66084275 0.67579    0.19120459 0.18623482 0.04530744\n",
      " 0.07578947 0.16849817 0.13776722 0.         0.64728682 0.67593008\n",
      " 0.42379958 0.50699627 0.3470214  0.16489362 0.56586948 0.69305394\n",
      " 0.71562083 0.70162692 0.61796644 0.84368677 0.44933921 0.67154849\n",
      " 0.3143108  0.4        0.36105477 0.39387571 0.98080456 0.93207759\n",
      " 0.95293136]\n",
      "Training Epoch 36/300, Loss: 0.2879, Accuracy: 0.8703, F1: 0.4980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95499674 0.87912088 0.83540373 0.1        0.11764706 0.04545455\n",
      " 0.04878049 0.05714286 0.06896552 0.8039604  0.77284595 0.544\n",
      " 0.58823529 0.37606838 0.10526316 0.73877551 0.81826321 0.85486443\n",
      " 0.81511915 0.57411765 0.77785564 0.57657658 0.76346604 0.3125\n",
      " 0.34920635 0.5        0.47058824 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 36/300, Loss: 0.2416, Accuracy: 0.8976, F1: 0.5616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93538105 0.66666667 0.64751264 0.13412229 0.13250518 0.04560261\n",
      " 0.04017857 0.17120623 0.15267176 0.         0.65279383 0.66061706\n",
      " 0.39533705 0.4583038  0.31911163 0.10659898 0.56735857 0.68249951\n",
      " 0.72423098 0.68967711 0.57269591 0.81166837 0.46253602 0.65636788\n",
      " 0.33656388 0.41287879 0.36916716 0.38245083 0.98159509 0.9282953\n",
      " 0.9492431 ]\n",
      "Training Epoch 37/300, Loss: 0.2953, Accuracy: 0.8651, F1: 0.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94985707 0.88586957 0.83692308 0.06666667 0.07843137 0.04545455\n",
      " 0.04878049 0.02941176 0.03571429 0.80082136 0.81142857 0.57680251\n",
      " 0.61299435 0.4742268  0.14492754 0.76923077 0.8312611  0.86363636\n",
      " 0.79818182 0.67246377 0.8118263  0.57613169 0.73180459 0.25\n",
      " 0.26993865 0.49728261 0.44933921 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 37/300, Loss: 0.2479, Accuracy: 0.9011, F1: 0.5639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93754111 0.69234668 0.68640513 0.14342629 0.11666667 0.05980066\n",
      " 0.08823529 0.12750455 0.12587413 0.63962559 0.66636322 0.42121685\n",
      " 0.4909048  0.3429216  0.12532637 0.57756177 0.69266055 0.72211821\n",
      " 0.7031791  0.58869779 0.83167721 0.44819985 0.66955111 0.36108677\n",
      " 0.41944709 0.36400346 0.38756414 0.98234512 0.93064737 0.95246594]\n",
      "Training Epoch 38/300, Loss: 0.2894, Accuracy: 0.8689, F1: 0.5098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.955826   0.86842105 0.84151473 0.15625    0.21428571 0.04444444\n",
      " 0.04705882 0.05714286 0.06896552 0.81836327 0.78947368 0.54857143\n",
      " 0.60946095 0.456      0.10344828 0.73724008 0.7898773  0.85486443\n",
      " 0.81699346 0.66120219 0.84055556 0.544      0.69589041 0.32786885\n",
      " 0.35955056 0.52463382 0.50359712 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 38/300, Loss: 0.2356, Accuracy: 0.9026, F1: 0.5744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94044152 0.69877049 0.68430425 0.13207547 0.13645224 0.03833866\n",
      " 0.05773196 0.19593346 0.17931034 0.         0.63203807 0.6956912\n",
      " 0.45495722 0.52319888 0.33760446 0.17391304 0.60089322 0.72680818\n",
      " 0.73721055 0.7189419  0.60938272 0.83875574 0.44329133 0.66430304\n",
      " 0.3175151  0.39481001 0.34947491 0.36905127 0.98314075 0.93295915\n",
      " 0.95192193]\n",
      "Training Epoch 39/300, Loss: 0.2803, Accuracy: 0.8733, F1: 0.5006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95228614 0.875      0.83030303 0.15873016 0.21818182 0.12765957\n",
      " 0.23655914 0.05714286 0.06896552 0.81422925 0.77348066 0.59610028\n",
      " 0.66046512 0.44       0.13793103 0.74230769 0.80031822 0.84430177\n",
      " 0.81224152 0.67403315 0.84401034 0.59414226 0.76989247 0.30107527\n",
      " 0.34065934 0.48648649 0.45470693 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 39/300, Loss: 0.2402, Accuracy: 0.9048, F1: 0.5870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93982439 0.6923472  0.69826065 0.15       0.13709677 0.05095541\n",
      " 0.05833333 0.1598513  0.16786571 0.         0.63981043 0.69411765\n",
      " 0.44122216 0.52526215 0.31313131 0.13231552 0.58578431 0.71139091\n",
      " 0.71916152 0.70666246 0.61953854 0.84501062 0.44167278 0.66272189\n",
      " 0.34531113 0.43519395 0.37064965 0.39844683 0.98235852 0.93450599\n",
      " 0.95429049]\n",
      "Training Epoch 40/300, Loss: 0.2790, Accuracy: 0.8731, F1: 0.5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95575349 0.87331536 0.8290469  0.125      0.17857143 0.12765957\n",
      " 0.25531915 0.05797101 0.07017544 0.81746032 0.78804348 0.56218905\n",
      " 0.58381503 0.38866397 0.13793103 0.75708502 0.82758621 0.85483871\n",
      " 0.82392586 0.62       0.82739449 0.57723577 0.77412731 0.28915663\n",
      " 0.32298137 0.50363901 0.48622366 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 40/300, Loss: 0.2382, Accuracy: 0.9034, F1: 0.5804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93886832 0.70211668 0.69775831 0.18290258 0.18333333 0.05351171\n",
      " 0.05907173 0.12972973 0.14578588 0.         0.64599686 0.68391867\n",
      " 0.4318297  0.52681602 0.34506636 0.11891892 0.5782644  0.70193246\n",
      " 0.72445158 0.70586381 0.60238569 0.84071388 0.47280638 0.67466812\n",
      " 0.3514719  0.42296651 0.38561151 0.41045441 0.98274009 0.92709698\n",
      " 0.94748061]\n",
      "Training Epoch 41/300, Loss: 0.2806, Accuracy: 0.8722, F1: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95548192 0.875      0.82334869 0.06896552 0.08163265 0.04545455\n",
      " 0.04878049 0.05882353 0.07142857 0.80163599 0.78236915 0.55612245\n",
      " 0.59686888 0.37974684 0.10526316 0.79310345 0.83701188 0.86774194\n",
      " 0.81017257 0.62842893 0.8221942  0.59911894 0.77196885 0.30769231\n",
      " 0.33939394 0.52197802 0.48861912 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 41/300, Loss: 0.2382, Accuracy: 0.9035, F1: 0.5679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94060083 0.69367089 0.68349911 0.16427105 0.17094017 0.05405405\n",
      " 0.06868687 0.15298507 0.1498829  0.         0.65769231 0.68173599\n",
      " 0.43808533 0.54028659 0.35267349 0.10416667 0.59363673 0.71012806\n",
      " 0.72419355 0.70734427 0.62250996 0.85293199 0.46870451 0.69262966\n",
      " 0.34057341 0.42553191 0.38535871 0.4049459  0.98382    0.93493044\n",
      " 0.95103399]\n",
      "Training Epoch 42/300, Loss: 0.2768, Accuracy: 0.8754, F1: 0.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95234059 0.88767123 0.83076923 0.09836066 0.11538462 0.04545455\n",
      " 0.04878049 0.08450704 0.06779661 0.82330097 0.8        0.59116022\n",
      " 0.67520373 0.41048035 0.07142857 0.78244275 0.84303351 0.85308057\n",
      " 0.82630691 0.68786127 0.81238504 0.62831858 0.81359906 0.2962963\n",
      " 0.35675676 0.50793651 0.4619883  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 42/300, Loss: 0.2408, Accuracy: 0.9056, F1: 0.5790\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94041321 0.68255578 0.70394408 0.18560606 0.17898833 0.05351171\n",
      " 0.08033827 0.23722628 0.2412993  0.65258216 0.69798658 0.44693878\n",
      " 0.52954863 0.34657837 0.14250614 0.59042985 0.70872483 0.72163837\n",
      " 0.70277158 0.62145262 0.84845418 0.46998536 0.68051002 0.35154827\n",
      " 0.42348412 0.37657394 0.40812558 0.98454746 0.93580386 0.95399285]\n",
      "Training Epoch 43/300, Loss: 0.2760, Accuracy: 0.8753, F1: 0.5299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95583755 0.88948787 0.84730539 0.1        0.08       0.04545455\n",
      " 0.04878049 0.05797101 0.07017544 0.81081081 0.78740157 0.58291457\n",
      " 0.60381143 0.4        0.13793103 0.79150579 0.84090909 0.87106918\n",
      " 0.83599664 0.64       0.83897158 0.58227848 0.76604555 0.25925926\n",
      " 0.30573248 0.52091768 0.49035813 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 43/300, Loss: 0.2345, Accuracy: 0.9057, F1: 0.5720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9412685  0.68004115 0.6986653  0.1954023  0.19551935 0.03858521\n",
      " 0.0942623  0.19926199 0.16425121 0.         0.         0.65097726\n",
      " 0.69663942 0.44622311 0.53118621 0.36908002 0.14395887 0.5895859\n",
      " 0.73071612 0.72746667 0.71352033 0.64222002 0.8577391  0.46311176\n",
      " 0.68017525 0.36536797 0.46438483 0.38050499 0.41946207 0.98474534\n",
      " 0.92869175 0.95034786]\n",
      "Training Epoch 44/300, Loss: 0.2743, Accuracy: 0.8763, F1: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95739216 0.8787062  0.84532925 0.06779661 0.08       0.04545455\n",
      " 0.04878049 0.05882353 0.07142857 0.79841897 0.78627968 0.58469945\n",
      " 0.63397948 0.40692641 0.03571429 0.80155642 0.84658041 0.8802589\n",
      " 0.81427264 0.64893617 0.84038728 0.53874539 0.66446281 0.24203822\n",
      " 0.2745098  0.54747226 0.48894063 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 44/300, Loss: 0.2340, Accuracy: 0.9041, F1: 0.5629\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94073876 0.69148394 0.70247315 0.17408124 0.19521912 0.06349206\n",
      " 0.1023622  0.20072993 0.22014052 0.         0.         0.63952569\n",
      " 0.71550562 0.42414861 0.50374181 0.32236475 0.13367609 0.59201954\n",
      " 0.71706937 0.72407358 0.70753674 0.62622309 0.84720307 0.49073388\n",
      " 0.67197629 0.38136324 0.45437956 0.37760188 0.40832815 0.98517631\n",
      " 0.92759588 0.95074565]\n",
      "Training Epoch 45/300, Loss: 0.2741, Accuracy: 0.8745, F1: 0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95844584 0.87804878 0.83231707 0.06779661 0.08       0.13043478\n",
      " 0.2173913  0.05633803 0.06779661 0.82466281 0.79551821 0.56811594\n",
      " 0.62608696 0.46774194 0.10169492 0.79296875 0.85969616 0.8635634\n",
      " 0.83181442 0.62531017 0.82596473 0.58874459 0.79059351 0.31034483\n",
      " 0.33918129 0.51790634 0.48787879 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 45/300, Loss: 0.2336, Accuracy: 0.9090, F1: 0.5835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94166067 0.70391645 0.7009932  0.1873805  0.18503937 0.05298013\n",
      " 0.05       0.18939394 0.19117647 0.         0.64592359 0.71688082\n",
      " 0.41980402 0.49953789 0.32756757 0.15274463 0.59538951 0.72276657\n",
      " 0.72809829 0.71886912 0.62834876 0.84520909 0.48798252 0.68480474\n",
      " 0.37735849 0.45933014 0.39102384 0.41471963 0.98608225 0.93344146\n",
      " 0.9543123 ]\n",
      "Training Epoch 46/300, Loss: 0.2709, Accuracy: 0.8761, F1: 0.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9540989  0.87978142 0.83256528 0.1        0.11764706 0.16326531\n",
      " 0.28282828 0.08571429 0.06896552 0.82677165 0.79045093 0.5923913\n",
      " 0.65       0.46640316 0.10526316 0.79615385 0.85234306 0.864\n",
      " 0.83557047 0.67236467 0.82046679 0.60944206 0.78059537 0.26086957\n",
      " 0.32911392 0.54314721 0.51532033 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 46/300, Loss: 0.2328, Accuracy: 0.9075, F1: 0.5931\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94191315 0.70137825 0.6994701  0.18042226 0.17829457 0.03134796\n",
      " 0.0422833  0.23636364 0.20657277 0.63021243 0.66575342 0.45121951\n",
      " 0.5427715  0.34945931 0.13812155 0.61562998 0.74349158 0.73452033\n",
      " 0.72300469 0.63317073 0.84860457 0.46454414 0.67246692 0.37608319\n",
      " 0.45923149 0.38177624 0.39192041 0.98602895 0.93152052 0.95268702]\n",
      "Training Epoch 47/300, Loss: 0.2718, Accuracy: 0.8764, F1: 0.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95870884 0.86684073 0.83149171 0.06896552 0.08163265 0.08\n",
      " 0.19607843 0.05970149 0.07142857 0.8046875  0.76574307 0.57824934\n",
      " 0.63694268 0.42372881 0.07142857 0.79764244 0.8617306  0.85805423\n",
      " 0.82381729 0.65104167 0.84089162 0.59821429 0.80046136 0.26666667\n",
      " 0.30674847 0.54027261 0.48175182 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 47/300, Loss: 0.2356, Accuracy: 0.9074, F1: 0.5774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94178022 0.70423992 0.69793525 0.16917293 0.17307692 0.07854985\n",
      " 0.14104882 0.22018349 0.21495327 0.         0.65829528 0.70868978\n",
      " 0.46341463 0.55579146 0.36727689 0.16831683 0.61306931 0.71895679\n",
      " 0.73998387 0.72426297 0.62457171 0.84998195 0.45527273 0.67695067\n",
      " 0.39579685 0.46398503 0.38752914 0.40662086 0.98652732 0.92883428\n",
      " 0.94918072]\n",
      "Training Epoch 48/300, Loss: 0.2655, Accuracy: 0.8774, F1: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95254261 0.88409704 0.83053435 0.15625    0.18181818 0.15384615\n",
      " 0.25862069 0.11267606 0.06666667 0.82625483 0.79373368 0.59383754\n",
      " 0.65737515 0.49242424 0.15873016 0.81663516 0.85350318 0.86677368\n",
      " 0.82565492 0.67806268 0.81074481 0.61924686 0.78175896 0.3030303\n",
      " 0.34355828 0.52197071 0.49635036 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 48/300, Loss: 0.2330, Accuracy: 0.9061, F1: 0.6012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94160801 0.72179684 0.71189873 0.16342412 0.14516129 0.08099688\n",
      " 0.10462777 0.22058824 0.21395349 0.66096423 0.70462633 0.46035806\n",
      " 0.54724041 0.34353741 0.17857143 0.59422614 0.72855778 0.73734683\n",
      " 0.7293971  0.6321446  0.84750927 0.48215586 0.68737214 0.37861525\n",
      " 0.46993525 0.38627109 0.41330459 0.98715527 0.92914172 0.94951295]\n",
      "Training Epoch 49/300, Loss: 0.2663, Accuracy: 0.8777, F1: 0.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95871659 0.87533156 0.83982684 0.1        0.08       0.08333333\n",
      " 0.21052632 0.05882353 0.07017544 0.80851064 0.781491   0.59078591\n",
      " 0.64096916 0.46774194 0.13559322 0.79626168 0.84475282 0.87560582\n",
      " 0.83769634 0.66666667 0.84381223 0.57358491 0.71090909 0.23376623\n",
      " 0.30065359 0.54108723 0.5112426  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 49/300, Loss: 0.2283, Accuracy: 0.9075, F1: 0.5812\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94238184 0.70659898 0.69678063 0.15270019 0.15500945 0.09003215\n",
      " 0.0969163  0.24738676 0.23370787 0.         0.65599375 0.71565495\n",
      " 0.45679012 0.52830189 0.35178082 0.16587678 0.60576923 0.73698419\n",
      " 0.73504274 0.72447685 0.63477828 0.84659734 0.46764706 0.68103763\n",
      " 0.38556338 0.44817927 0.3941691  0.42067523 0.98465618 0.93264313\n",
      " 0.95013061]\n",
      "Training Epoch 50/300, Loss: 0.2653, Accuracy: 0.8776, F1: 0.5208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95834327 0.87634409 0.84740741 0.1        0.15384615 0.12765957\n",
      " 0.21052632 0.05797101 0.10344828 0.82600382 0.78947368 0.55045872\n",
      " 0.61757106 0.50583658 0.16129032 0.8030303  0.85968028 0.86942675\n",
      " 0.83161512 0.61616162 0.82950991 0.60444444 0.80373832 0.28235294\n",
      " 0.3452381  0.54851229 0.50220264 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 50/300, Loss: 0.2283, Accuracy: 0.9104, F1: 0.5927\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94240645 0.68586118 0.70030272 0.23134328 0.22857143 0.09009009\n",
      " 0.0952381  0.23928571 0.22624434 0.         0.         0.67057903\n",
      " 0.7388764  0.47248864 0.56089594 0.34825328 0.160401   0.61895079\n",
      " 0.74088827 0.72506596 0.72277684 0.64817518 0.85120439 0.49674149\n",
      " 0.68850679 0.40429338 0.49042146 0.39406054 0.40952955 0.98442132\n",
      " 0.92834425 0.94873012]\n",
      "Training Epoch 51/300, Loss: 0.2648, Accuracy: 0.8784, F1: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95445198 0.87399464 0.83506686 0.1875     0.25       0.04545455\n",
      " 0.04878049 0.08450704 0.10169492 0.82824427 0.80886427 0.6162465\n",
      " 0.65436654 0.48062016 0.12903226 0.81310212 0.84552846 0.87220447\n",
      " 0.82900627 0.68493151 0.83657143 0.6212766  0.7963595  0.25641026\n",
      " 0.2781457  0.54993515 0.50437318 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 51/300, Loss: 0.2318, Accuracy: 0.9096, F1: 0.5928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94266301 0.7136294  0.71247199 0.15057915 0.20952381 0.05047319\n",
      " 0.0698152  0.28007181 0.29090909 0.         0.6543015  0.70567376\n",
      " 0.45619335 0.54071511 0.35256065 0.17199017 0.61483254 0.72695244\n",
      " 0.73770927 0.71789137 0.64296152 0.85102041 0.46928201 0.67645398\n",
      " 0.36660617 0.44572526 0.39025788 0.39975736 0.98561333 0.93094629\n",
      " 0.95111798]\n",
      "Training Epoch 52/300, Loss: 0.2629, Accuracy: 0.8778, F1: 0.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95672962 0.88346883 0.83536585 0.23880597 0.27586207 0.04545455\n",
      " 0.04878049 0.05797101 0.10526316 0.82421875 0.80547945 0.58765432\n",
      " 0.62040816 0.39647577 0.10714286 0.8038835  0.85165794 0.85981308\n",
      " 0.82644628 0.65053763 0.8374761  0.58666667 0.80046404 0.25316456\n",
      " 0.33333333 0.54927727 0.50615595 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 52/300, Loss: 0.2301, Accuracy: 0.9084, F1: 0.5882\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94356882 0.71485944 0.71670823 0.19734345 0.23333333 0.08360129\n",
      " 0.11764706 0.24231465 0.27293065 0.65129007 0.72232305 0.46565657\n",
      " 0.5484242  0.36191537 0.18414322 0.62574731 0.74951978 0.73779193\n",
      " 0.73453406 0.65433301 0.86190428 0.4904271  0.70261194 0.37163375\n",
      " 0.46816479 0.40150637 0.43887531 0.98690011 0.93213573 0.95388654]\n",
      "Training Epoch 53/300, Loss: 0.2596, Accuracy: 0.8816, F1: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95791189 0.86387435 0.83661972 0.19047619 0.25454545 0.08888889\n",
      " 0.11764706 0.05797101 0.07017544 0.80933852 0.79487179 0.59640103\n",
      " 0.63061224 0.47773279 0.16949153 0.80152672 0.83809524 0.875\n",
      " 0.83837511 0.65745856 0.84920635 0.61538462 0.80496054 0.33526012\n",
      " 0.40462428 0.54975124 0.49758454 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 53/300, Loss: 0.2256, Accuracy: 0.9094, F1: 0.5994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94386315 0.71039354 0.72103659 0.21789883 0.22309198 0.07207207\n",
      " 0.13282732 0.29432624 0.28699552 0.66666667 0.72476656 0.46592065\n",
      " 0.54417952 0.38975501 0.17241379 0.63081862 0.74577588 0.73924588\n",
      " 0.73752914 0.65726787 0.86107444 0.49373618 0.70301451 0.4137931\n",
      " 0.48934198 0.38958032 0.41702921 0.98613737 0.93026447 0.95231859]\n",
      "Training Epoch 54/300, Loss: 0.2580, Accuracy: 0.8819, F1: 0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95800619 0.88108108 0.83180428 0.23880597 0.27586207 0.04545455\n",
      " 0.04878049 0.05797101 0.07017544 0.82539683 0.80645161 0.60540541\n",
      " 0.64200218 0.5234375  0.21538462 0.8        0.84380306 0.85532591\n",
      " 0.82786885 0.65066667 0.82223416 0.59130435 0.80133929 0.32142857\n",
      " 0.39285714 0.55930087 0.50652742 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 54/300, Loss: 0.2270, Accuracy: 0.9085, F1: 0.5999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94302773 0.71311475 0.71097684 0.19678715 0.18295218 0.10932476\n",
      " 0.15686275 0.27338129 0.28571429 0.         0.64619067 0.69327146\n",
      " 0.4662197  0.55337482 0.36273429 0.19559902 0.63103311 0.74161659\n",
      " 0.73308471 0.72721559 0.62481752 0.84933733 0.49241877 0.70243545\n",
      " 0.40391459 0.48106061 0.40601931 0.43100868 0.98708173 0.93428108\n",
      " 0.95381131]\n",
      "Training Epoch 55/300, Loss: 0.2597, Accuracy: 0.8807, F1: 0.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95764264 0.89247312 0.83890578 0.16129032 0.15384615 0.04545455\n",
      " 0.04878049 0.1369863  0.06666667 0.82191781 0.80108992 0.57647059\n",
      " 0.6259542  0.46025105 0.06896552 0.80998081 0.84622222 0.86666667\n",
      " 0.84087102 0.67032967 0.84494124 0.57983193 0.77238403 0.32298137\n",
      " 0.37267081 0.54241338 0.49144254 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 55/300, Loss: 0.2282, Accuracy: 0.9099, F1: 0.5872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94436128 0.7456446  0.74041727 0.19961612 0.22265625 0.09302326\n",
      " 0.11481481 0.26642984 0.29464286 0.         0.63873518 0.71699779\n",
      " 0.47764228 0.57023644 0.38156484 0.17171717 0.62384585 0.74074074\n",
      " 0.74030802 0.73442623 0.64607843 0.86163714 0.4745509  0.67968024\n",
      " 0.40286482 0.50374532 0.40057143 0.42839879 0.9873338  0.93244339\n",
      " 0.95252279]\n",
      "Training Epoch 56/300, Loss: 0.2559, Accuracy: 0.8821, F1: 0.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95814574 0.88       0.84927536 0.18461538 0.24561404 0.08695652\n",
      " 0.18181818 0.11428571 0.06896552 0.82213439 0.80540541 0.58789625\n",
      " 0.63333333 0.51162791 0.16129032 0.81142857 0.85590278 0.86071987\n",
      " 0.8369028  0.67024129 0.83444075 0.59414226 0.78833693 0.35955056\n",
      " 0.44444444 0.52885906 0.49560117 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 56/300, Loss: 0.2250, Accuracy: 0.9115, F1: 0.6057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94547921 0.72126144 0.71260336 0.17373737 0.15513627 0.10682493\n",
      " 0.12972973 0.2831216  0.27990971 0.         0.66096423 0.74571805\n",
      " 0.47       0.54060325 0.35133599 0.16020672 0.64636076 0.73611929\n",
      " 0.74940586 0.74033323 0.64965653 0.86663931 0.50687907 0.71078876\n",
      " 0.38112523 0.46418338 0.40205891 0.42990093 0.98790932 0.93638518\n",
      " 0.95483024]\n",
      "Training Epoch 57/300, Loss: 0.2544, Accuracy: 0.8833, F1: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9577827  0.89066667 0.84705882 0.18181818 0.24137931 0.15384615\n",
      " 0.28333333 0.15584416 0.20895522 0.82666667 0.81382979 0.60344828\n",
      " 0.64987406 0.52777778 0.28985507 0.80075188 0.84806867 0.87220447\n",
      " 0.84110535 0.66666667 0.84248879 0.59919028 0.77731092 0.4\n",
      " 0.4742268  0.51788269 0.5224359  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 57/300, Loss: 0.2246, Accuracy: 0.9121, F1: 0.6264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94467885 0.71763507 0.72736368 0.15355086 0.1980198  0.11428571\n",
      " 0.16771488 0.28       0.2706422  0.         0.6753634  0.72879121\n",
      " 0.4822335  0.56487119 0.36311239 0.13903743 0.65931469 0.73850968\n",
      " 0.74387646 0.72476056 0.65245414 0.86641672 0.4882227  0.69740425\n",
      " 0.43448276 0.5202952  0.41556987 0.4363419  0.98684459 0.92964949\n",
      " 0.95153031]\n",
      "Training Epoch 58/300, Loss: 0.2544, Accuracy: 0.8830, F1: 0.5411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95871483 0.88359788 0.84659091 0.18461538 0.24561404 0.08510638\n",
      " 0.21978022 0.11267606 0.1        0.82283465 0.8021978  0.5989011\n",
      " 0.64441887 0.47154472 0.13559322 0.80998081 0.84730803 0.87640449\n",
      " 0.8349345  0.6576087  0.84353365 0.57575758 0.73653846 0.275\n",
      " 0.37267081 0.55897436 0.51724138 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 58/300, Loss: 0.2262, Accuracy: 0.9106, F1: 0.6005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94446449 0.72517553 0.74332344 0.18687873 0.20825147 0.12461059\n",
      " 0.16796875 0.28671329 0.3257732  0.         0.66590909 0.70741573\n",
      " 0.49850449 0.57766659 0.356974   0.20942408 0.6209073  0.73804897\n",
      " 0.74822041 0.72941176 0.65658537 0.86267696 0.53013798 0.71107866\n",
      " 0.4460177  0.50698975 0.40992018 0.42774213 0.9865793  0.9274802\n",
      " 0.94854162]\n",
      "Training Epoch 59/300, Loss: 0.2535, Accuracy: 0.8830, F1: 0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95760418 0.87139108 0.85390071 0.23880597 0.27586207 0.08510638\n",
      " 0.18181818 0.08571429 0.10169492 0.8046875  0.80927835 0.58064516\n",
      " 0.62686567 0.5037594  0.24242424 0.78058252 0.83485477 0.83333333\n",
      " 0.80030488 0.68681319 0.85102788 0.59437751 0.76523477 0.38\n",
      " 0.4368932  0.55771725 0.5242236  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 59/300, Loss: 0.2251, Accuracy: 0.9075, F1: 0.6088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94324857 0.70186335 0.7196738  0.23146474 0.24       0.06514658\n",
      " 0.08558559 0.33219178 0.31600832 0.         0.66794479 0.71985816\n",
      " 0.46573931 0.54695462 0.36716583 0.20902613 0.64305392 0.74533205\n",
      " 0.74927036 0.73584608 0.64586429 0.85884874 0.5        0.69150257\n",
      " 0.44230769 0.5369863  0.41049294 0.41718171 0.98549994 0.93088822\n",
      " 0.95252279]\n",
      "Training Epoch 60/300, Loss: 0.2574, Accuracy: 0.8815, F1: 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95460024 0.899729   0.84307692 0.20895522 0.24561404 0.08695652\n",
      " 0.11363636 0.11267606 0.1        0.8247012  0.79575597 0.61095101\n",
      " 0.65286236 0.51879699 0.15873016 0.8173258  0.84757709 0.87598116\n",
      " 0.8441331  0.70588235 0.84295062 0.60082305 0.78085106 0.37988827\n",
      " 0.46153846 0.54545455 0.50678733 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 60/300, Loss: 0.2276, Accuracy: 0.9111, F1: 0.6111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94510018 0.71715145 0.7251813  0.17537313 0.1744186  0.10031348\n",
      " 0.12144213 0.33507853 0.34782609 0.6566358  0.72586521 0.47357513\n",
      " 0.57325444 0.3838941  0.17847769 0.62038873 0.74653503 0.75178053\n",
      " 0.74366547 0.64582316 0.86171895 0.5143277  0.71884164 0.43617021\n",
      " 0.53515982 0.42165899 0.44220183 0.98579276 0.93352457 0.95102235]\n",
      "Training Epoch 61/300, Loss: 0.2523, Accuracy: 0.8845, F1: 0.5647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95541793 0.89487871 0.83870968 0.19354839 0.25925926 0.08695652\n",
      " 0.16091954 0.1369863  0.06666667 0.83106796 0.80225989 0.6180758\n",
      " 0.65736041 0.51636364 0.21538462 0.83271375 0.84951024 0.87319422\n",
      " 0.83363472 0.63852243 0.83236994 0.62337662 0.80701754 0.35928144\n",
      " 0.42857143 0.52320675 0.50157729 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 61/300, Loss: 0.2307, Accuracy: 0.9114, F1: 0.6112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94557275 0.7307118  0.72892603 0.23817863 0.2541806  0.09815951\n",
      " 0.1027668  0.26325411 0.27927928 0.66563826 0.73992025 0.49371543\n",
      " 0.59518804 0.40133779 0.19240506 0.64040961 0.75804897 0.73993644\n",
      " 0.73874725 0.67347932 0.86441712 0.50551065 0.7090566  0.42778793\n",
      " 0.52540748 0.42593628 0.44358898 0.98672204 0.937882   0.95636059]\n",
      "Training Epoch 62/300, Loss: 0.2483, Accuracy: 0.8854, F1: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95891803 0.87598945 0.85227273 0.24242424 0.28070175 0.08888889\n",
      " 0.11764706 0.10810811 0.13114754 0.82170543 0.81081081 0.58181818\n",
      " 0.6185567  0.45378151 0.16949153 0.80834915 0.8537415  0.85804416\n",
      " 0.82994304 0.61306533 0.83133452 0.58091286 0.78074866 0.38202247\n",
      " 0.46153846 0.54808959 0.51362984 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 62/300, Loss: 0.2259, Accuracy: 0.9087, F1: 0.6057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94596659 0.71327254 0.71644042 0.21343874 0.23809524 0.09345794\n",
      " 0.12653061 0.33571429 0.38626609 0.66767372 0.73090586 0.51877817\n",
      " 0.5987025  0.37183099 0.20705882 0.64551943 0.75702734 0.75528541\n",
      " 0.74598472 0.64180569 0.85912334 0.50536865 0.70696833 0.42334495\n",
      " 0.5077343  0.42263083 0.44802867 0.98689351 0.93438124 0.95311848]\n",
      "Training Epoch 63/300, Loss: 0.2487, Accuracy: 0.8850, F1: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9585381  0.88594164 0.84927536 0.21538462 0.25       0.25\n",
      " 0.37241379 0.13333333 0.15625    0.83491461 0.82191781 0.62702703\n",
      " 0.6779661  0.52075472 0.21538462 0.80827068 0.84736842 0.87341772\n",
      " 0.84283247 0.67605634 0.84071575 0.60629921 0.74829932 0.3880597\n",
      " 0.45192308 0.54495913 0.52418097 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 63/300, Loss: 0.2207, Accuracy: 0.9123, F1: 0.6306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94552281 0.72662602 0.73274336 0.23818526 0.24427481 0.14243323\n",
      " 0.16764133 0.30335097 0.28265525 0.65832682 0.69371378 0.49407115\n",
      " 0.59445958 0.38391846 0.15957447 0.64028492 0.75128841 0.75763207\n",
      " 0.74070543 0.65056678 0.866265   0.52463768 0.71328671 0.43024302\n",
      " 0.53045923 0.41976711 0.43902439 0.98816717 0.93071406 0.94954891]\n",
      "Training Epoch 64/300, Loss: 0.2463, Accuracy: 0.8850, F1: 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95885039 0.88770053 0.83604136 0.23529412 0.27118644 0.16\n",
      " 0.21052632 0.16216216 0.15873016 0.82217973 0.79683377 0.60477454\n",
      " 0.65505985 0.49011858 0.22222222 0.7948244  0.84139101 0.86604361\n",
      " 0.84317032 0.65951743 0.85230428 0.61883408 0.81481481 0.40625\n",
      " 0.47236181 0.54787234 0.54005935 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 64/300, Loss: 0.2208, Accuracy: 0.9130, F1: 0.6242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94548396 0.74077817 0.74070326 0.18691589 0.18846154 0.0960961\n",
      " 0.1187384  0.3202847  0.32119914 0.         0.65891473 0.69631626\n",
      " 0.50152284 0.57614508 0.39435146 0.20093458 0.64785374 0.74415888\n",
      " 0.74699439 0.7429472  0.67255768 0.87678756 0.53521127 0.73267327\n",
      " 0.43893805 0.52816251 0.43210931 0.45143555 0.98988249 0.92796108\n",
      " 0.94819913]\n",
      "Training Epoch 65/300, Loss: 0.2470, Accuracy: 0.8858, F1: 0.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95529312 0.89304813 0.84131737 0.19354839 0.22641509 0.08888889\n",
      " 0.11764706 0.16       0.1875     0.82235529 0.80112045 0.61408451\n",
      " 0.65779927 0.52238806 0.1875     0.82285714 0.8625     0.87203791\n",
      " 0.84174508 0.67403315 0.84485231 0.62337662 0.80507497 0.36686391\n",
      " 0.45086705 0.54497354 0.5230312  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 65/300, Loss: 0.2264, Accuracy: 0.9123, F1: 0.6166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94440462 0.71285141 0.71783518 0.20384615 0.2659176  0.13489736\n",
      " 0.12280702 0.32085561 0.34408602 0.         0.65582656 0.71200365\n",
      " 0.50051493 0.58464428 0.41341991 0.19095477 0.65189873 0.74318005\n",
      " 0.75504323 0.73728681 0.64870162 0.85582775 0.52468681 0.70673885\n",
      " 0.43715847 0.51730769 0.40948884 0.43241609 0.98930683 0.93040659\n",
      " 0.94927321]\n",
      "Training Epoch 66/300, Loss: 0.2500, Accuracy: 0.8835, F1: 0.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95972189 0.89247312 0.83880597 0.20895522 0.24561404 0.08695652\n",
      " 0.18181818 0.13513514 0.19047619 0.81763527 0.79338843 0.59610028\n",
      " 0.65357968 0.50746269 0.21875    0.8021978  0.83924155 0.87640449\n",
      " 0.83539823 0.63049096 0.8337717  0.59322034 0.81026786 0.36686391\n",
      " 0.44444444 0.55497382 0.53576438 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 66/300, Loss: 0.2256, Accuracy: 0.9121, F1: 0.6149\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94666723 0.74230963 0.75100806 0.21621622 0.22504537 0.11214953\n",
      " 0.12170385 0.29929577 0.33898305 0.65315666 0.71931408 0.50225564\n",
      " 0.59649123 0.3656148  0.19806763 0.6490952  0.7532567  0.75026344\n",
      " 0.73983235 0.65707196 0.86883064 0.53400868 0.72946412 0.47284879\n",
      " 0.55785838 0.41576242 0.42865636 0.9890027  0.93101297 0.95293136]\n",
      "Training Epoch 67/300, Loss: 0.2454, Accuracy: 0.8865, F1: 0.5739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95714523 0.89839572 0.84355828 0.21212121 0.25       0.08888889\n",
      " 0.11764706 0.16216216 0.19047619 0.82758621 0.80991736 0.60962567\n",
      " 0.65914221 0.51094891 0.21875    0.7992126  0.84047402 0.87640449\n",
      " 0.84291845 0.69060773 0.85094067 0.62601626 0.80593849 0.28\n",
      " 0.36       0.5331565  0.5308311  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 67/300, Loss: 0.2269, Accuracy: 0.9123, F1: 0.6130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9457462  0.72468193 0.73480663 0.20925553 0.22810591 0.11585366\n",
      " 0.14396887 0.36456559 0.30578512 0.         0.         0.65205479\n",
      " 0.7063129  0.50630358 0.59871703 0.40906638 0.21287129 0.64906832\n",
      " 0.75376506 0.74341044 0.74230348 0.65600775 0.87040993 0.51457726\n",
      " 0.70340357 0.41748439 0.49484536 0.41678322 0.44276583 0.9896259\n",
      " 0.93013972 0.95204094]\n",
      "Training Epoch 68/300, Loss: 0.2440, Accuracy: 0.8853, F1: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95762124 0.8972973  0.84307692 0.23188406 0.27118644 0.16326531\n",
      " 0.13207547 0.13513514 0.18461538 0.81510934 0.79889807 0.62755102\n",
      " 0.65556712 0.5037037  0.1875     0.81904762 0.85136324 0.8719611\n",
      " 0.83348018 0.67567568 0.85088458 0.59836066 0.78630705 0.4\n",
      " 0.46575342 0.53972603 0.52380952 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 68/300, Loss: 0.2233, Accuracy: 0.9113, F1: 0.6206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94586921 0.73047859 0.73731567 0.19455253 0.24505929 0.14723926\n",
      " 0.15257732 0.31448763 0.31277533 0.         0.65275591 0.74050916\n",
      " 0.50562948 0.58782689 0.39827307 0.20671835 0.65753425 0.74348581\n",
      " 0.74912985 0.74365482 0.64668305 0.8642303  0.51461988 0.69743033\n",
      " 0.45989305 0.56108597 0.43311743 0.45930749 0.98918239 0.93290097\n",
      " 0.95161099]\n",
      "Training Epoch 69/300, Loss: 0.2457, Accuracy: 0.8862, F1: 0.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9542035  0.89655172 0.83812405 0.1875     0.22222222 0.16666667\n",
      " 0.15384615 0.18666667 0.15873016 0.82490272 0.81232493 0.61452514\n",
      " 0.66666667 0.50746269 0.16393443 0.82011605 0.85067873 0.86708861\n",
      " 0.84010372 0.7008547  0.8329784  0.64377682 0.81609195 0.3908046\n",
      " 0.47191011 0.54098361 0.51083591 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 69/300, Loss: 0.2323, Accuracy: 0.9119, F1: 0.6213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94677833 0.74308698 0.74603562 0.25373134 0.25602968 0.09411765\n",
      " 0.11460259 0.3630137  0.33196721 0.67259374 0.72202166 0.52008032\n",
      " 0.59550307 0.40618337 0.24766355 0.65580286 0.76875363 0.75550836\n",
      " 0.74782609 0.64081435 0.86656824 0.48812095 0.68371317 0.46450482\n",
      " 0.55423883 0.42836879 0.46186186 0.98811993 0.93277625 0.95252279]\n",
      "Training Epoch 70/300, Loss: 0.2440, Accuracy: 0.8867, F1: 0.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95897074 0.87765957 0.8483965  0.26865672 0.24561404 0.23333333\n",
      " 0.25       0.16438356 0.16393443 0.81746032 0.81743869 0.58\n",
      " 0.62170088 0.47257384 0.16666667 0.80446927 0.84062758 0.86071987\n",
      " 0.83591837 0.6010101  0.82792125 0.59227468 0.79734219 0.2745098\n",
      " 0.35526316 0.56019656 0.5138539  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 70/300, Loss: 0.2283, Accuracy: 0.9069, F1: 0.6116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94649101 0.73594378 0.74204061 0.22727273 0.26788991 0.13333333\n",
      " 0.18882466 0.3447099  0.33402062 0.67692308 0.72877467 0.51212121\n",
      " 0.5929078  0.39647577 0.2396088  0.64943204 0.76106885 0.77077288\n",
      " 0.75484786 0.65063788 0.8668886  0.53466762 0.7159447  0.43229167\n",
      " 0.51785714 0.43138358 0.46547619 0.99096159 0.93157008 0.9515083 ]\n",
      "Training Epoch 71/300, Loss: 0.2424, Accuracy: 0.8879, F1: 0.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96103459 0.88654354 0.85545723 0.31428571 0.27118644 0.08695652\n",
      " 0.11363636 0.16       0.19047619 0.8172888  0.79459459 0.59776536\n",
      " 0.64916468 0.49795918 0.16129032 0.81818182 0.86115993 0.87440382\n",
      " 0.84687767 0.61691542 0.83004358 0.62931034 0.82568807 0.37804878\n",
      " 0.45783133 0.57387057 0.5218543  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 71/300, Loss: 0.2232, Accuracy: 0.9135, F1: 0.6197\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94771431 0.72764228 0.75462269 0.25373134 0.30018083 0.09202454\n",
      " 0.1496063  0.31597222 0.34226804 0.         0.67342167 0.70630631\n",
      " 0.51225613 0.60009289 0.39460916 0.18886199 0.6713948  0.76982893\n",
      " 0.75577731 0.74503106 0.67900633 0.87724705 0.52631579 0.70950027\n",
      " 0.46006944 0.55615942 0.43856655 0.46359584 0.98881066 0.9354537\n",
      " 0.95381682]\n",
      "Training Epoch 72/300, Loss: 0.2388, Accuracy: 0.8893, F1: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95903086 0.89487871 0.84194529 0.28985507 0.27118644 0.08888889\n",
      " 0.11764706 0.15789474 0.18461538 0.81782946 0.78787879 0.61538462\n",
      " 0.67070218 0.5631769  0.28571429 0.82442748 0.86123545 0.86750789\n",
      " 0.83898305 0.67945205 0.85495316 0.6097561  0.80130293 0.30065359\n",
      " 0.41558442 0.56070088 0.52369077 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 72/300, Loss: 0.2235, Accuracy: 0.9143, F1: 0.6228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94761827 0.7245935  0.74748491 0.2519084  0.26102941 0.11143695\n",
      " 0.15270019 0.32937182 0.32454361 0.         0.67535454 0.74050916\n",
      " 0.52212829 0.58974948 0.40485383 0.19847328 0.65244375 0.76146964\n",
      " 0.75621118 0.7559249  0.66959922 0.87157464 0.50400583 0.70843373\n",
      " 0.48415493 0.5620438  0.43226177 0.484375   0.98917967 0.93310057\n",
      " 0.95240362]\n",
      "Training Epoch 73/300, Loss: 0.2398, Accuracy: 0.8890, F1: 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95632641 0.89361702 0.83783784 0.22222222 0.25925926 0.16\n",
      " 0.1875     0.1369863  0.16129032 0.82283465 0.81460674 0.59940653\n",
      " 0.64673913 0.54135338 0.23880597 0.81593928 0.85053381 0.86929134\n",
      " 0.83520276 0.66129032 0.84490146 0.62711864 0.81540204 0.4\n",
      " 0.47368421 0.54278075 0.53129771 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 73/300, Loss: 0.2279, Accuracy: 0.9132, F1: 0.6248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94777818 0.70564516 0.72163426 0.22264151 0.23465704 0.09970674\n",
      " 0.13620072 0.33684211 0.36585366 0.67409685 0.72907679 0.49772842\n",
      " 0.58614232 0.38470191 0.18719212 0.66954136 0.78790229 0.75429464\n",
      " 0.74649205 0.67943054 0.88109363 0.53191489 0.73247033 0.43591979\n",
      " 0.55921638 0.43352273 0.45976313 0.99089825 0.93314207 0.9530673 ]\n",
      "Training Epoch 74/300, Loss: 0.2402, Accuracy: 0.8891, F1: 0.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96146833 0.88481675 0.84559885 0.24242424 0.28070175 0.23529412\n",
      " 0.26530612 0.18421053 0.1875     0.83172147 0.81666667 0.6091954\n",
      " 0.65660377 0.58992806 0.36111111 0.81749049 0.86067019 0.87345679\n",
      " 0.84723369 0.64102564 0.83894737 0.60683761 0.81431767 0.40206186\n",
      " 0.46766169 0.55862978 0.52906977 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 74/300, Loss: 0.2207, Accuracy: 0.9157, F1: 0.6403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9474492  0.72966145 0.73517588 0.22437137 0.24952015 0.14925373\n",
      " 0.23119266 0.37651123 0.35146444 0.         0.66817667 0.71359008\n",
      " 0.49319213 0.56948994 0.40222222 0.19093079 0.66069342 0.75718419\n",
      " 0.75392392 0.75206226 0.6679803  0.87780574 0.54242204 0.72956909\n",
      " 0.42696629 0.51880424 0.44431914 0.48563814 0.98962721 0.93009043\n",
      " 0.95083135]\n",
      "Training Epoch 75/300, Loss: 0.2385, Accuracy: 0.8886, F1: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95908558 0.88359788 0.84240688 0.23188406 0.26666667 0.2\n",
      " 0.23157895 0.18421053 0.19047619 0.81765835 0.79778393 0.61494253\n",
      " 0.66996292 0.5204461  0.21538462 0.80075188 0.83752094 0.88151659\n",
      " 0.83899043 0.62886598 0.82964543 0.61044177 0.77754678 0.37569061\n",
      " 0.45989305 0.54232425 0.52287582 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 75/300, Loss: 0.2228, Accuracy: 0.9124, F1: 0.6243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94683411 0.71881391 0.7365224  0.20408163 0.23400366 0.11242604\n",
      " 0.14615385 0.40347826 0.39834025 0.6656558  0.72062905 0.51386139\n",
      " 0.59333182 0.38841567 0.16410256 0.66087643 0.76050255 0.75606574\n",
      " 0.74635294 0.67779961 0.87353824 0.50664697 0.7132216  0.46875\n",
      " 0.56580125 0.43514879 0.47117354 0.99057552 0.93202794 0.95232427]\n",
      "Training Epoch 76/300, Loss: 0.2393, Accuracy: 0.8880, F1: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95904651 0.8806366  0.84750733 0.31168831 0.26470588 0.25925926\n",
      " 0.20560748 0.25641026 0.16129032 0.80234834 0.78304239 0.60453401\n",
      " 0.62089552 0.4743083  0.19354839 0.81564246 0.84551495 0.8676236\n",
      " 0.84245998 0.66666667 0.85675082 0.62641509 0.7696793  0.4\n",
      " 0.4742268  0.55570839 0.53815261 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 76/300, Loss: 0.2228, Accuracy: 0.9109, F1: 0.6294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94716515 0.71797418 0.72515188 0.22612086 0.2332696  0.16091954\n",
      " 0.19188192 0.38095238 0.396      0.65362486 0.71873547 0.50631632\n",
      " 0.60194625 0.39461883 0.17821782 0.66036993 0.76196033 0.75171685\n",
      " 0.7482104  0.67677262 0.87790906 0.50399419 0.71496123 0.46457399\n",
      " 0.57297297 0.43694196 0.47048458 0.99083605 0.92865162 0.94878642]\n",
      "Training Epoch 77/300, Loss: 0.2403, Accuracy: 0.8883, F1: 0.5847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95870992 0.90374332 0.85454545 0.23880597 0.27118644 0.27118644\n",
      " 0.4084507  0.18421053 0.1875     0.82616822 0.823219   0.62087912\n",
      " 0.67291911 0.48360656 0.1        0.82442748 0.85790885 0.87658228\n",
      " 0.85185185 0.67759563 0.85007194 0.63636364 0.82212581 0.30263158\n",
      " 0.40522876 0.56850192 0.53372434 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 77/300, Loss: 0.2224, Accuracy: 0.9156, F1: 0.6337\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94792222 0.70618034 0.74148989 0.23897059 0.24956063 0.15430267\n",
      " 0.20229008 0.33922261 0.34893617 0.67947269 0.72636816 0.52459016\n",
      " 0.60575139 0.4056338  0.19753086 0.66003976 0.76715543 0.75444096\n",
      " 0.75309789 0.66930302 0.87522641 0.50708215 0.71428571 0.46045694\n",
      " 0.56727273 0.43736018 0.48192057 0.99018868 0.92713662 0.94936408]\n",
      "Training Epoch 78/300, Loss: 0.2367, Accuracy: 0.8895, F1: 0.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95784237 0.88235294 0.83382789 0.23880597 0.27586207 0.17857143\n",
      " 0.22222222 0.15789474 0.18461538 0.82945736 0.80314961 0.63414634\n",
      " 0.67785235 0.55033557 0.28985507 0.82862524 0.85886403 0.87459807\n",
      " 0.83542039 0.67560322 0.8554489  0.64102564 0.81944444 0.28378378\n",
      " 0.3537415  0.54790823 0.53846154 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 78/300, Loss: 0.2254, Accuracy: 0.9141, F1: 0.6276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94838674 0.74848485 0.7549195  0.24015009 0.23550725 0.07361963\n",
      " 0.13333333 0.39655172 0.3551797  0.65370885 0.72084481 0.53044791\n",
      " 0.61862581 0.39828234 0.25454545 0.64815549 0.77216397 0.74691196\n",
      " 0.75392996 0.67377605 0.87792181 0.53662074 0.72811745 0.44818423\n",
      " 0.55166217 0.44394619 0.48621701 0.99069884 0.93401522 0.95282345]\n",
      "Training Epoch 79/300, Loss: 0.2323, Accuracy: 0.8910, F1: 0.5869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9597354  0.89839572 0.85542169 0.28985507 0.28070175 0.24\n",
      " 0.20618557 0.20779221 0.19047619 0.8219697  0.80952381 0.609375\n",
      " 0.65668449 0.47302905 0.10526316 0.82954545 0.86510009 0.87636933\n",
      " 0.8487395  0.65240642 0.84448161 0.62660944 0.82460137 0.35928144\n",
      " 0.46511628 0.57534247 0.5370138  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 79/300, Loss: 0.2197, Accuracy: 0.9144, F1: 0.6302\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94871439 0.72773025 0.74638569 0.20817844 0.25132743 0.1958457\n",
      " 0.22350674 0.40666667 0.36470588 0.67645922 0.73248127 0.51125563\n",
      " 0.61563145 0.42481598 0.23340961 0.66510903 0.77420597 0.74915343\n",
      " 0.74761979 0.67809897 0.87482029 0.51322373 0.71397695 0.46902655\n",
      " 0.57323689 0.44294926 0.45440867 0.98924055 0.93376575 0.95560203]\n",
      "Training Epoch 80/300, Loss: 0.2326, Accuracy: 0.8902, F1: 0.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95900894 0.87272727 0.83569405 0.23880597 0.28070175 0.16666667\n",
      " 0.15384615 0.18918919 0.22222222 0.81782946 0.80104712 0.62330623\n",
      " 0.67564534 0.54330709 0.19354839 0.83175803 0.85486726 0.88571429\n",
      " 0.85268631 0.65435356 0.84109589 0.63793103 0.83602771 0.32911392\n",
      " 0.44720497 0.56537983 0.53691275 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 80/300, Loss: 0.2209, Accuracy: 0.9145, F1: 0.6281\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94870234 0.73915212 0.74727992 0.26345083 0.2972028  0.16155989\n",
      " 0.20848057 0.39310345 0.4008016  0.66304348 0.71598174 0.5228299\n",
      " 0.62858486 0.41981886 0.18592965 0.65224233 0.77       0.75781664\n",
      " 0.74726306 0.69650762 0.88252237 0.54387237 0.73154236 0.47038019\n",
      " 0.57733813 0.45391641 0.48440259 0.99050732 0.93003243 0.95199572]\n",
      "Training Epoch 81/300, Loss: 0.2355, Accuracy: 0.8915, F1: 0.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9599114  0.89124668 0.85212299 0.23880597 0.28070175 0.08888889\n",
      " 0.11764706 0.16216216 0.19354839 0.82533589 0.81126761 0.59949622\n",
      " 0.63469388 0.43514644 0.16666667 0.82222222 0.86101695 0.86970173\n",
      " 0.84757119 0.65951743 0.86440678 0.608      0.77938144 0.29333333\n",
      " 0.41059603 0.58154235 0.54891995 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 81/300, Loss: 0.2231, Accuracy: 0.9139, F1: 0.6134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94818692 0.74188717 0.73645137 0.29333333 0.32391714 0.13913043\n",
      " 0.23304348 0.39931741 0.44532803 0.         0.65825778 0.71992819\n",
      " 0.52837573 0.60501495 0.41003737 0.14250614 0.64968652 0.75702543\n",
      " 0.75980005 0.75465839 0.69858329 0.88233177 0.54688618 0.72870778\n",
      " 0.48128342 0.56932966 0.4572238  0.4899696  0.99095705 0.92952476\n",
      " 0.95092681]\n",
      "Training Epoch 82/300, Loss: 0.2345, Accuracy: 0.8910, F1: 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95930441 0.90374332 0.85887709 0.21212121 0.25       0.26923077\n",
      " 0.28282828 0.18421053 0.1875     0.83428571 0.82644628 0.60913706\n",
      " 0.63273453 0.51162791 0.19672131 0.82926829 0.86637555 0.87936508\n",
      " 0.85714286 0.66304348 0.85406631 0.63453815 0.80416667 0.44\n",
      " 0.5        0.57066667 0.54628225 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 82/300, Loss: 0.2204, Accuracy: 0.9151, F1: 0.6387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94981588 0.7337695  0.74533234 0.20729367 0.23970037 0.16393443\n",
      " 0.23344948 0.37351443 0.40501044 0.         0.66692397 0.71448276\n",
      " 0.52716298 0.61908094 0.43681917 0.24880383 0.67318982 0.78831548\n",
      " 0.75844156 0.75985335 0.6783115  0.87508893 0.53188406 0.72028101\n",
      " 0.45349867 0.57245725 0.4541387  0.48972402 0.98987612 0.93082153\n",
      " 0.95389754]\n",
      "Training Epoch 83/300, Loss: 0.2331, Accuracy: 0.8922, F1: 0.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95940463 0.89655172 0.85459941 0.21212121 0.25       0.27586207\n",
      " 0.3220339  0.32098765 0.21538462 0.82041588 0.80104712 0.60916442\n",
      " 0.66073415 0.53731343 0.27272727 0.81439394 0.85521886 0.85625966\n",
      " 0.84048583 0.65963061 0.84906696 0.64135021 0.83314415 0.42857143\n",
      " 0.51578947 0.5745554  0.56699577 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 83/300, Loss: 0.2239, Accuracy: 0.9152, F1: 0.6481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94966181 0.75848101 0.74899396 0.21969697 0.24043716 0.17613636\n",
      " 0.23508772 0.4219554  0.36550308 0.65612953 0.75277408 0.52568579\n",
      " 0.60935645 0.43093333 0.21515892 0.66926373 0.7622729  0.75026233\n",
      " 0.75497916 0.69569472 0.88134374 0.54506438 0.72694459 0.49033392\n",
      " 0.57221711 0.44925499 0.46982249 0.99000691 0.93147952 0.95331666]\n",
      "Training Epoch 84/300, Loss: 0.2297, Accuracy: 0.8923, F1: 0.5983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96030074 0.88020833 0.83261803 0.20895522 0.21428571 0.2\n",
      " 0.2020202  0.23376623 0.21875    0.82732448 0.82702703 0.60795455\n",
      " 0.66347305 0.54054054 0.23880597 0.82352941 0.86387435 0.88151659\n",
      " 0.85279188 0.68131868 0.85502283 0.62450593 0.80041797 0.34615385\n",
      " 0.39240506 0.5686747  0.52631579 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 84/300, Loss: 0.2211, Accuracy: 0.9149, F1: 0.6290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94935698 0.73731793 0.75314427 0.26788991 0.32291667 0.18879056\n",
      " 0.24603175 0.38062284 0.38888889 0.66845947 0.71251719 0.53293112\n",
      " 0.61364684 0.41462084 0.2327791  0.63936382 0.75724004 0.76272966\n",
      " 0.76265325 0.67941176 0.88214341 0.53314724 0.72428695 0.47100803\n",
      " 0.57870792 0.44121754 0.48653501 0.99095477 0.93287586 0.95039506]\n",
      "Training Epoch 85/300, Loss: 0.2310, Accuracy: 0.8919, F1: 0.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96054905 0.88297872 0.84911243 0.28985507 0.28070175 0.23076923\n",
      " 0.23529412 0.23376623 0.21212121 0.82490272 0.81743869 0.62087912\n",
      " 0.66666667 0.56818182 0.27692308 0.82835821 0.86082474 0.87619048\n",
      " 0.8502994  0.65782493 0.85351724 0.6374502  0.8021164  0.4\n",
      " 0.46927374 0.575      0.54942234 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 85/300, Loss: 0.2210, Accuracy: 0.9160, F1: 0.6436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95016452 0.73897618 0.7574171  0.22265625 0.25769231 0.15864023\n",
      " 0.25391304 0.40410959 0.3959596  0.66304769 0.72623239 0.53613281\n",
      " 0.62826985 0.42517946 0.22588235 0.67568612 0.7820148  0.75368421\n",
      " 0.75761381 0.69305963 0.88367576 0.54882395 0.73128243 0.48841355\n",
      " 0.58152174 0.44935646 0.4702416  0.99133275 0.93793276 0.95675579]\n",
      "Training Epoch 86/300, Loss: 0.2292, Accuracy: 0.8940, F1: 0.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95625665 0.89784946 0.84673748 0.18461538 0.21428571 0.16\n",
      " 0.1875     0.21052632 0.19047619 0.82758621 0.81232493 0.62536873\n",
      " 0.68428005 0.55762082 0.32432432 0.82509506 0.85963383 0.87539936\n",
      " 0.84021544 0.67955801 0.84593023 0.65020576 0.81858407 0.34567901\n",
      " 0.42857143 0.57324841 0.52316891 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 86/300, Loss: 0.2259, Accuracy: 0.9147, F1: 0.6314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94916449 0.73126873 0.74468085 0.26887661 0.29913043 0.18630137\n",
      " 0.23826715 0.37948718 0.38658777 0.65392119 0.71232877 0.54054054\n",
      " 0.62091352 0.41028388 0.22966507 0.66352201 0.7638916  0.77134549\n",
      " 0.7728125  0.68653751 0.88637543 0.50983248 0.73232606 0.48257373\n",
      " 0.58909091 0.44463134 0.48701299 0.99082223 0.92858479 0.95173481]\n",
      "Training Epoch 87/300, Loss: 0.2265, Accuracy: 0.8924, F1: 0.6004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96018848 0.88947368 0.84164223 0.31428571 0.27586207 0.08888889\n",
      " 0.11764706 0.25974026 0.22222222 0.82352941 0.80428954 0.61413043\n",
      " 0.65406007 0.5390625  0.35294118 0.83615819 0.86925795 0.88291139\n",
      " 0.85616438 0.65284974 0.85070273 0.62978723 0.82298851 0.33540373\n",
      " 0.42682927 0.57213317 0.53217822 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 87/300, Loss: 0.2233, Accuracy: 0.9151, F1: 0.6341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95016377 0.74418605 0.75055956 0.28363636 0.30449827 0.22857143\n",
      " 0.27007299 0.38408304 0.41889117 0.64073045 0.73083779 0.54846811\n",
      " 0.63934051 0.43027475 0.24663677 0.64770932 0.76964875 0.76915033\n",
      " 0.76293771 0.68161872 0.88684984 0.54273504 0.73603427 0.48892826\n",
      " 0.60162602 0.46327373 0.48819362 0.99025096 0.93562874 0.9549797 ]\n",
      "Training Epoch 88/300, Loss: 0.2270, Accuracy: 0.8943, F1: 0.6097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96040887 0.89893617 0.85373134 0.28169014 0.23333333 0.31034483\n",
      " 0.416      0.36363636 0.29333333 0.83396226 0.82417582 0.61202186\n",
      " 0.66820276 0.55762082 0.3030303  0.83208955 0.86185925 0.88299532\n",
      " 0.85262281 0.64285714 0.85599356 0.63453815 0.80474649 0.44198895\n",
      " 0.5        0.55944056 0.55590062 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 88/300, Loss: 0.2227, Accuracy: 0.9173, F1: 0.6611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95034407 0.76015857 0.78053576 0.25373134 0.28158845 0.16959064\n",
      " 0.22857143 0.40344828 0.38       0.67927383 0.72652689 0.5333998\n",
      " 0.63179534 0.43376188 0.20673077 0.67156105 0.77674419 0.76550999\n",
      " 0.76582378 0.68700787 0.88488719 0.53493296 0.7287186  0.44055944\n",
      " 0.54787234 0.45120265 0.46418171 0.99171479 0.93438942 0.95459698]\n",
      "Training Epoch 89/300, Loss: 0.2256, Accuracy: 0.8940, F1: 0.6006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95906684 0.90514905 0.85230769 0.28985507 0.24137931 0.23529412\n",
      " 0.27659574 0.27848101 0.19047619 0.83365201 0.82872928 0.62376238\n",
      " 0.64748201 0.51162791 0.22580645 0.83111954 0.86467487 0.8875\n",
      " 0.85344828 0.67208672 0.86023342 0.65020576 0.83277962 0.37125749\n",
      " 0.48       0.57066667 0.56195965 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 89/300, Loss: 0.2251, Accuracy: 0.9169, F1: 0.6444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94985201 0.74863116 0.76240079 0.25475285 0.29739777 0.1852861\n",
      " 0.23934426 0.37627119 0.39685658 0.66743917 0.7310962  0.53182042\n",
      " 0.61751372 0.44134367 0.25       0.67161265 0.78242436 0.75721028\n",
      " 0.75608235 0.68145957 0.88542094 0.55360897 0.74737224 0.50587173\n",
      " 0.61213235 0.46472564 0.49576147 0.9906965  0.93327513 0.95390304]\n",
      "Training Epoch 90/300, Loss: 0.2287, Accuracy: 0.8940, F1: 0.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96081249 0.88020833 0.84760522 0.32432432 0.29032258 0.32727273\n",
      " 0.39655172 0.28571429 0.30769231 0.82889734 0.8125     0.63509749\n",
      " 0.69729093 0.59060403 0.43373494 0.83615819 0.869869   0.87974684\n",
      " 0.8559464  0.67582418 0.85021398 0.65079365 0.81770285 0.40236686\n",
      " 0.48863636 0.58056266 0.56043956 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 90/300, Loss: 0.2205, Accuracy: 0.9182, F1: 0.6695\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95050379 0.75433231 0.75088968 0.3024055  0.32025118 0.18181818\n",
      " 0.26970228 0.40268456 0.39525692 0.66339623 0.73602908 0.5444664\n",
      " 0.63538567 0.40628507 0.20050125 0.68823071 0.79171551 0.7631921\n",
      " 0.74887545 0.68031189 0.88784758 0.54327938 0.72867647 0.51219512\n",
      " 0.60510114 0.44049633 0.46347903 0.99095023 0.9372505  0.95524885]\n",
      "Training Epoch 91/300, Loss: 0.2252, Accuracy: 0.8944, F1: 0.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96082107 0.88770053 0.84319527 0.325      0.23255814 0.30188679\n",
      " 0.28571429 0.31707317 0.20289855 0.82706767 0.82479784 0.60916442\n",
      " 0.66213152 0.54615385 0.24242424 0.82089552 0.85493562 0.88291139\n",
      " 0.84440559 0.67368421 0.85674931 0.65863454 0.82200647 0.37125749\n",
      " 0.46857143 0.58692972 0.54499366 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 91/300, Loss: 0.2220, Accuracy: 0.9159, F1: 0.6484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95049055 0.76156942 0.76892028 0.24719101 0.28007181 0.20930233\n",
      " 0.23420074 0.39102564 0.40816327 0.66944655 0.73344948 0.53466334\n",
      " 0.62244178 0.43373494 0.19399538 0.67007874 0.78471538 0.76818774\n",
      " 0.76547381 0.68861985 0.88693777 0.56276446 0.74072721 0.50307828\n",
      " 0.60877193 0.45090293 0.48952723 0.9903828  0.92940883 0.94884273]\n",
      "Training Epoch 92/300, Loss: 0.2242, Accuracy: 0.8946, F1: 0.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95968474 0.89247312 0.84370258 0.35135135 0.32258065 0.29090909\n",
      " 0.26785714 0.24       0.16666667 0.81593928 0.816      0.63068182\n",
      " 0.68170426 0.55639098 0.26470588 0.8374761  0.85895118 0.88431062\n",
      " 0.85169124 0.64082687 0.84548422 0.5984252  0.78637771 0.36024845\n",
      " 0.44311377 0.58039216 0.56366237 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 92/300, Loss: 0.2237, Accuracy: 0.9159, F1: 0.6450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94995458 0.73839878 0.74502895 0.29432624 0.32478632 0.19337017\n",
      " 0.2675367  0.42560554 0.45867769 0.         0.66146646 0.72962138\n",
      " 0.53760311 0.62778653 0.45340314 0.25242718 0.66614297 0.78551001\n",
      " 0.75825627 0.76085934 0.68655257 0.88103157 0.56380678 0.73943662\n",
      " 0.4845815  0.5978836  0.4735062  0.50633675 0.99189749 0.92927529\n",
      " 0.94980695]\n",
      "Training Epoch 93/300, Loss: 0.2256, Accuracy: 0.8940, F1: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95983389 0.896      0.85201794 0.35897436 0.28169014 0.29032258\n",
      " 0.41176471 0.34146341 0.21212121 0.82706767 0.80645161 0.62983425\n",
      " 0.6992665  0.55882353 0.40506329 0.82309125 0.85421995 0.8847352\n",
      " 0.85197935 0.66666667 0.85076314 0.64489796 0.82675439 0.42857143\n",
      " 0.5026178  0.575      0.56671664 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 93/300, Loss: 0.2203, Accuracy: 0.9180, F1: 0.6668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95170284 0.74797571 0.76235411 0.24667932 0.29401089 0.16666667\n",
      " 0.21245421 0.40740741 0.41422594 0.66870462 0.7242268  0.55363322\n",
      " 0.64399722 0.44772967 0.25059102 0.678935   0.78764023 0.77422734\n",
      " 0.76514678 0.69888835 0.88405649 0.56595745 0.73836042 0.48128342\n",
      " 0.60947274 0.47285559 0.510907   0.9915185  0.93413995 0.95369212]\n",
      "Training Epoch 94/300, Loss: 0.2245, Accuracy: 0.8962, F1: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96045793 0.89893617 0.85885886 0.33333333 0.27118644 0.23076923\n",
      " 0.25490196 0.30588235 0.25641026 0.84052533 0.83646113 0.60504202\n",
      " 0.6737338  0.56716418 0.34285714 0.83677298 0.86585366 0.8847352\n",
      " 0.85834739 0.65116279 0.84878049 0.62447257 0.80405405 0.43386243\n",
      " 0.50746269 0.58344284 0.55068079 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 94/300, Loss: 0.2194, Accuracy: 0.9176, F1: 0.6561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95074109 0.75012519 0.75833128 0.25095057 0.30823117 0.14857143\n",
      " 0.20111732 0.41414141 0.41960784 0.66434917 0.72599119 0.5420189\n",
      " 0.62776753 0.43565401 0.27338129 0.66562744 0.78140801 0.76148456\n",
      " 0.75745342 0.69873664 0.88497303 0.58584443 0.74954363 0.49076517\n",
      " 0.61284722 0.47065463 0.49970185 0.99101251 0.92940883 0.953587  ]\n",
      "Training Epoch 95/300, Loss: 0.2225, Accuracy: 0.8953, F1: 0.6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96009215 0.87564767 0.83124128 0.35135135 0.29508197 0.24489796\n",
      " 0.23913043 0.30379747 0.21875    0.80924855 0.78461538 0.61994609\n",
      " 0.67976879 0.56390977 0.36619718 0.82899628 0.85960379 0.88188976\n",
      " 0.845953   0.66489362 0.85904182 0.64227642 0.81344902 0.35220126\n",
      " 0.42944785 0.56218905 0.53281853 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 95/300, Loss: 0.2207, Accuracy: 0.9157, F1: 0.6471\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95199092 0.73858505 0.74962444 0.2883549  0.31734317 0.22702703\n",
      " 0.29541596 0.42789223 0.44       0.67820069 0.74247191 0.5711501\n",
      " 0.65458716 0.45281018 0.22650602 0.6806364  0.78089025 0.76237113\n",
      " 0.76126057 0.70241023 0.89066942 0.55162659 0.7425943  0.46444644\n",
      " 0.57405704 0.46899662 0.50598802 0.9915153  0.93195285 0.95385716]\n",
      "Training Epoch 96/300, Loss: 0.2229, Accuracy: 0.8969, F1: 0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95919246 0.88829787 0.83965015 0.38356164 0.33898305 0.34482759\n",
      " 0.29824561 0.30952381 0.31578947 0.83553875 0.82926829 0.62068966\n",
      " 0.66596417 0.48412698 0.29850746 0.82797732 0.86387435 0.88161994\n",
      " 0.85213033 0.66666667 0.84998608 0.63559322 0.82245132 0.37267081\n",
      " 0.45121951 0.57655172 0.57784431 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 96/300, Loss: 0.2233, Accuracy: 0.9166, F1: 0.6596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95124167 0.75187219 0.75848402 0.23121387 0.2109375  0.22105263\n",
      " 0.23548922 0.40614334 0.3992016  0.67120181 0.74177557 0.56487026\n",
      " 0.64660602 0.438549   0.24537037 0.66482213 0.7816274  0.76304802\n",
      " 0.76271963 0.70541872 0.89220136 0.53304904 0.74864376 0.50347222\n",
      " 0.6122807  0.48083242 0.50935905 0.99095591 0.93637725 0.95581993]\n",
      "Training Epoch 97/300, Loss: 0.2224, Accuracy: 0.8966, F1: 0.6105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96074775 0.875      0.83544304 0.35616438 0.29508197 0.33962264\n",
      " 0.31067961 0.325      0.18181818 0.83076923 0.81889764 0.626703\n",
      " 0.64829107 0.57454545 0.4109589  0.8358209  0.86910995 0.87735849\n",
      " 0.8525695  0.65968586 0.86469003 0.64092664 0.79310345 0.41530055\n",
      " 0.46391753 0.57627119 0.52682927 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 97/300, Loss: 0.2217, Accuracy: 0.9152, F1: 0.6588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95042234 0.73895582 0.76128385 0.28007181 0.31487889 0.18289086\n",
      " 0.23571429 0.35395189 0.37979798 0.68167702 0.72014421 0.54581673\n",
      " 0.6299549  0.44117647 0.24460432 0.68435427 0.78538103 0.76608187\n",
      " 0.7613849  0.68201862 0.88282766 0.57838225 0.75770758 0.47463768\n",
      " 0.58472998 0.46020179 0.50798344 0.99133166 0.92838428 0.95214826]\n",
      "Training Epoch 98/300, Loss: 0.2217, Accuracy: 0.8953, F1: 0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96029902 0.89008043 0.85157421 0.28985507 0.24561404 0.29090909\n",
      " 0.29357798 0.30379747 0.21875    0.82600382 0.82258065 0.62702703\n",
      " 0.66370699 0.53125    0.29850746 0.83643123 0.86828423 0.87850467\n",
      " 0.8493617  0.65053763 0.8569823  0.64257028 0.81632653 0.40236686\n",
      " 0.48314607 0.58281445 0.55957162 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 98/300, Loss: 0.2214, Accuracy: 0.9170, F1: 0.6513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95187305 0.75882645 0.77576055 0.26055046 0.27826087 0.18232044\n",
      " 0.2529511  0.44594595 0.4921875  0.6669279  0.7184466  0.56553756\n",
      " 0.6557377  0.47282051 0.25171625 0.67857143 0.78059072 0.7625\n",
      " 0.76514445 0.70177165 0.8895873  0.57838225 0.76289439 0.48776065\n",
      " 0.61281337 0.47605713 0.52       0.99170854 0.93670097 0.9549173 ]\n",
      "Training Epoch 99/300, Loss: 0.2197, Accuracy: 0.8982, F1: 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95945011 0.90322581 0.84939759 0.35135135 0.26666667 0.25925926\n",
      " 0.26415094 0.32098765 0.21538462 0.82625483 0.82451253 0.61538462\n",
      " 0.67413214 0.56934307 0.36619718 0.8365019  0.85994648 0.87974684\n",
      " 0.84938704 0.67741935 0.85817979 0.63673469 0.82068207 0.35220126\n",
      " 0.44171779 0.57069409 0.55277778 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 99/300, Loss: 0.2252, Accuracy: 0.9171, F1: 0.6533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95198493 0.77374441 0.77846997 0.25688073 0.32582322 0.19834711\n",
      " 0.3089701  0.42765273 0.43636364 0.         0.68652271 0.76588338\n",
      " 0.55433699 0.64873714 0.43953617 0.25059102 0.66874513 0.78524527\n",
      " 0.75597092 0.76202182 0.67935578 0.89304646 0.54415954 0.73911466\n",
      " 0.51567944 0.61304736 0.47505669 0.50722892 0.99145299 0.93314207\n",
      " 0.95370867]\n",
      "Training Epoch 100/300, Loss: 0.2184, Accuracy: 0.8975, F1: 0.6007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95933554 0.90322581 0.85365854 0.30555556 0.27692308 0.28\n",
      " 0.25531915 0.35       0.22222222 0.83206107 0.82644628 0.61152882\n",
      " 0.64220183 0.47736626 0.25806452 0.83738318 0.87183958 0.87774295\n",
      " 0.8559322  0.66312997 0.85516477 0.64489796 0.81481481 0.36809816\n",
      " 0.43529412 0.57653061 0.54830287 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 100/300, Loss: 0.2241, Accuracy: 0.9154, F1: 0.6467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95241181 0.73777778 0.75412257 0.23376623 0.31010453 0.20786517\n",
      " 0.2728972  0.41891892 0.42655936 0.         0.68037383 0.73224044\n",
      " 0.5525407  0.64771151 0.46102819 0.26066351 0.67571761 0.79190314\n",
      " 0.77203965 0.77039322 0.7091358  0.90167667 0.55793991 0.74280543\n",
      " 0.5044405  0.61769912 0.47414034 0.5029036  0.99341156 0.9350212\n",
      " 0.95351055]\n",
      "Training Epoch 101/300, Loss: 0.2206, Accuracy: 0.8984, F1: 0.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96024848 0.88829787 0.84875184 0.35616438 0.29508197 0.26923077\n",
      " 0.27722772 0.34146341 0.26470588 0.82375479 0.80818414 0.64171123\n",
      " 0.66167024 0.56603774 0.3943662  0.83712121 0.87489064 0.86970173\n",
      " 0.84822934 0.65263158 0.85230685 0.62240664 0.80752212 0.4\n",
      " 0.47668394 0.57888199 0.54404145 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 101/300, Loss: 0.2206, Accuracy: 0.9157, F1: 0.6586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95124936 0.73242286 0.7427999  0.29213483 0.32924694 0.20630372\n",
      " 0.27697842 0.40468227 0.43190661 0.67092412 0.72194228 0.55948869\n",
      " 0.63600647 0.41163056 0.19117647 0.6711146  0.78141136 0.75702653\n",
      " 0.75668948 0.68995633 0.88448575 0.57445307 0.74634938 0.48409894\n",
      " 0.59232828 0.48118205 0.51737452 0.99227533 0.93189472 0.95292014]\n",
      "Training Epoch 102/300, Loss: 0.2188, Accuracy: 0.8956, F1: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96003866 0.87206266 0.83356643 0.35897436 0.29411765 0.3\n",
      " 0.26890756 0.30952381 0.31168831 0.82851638 0.81818182 0.63865546\n",
      " 0.68663594 0.60070671 0.40963855 0.79636364 0.82148499 0.87301587\n",
      " 0.84451997 0.66666667 0.86227876 0.6328125  0.79755849 0.40243902\n",
      " 0.46783626 0.59012346 0.56052632 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 102/300, Loss: 0.2235, Accuracy: 0.9148, F1: 0.6602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9505714  0.74166252 0.76065411 0.27865961 0.33438486 0.1920904\n",
      " 0.27659574 0.42       0.39534884 0.68413174 0.74836459 0.56011875\n",
      " 0.64697802 0.47014115 0.31205674 0.67689886 0.75834971 0.75975039\n",
      " 0.75301019 0.69785575 0.88288848 0.52447042 0.73323286 0.49912434\n",
      " 0.59318996 0.46441735 0.48958648 0.99322034 0.9362525  0.95702657]\n",
      "Training Epoch 103/300, Loss: 0.2221, Accuracy: 0.8956, F1: 0.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96055284 0.88126649 0.8422576  0.37974684 0.25974026 0.35714286\n",
      " 0.30909091 0.29885057 0.35714286 0.828125   0.82222222 0.62702703\n",
      " 0.67552602 0.57992565 0.38888889 0.81818182 0.86308492 0.86769231\n",
      " 0.83990346 0.69589041 0.85968948 0.65863454 0.82478632 0.42045455\n",
      " 0.48648649 0.5920398  0.56984786 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 103/300, Loss: 0.2219, Accuracy: 0.9176, F1: 0.6687\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95187809 0.7340372  0.75220372 0.24542125 0.31634446 0.20930233\n",
      " 0.29963899 0.44552846 0.43495146 0.6768771  0.73345422 0.5499002\n",
      " 0.64387464 0.45095829 0.24213075 0.67958156 0.78297385 0.76579153\n",
      " 0.76329251 0.69849001 0.89713724 0.56080114 0.74870658 0.49475524\n",
      " 0.59685864 0.46701628 0.48830409 0.99215268 0.92917317 0.95018428]\n",
      "Training Epoch 104/300, Loss: 0.2184, Accuracy: 0.8971, F1: 0.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95997877 0.875      0.83862069 0.36842105 0.3030303  0.35714286\n",
      " 0.30909091 0.32098765 0.21538462 0.80859375 0.80314961 0.6342711\n",
      " 0.66666667 0.57039711 0.37142857 0.82439926 0.84742952 0.87598116\n",
      " 0.84504657 0.68108108 0.85898153 0.63157895 0.80728051 0.4\n",
      " 0.47674419 0.57934509 0.55154639 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 104/300, Loss: 0.2217, Accuracy: 0.9150, F1: 0.6593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95115809 0.75062469 0.77261369 0.29287091 0.33834586 0.22969188\n",
      " 0.30714286 0.42465753 0.43232323 0.         0.68268497 0.73736018\n",
      " 0.56148947 0.66229656 0.46989247 0.25775656 0.67503925 0.78667192\n",
      " 0.76069484 0.75954848 0.6958231  0.88767494 0.572843   0.7515393\n",
      " 0.51313485 0.62214411 0.47912088 0.50230947 0.99184032 0.93343315\n",
      " 0.95191049]\n",
      "Training Epoch 105/300, Loss: 0.2188, Accuracy: 0.8973, F1: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95936119 0.90860215 0.8610687  0.33802817 0.30508475 0.28070175\n",
      " 0.28070175 0.30379747 0.1875     0.83301344 0.82913165 0.62222222\n",
      " 0.6745283  0.53488372 0.24242424 0.84030418 0.84754991 0.88098918\n",
      " 0.85226302 0.66120219 0.85030639 0.64069264 0.83098592 0.37037037\n",
      " 0.44047619 0.58353511 0.54172015 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 105/300, Loss: 0.2263, Accuracy: 0.9165, F1: 0.6500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95116133 0.72227874 0.73734098 0.29834254 0.37366548 0.17977528\n",
      " 0.23698384 0.45098039 0.43460765 0.6635514  0.73144399 0.58308751\n",
      " 0.66054203 0.4502345  0.27014218 0.67534517 0.78235636 0.77026677\n",
      " 0.76878079 0.71097981 0.89660502 0.54338549 0.73420957 0.49262793\n",
      " 0.59688581 0.4625624  0.49064327 0.99221692 0.93157008 0.95302814]\n",
      "Training Epoch 106/300, Loss: 0.2190, Accuracy: 0.8961, F1: 0.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95941667 0.89182058 0.8443804  0.33802817 0.24561404 0.34375\n",
      " 0.27536232 0.23684211 0.16393443 0.81818182 0.79365079 0.63783784\n",
      " 0.6832018  0.53639847 0.33802817 0.83082707 0.86032562 0.87323944\n",
      " 0.8462192  0.67036011 0.84733045 0.64       0.82089552 0.42285714\n",
      " 0.49462366 0.58072289 0.53855879 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 106/300, Loss: 0.2221, Accuracy: 0.9148, F1: 0.6510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95152081 0.75893306 0.76120537 0.29032258 0.3744     0.20555556\n",
      " 0.30215827 0.38461538 0.37227723 0.67679128 0.75789474 0.54749148\n",
      " 0.65418453 0.47406639 0.28009828 0.6848249  0.78905798 0.76163392\n",
      " 0.75447807 0.70588235 0.89950764 0.55673009 0.74220033 0.47239819\n",
      " 0.58550186 0.48111888 0.5045208  0.99284639 0.92633942 0.94916261]\n",
      "Training Epoch 107/300, Loss: 0.2162, Accuracy: 0.8974, F1: 0.6199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96059419 0.89839572 0.84947839 0.32876712 0.20689655 0.37681159\n",
      " 0.40993789 0.3        0.20895522 0.83301344 0.82872928 0.63013699\n",
      " 0.69304556 0.58064516 0.35135135 0.84543762 0.87192982 0.88151659\n",
      " 0.84938704 0.68073879 0.86285397 0.63035019 0.80041365 0.3902439\n",
      " 0.46783626 0.57645467 0.5504     0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 107/300, Loss: 0.2236, Accuracy: 0.9190, F1: 0.6621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9513246  0.76209677 0.77026355 0.35906643 0.36912752 0.21288515\n",
      " 0.25042301 0.42735043 0.44354839 0.67126966 0.71461292 0.55902439\n",
      " 0.65363385 0.46767241 0.28904429 0.6627952  0.79559931 0.76272966\n",
      " 0.75392507 0.69332033 0.89012731 0.59084605 0.75867132 0.50909091\n",
      " 0.59548611 0.48029075 0.50542169 0.99183725 0.92990771 0.95182517]\n",
      "Training Epoch 108/300, Loss: 0.2151, Accuracy: 0.8973, F1: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9614025  0.88188976 0.83641536 0.35616438 0.33333333 0.3880597\n",
      " 0.47619048 0.39534884 0.34210526 0.82771536 0.83378747 0.6122449\n",
      " 0.68535032 0.57462687 0.38461538 0.82287823 0.85446809 0.87713841\n",
      " 0.84945332 0.63613232 0.84130719 0.61354582 0.78578892 0.4198895\n",
      " 0.48421053 0.58309859 0.5681445  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 108/300, Loss: 0.2239, Accuracy: 0.9174, F1: 0.6741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95246912 0.72835821 0.75553369 0.30742049 0.35702479 0.23595506\n",
      " 0.30939227 0.45483871 0.47299814 0.         0.68423006 0.74585388\n",
      " 0.56430318 0.65363385 0.44787645 0.26267281 0.68194175 0.78922224\n",
      " 0.76723017 0.76134609 0.69272106 0.89053362 0.56236786 0.73659335\n",
      " 0.51748252 0.6036036  0.47546531 0.50015065 0.99234053 0.93237679\n",
      " 0.95358549]\n",
      "Training Epoch 109/300, Loss: 0.2179, Accuracy: 0.8978, F1: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95934533 0.88421053 0.81626928 0.4        0.30555556 0.26415094\n",
      " 0.26923077 0.40425532 0.30379747 0.82264151 0.81318681 0.64190981\n",
      " 0.70441676 0.56521739 0.37333333 0.83798883 0.86828423 0.87974684\n",
      " 0.85490877 0.69754768 0.85860597 0.656      0.82045702 0.46666667\n",
      " 0.55789474 0.57142857 0.55961844 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 109/300, Loss: 0.2250, Accuracy: 0.9187, F1: 0.6718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95278508 0.75165058 0.76708861 0.31071429 0.34662045 0.25274725\n",
      " 0.30797774 0.46566164 0.41832669 0.67604591 0.73688969 0.55802708\n",
      " 0.65385495 0.47516199 0.25570776 0.68369352 0.784375   0.77602524\n",
      " 0.76899273 0.72968981 0.89296668 0.59930314 0.76041477 0.51183173\n",
      " 0.60995475 0.46524664 0.49562172 0.99272271 0.93943741 0.95688057]\n",
      "Training Epoch 110/300, Loss: 0.2178, Accuracy: 0.8996, F1: 0.6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9573397  0.89784946 0.84       0.23880597 0.25       0.2745098\n",
      " 0.3125     0.26315789 0.13333333 0.82061069 0.82451253 0.63687151\n",
      " 0.70343137 0.55762082 0.34666667 0.82851638 0.85480944 0.87636933\n",
      " 0.84719864 0.69637883 0.85198342 0.66122449 0.8305275  0.30463576\n",
      " 0.3974359  0.57293035 0.53658537 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 110/300, Loss: 0.2361, Accuracy: 0.9167, F1: 0.6438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95239819 0.74638764 0.76127125 0.27037037 0.31842576 0.26246719\n",
      " 0.321489   0.42512077 0.41618497 0.         0.66866567 0.72409152\n",
      " 0.56865599 0.67111623 0.46897309 0.30699774 0.70027354 0.80123385\n",
      " 0.78391699 0.77746999 0.72309198 0.89983005 0.57044674 0.74168614\n",
      " 0.50312221 0.59763851 0.47439505 0.50435828 0.99182904 0.9318281\n",
      " 0.95214826]\n",
      "Training Epoch 111/300, Loss: 0.2155, Accuracy: 0.8993, F1: 0.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96006862 0.88947368 0.83908046 0.41558442 0.3125     0.2962963\n",
      " 0.30188679 0.43678161 0.1875     0.83206107 0.82913165 0.63736264\n",
      " 0.69859813 0.58940397 0.43373494 0.83054004 0.8616188  0.89206349\n",
      " 0.85363716 0.67777778 0.85150265 0.65873016 0.82252922 0.39285714\n",
      " 0.46590909 0.56521739 0.55764075 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 111/300, Loss: 0.2245, Accuracy: 0.9184, F1: 0.6696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95250787 0.74650699 0.7655     0.31758034 0.37037037 0.25824176\n",
      " 0.33216783 0.4661157  0.43942505 0.68975904 0.73373327 0.57681159\n",
      " 0.66727647 0.43918547 0.26004728 0.70376176 0.79098923 0.78265386\n",
      " 0.78011532 0.71972656 0.89963749 0.58741259 0.77596017 0.51941329\n",
      " 0.62105263 0.47369902 0.50903704 0.99246799 0.936502   0.95444504]\n",
      "Training Epoch 112/300, Loss: 0.2137, Accuracy: 0.9008, F1: 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95814549 0.90909091 0.85844749 0.36842105 0.25806452 0.33333333\n",
      " 0.35151515 0.38202247 0.32       0.83239171 0.82913165 0.62734584\n",
      " 0.68360277 0.55555556 0.35616438 0.83365201 0.84810127 0.884375\n",
      " 0.85365854 0.67574932 0.85250652 0.68016194 0.84350721 0.43386243\n",
      " 0.49746193 0.56277056 0.53658537 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 112/300, Loss: 0.2295, Accuracy: 0.9176, F1: 0.6708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95336063 0.7751861  0.78977133 0.3040293  0.34224599 0.19680851\n",
      " 0.29984051 0.45676998 0.47882136 0.6838565  0.72775564 0.58105469\n",
      " 0.68049793 0.48128342 0.30248307 0.68689226 0.79088785 0.7780083\n",
      " 0.77685697 0.71456123 0.89493841 0.56432125 0.74406239 0.52687225\n",
      " 0.62633452 0.48513476 0.5094623  0.99310172 0.93588624 0.95782232]\n",
      "Training Epoch 113/300, Loss: 0.2125, Accuracy: 0.9008, F1: 0.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96029384 0.8994709  0.85882353 0.37837838 0.27586207 0.35483871\n",
      " 0.30645161 0.34146341 0.37837838 0.82954545 0.81818182 0.63934426\n",
      " 0.6875     0.61324042 0.42352941 0.8411215  0.86873921 0.88401254\n",
      " 0.85521886 0.67036011 0.85087972 0.62790698 0.78450844 0.40243902\n",
      " 0.45882353 0.59479554 0.56833559 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 113/300, Loss: 0.2221, Accuracy: 0.9173, F1: 0.6723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95391973 0.7560241  0.76303435 0.26838235 0.275      0.23369565\n",
      " 0.26865672 0.49081803 0.51953125 0.69025875 0.74921207 0.56962025\n",
      " 0.68025362 0.46521508 0.32071269 0.67494182 0.8042065  0.76974877\n",
      " 0.77078859 0.70788705 0.89647315 0.57560976 0.76583926 0.51730104\n",
      " 0.60792952 0.4819143  0.50810492 0.9927859  0.93078074 0.95279481]\n",
      "Training Epoch 114/300, Loss: 0.2132, Accuracy: 0.9003, F1: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96083172 0.88421053 0.85050798 0.35135135 0.30769231 0.36923077\n",
      " 0.33333333 0.35       0.36619718 0.81869159 0.81914894 0.64210526\n",
      " 0.67826087 0.57664234 0.42857143 0.83088235 0.86078098 0.86915888\n",
      " 0.84757119 0.672      0.86435506 0.65863454 0.81798715 0.39506173\n",
      " 0.44047619 0.57793765 0.52757794 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 114/300, Loss: 0.2240, Accuracy: 0.9160, F1: 0.6699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95330161 0.77335984 0.79921549 0.29250457 0.36528029 0.24064171\n",
      " 0.33898305 0.40823328 0.42687747 0.6746988  0.74504624 0.56707617\n",
      " 0.65530126 0.45850622 0.3143508  0.68895801 0.79545455 0.77757591\n",
      " 0.76633205 0.71870398 0.90041623 0.58798587 0.75740707 0.51777575\n",
      " 0.62835959 0.46981339 0.5157774  0.99214972 0.93612774 0.95587091]\n",
      "Training Epoch 115/300, Loss: 0.2130, Accuracy: 0.9010, F1: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96116411 0.89655172 0.84750733 0.39473684 0.29850746 0.38596491\n",
      " 0.34234234 0.36585366 0.23880597 0.81765835 0.80916031 0.62105263\n",
      " 0.6673913  0.5754386  0.375      0.82809612 0.86201022 0.87874016\n",
      " 0.85059423 0.67391304 0.86375176 0.6640625  0.82109617 0.39520958\n",
      " 0.46590909 0.58159509 0.55076142 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 115/300, Loss: 0.2234, Accuracy: 0.9172, F1: 0.6677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95290008 0.7744511  0.76564052 0.33393829 0.40672269 0.25915493\n",
      " 0.29590018 0.46325879 0.43346008 0.         0.67309175 0.75473399\n",
      " 0.57751938 0.66254296 0.46332454 0.29017857 0.68597914 0.78306064\n",
      " 0.7783586  0.78285182 0.70180576 0.8951367  0.57524613 0.76229951\n",
      " 0.48833034 0.60349586 0.4802213  0.51173709 0.99240665 0.92955637\n",
      " 0.95289207]\n",
      "Training Epoch 116/300, Loss: 0.2100, Accuracy: 0.9000, F1: 0.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95991591 0.89709763 0.84241532 0.40540541 0.31034483 0.29090909\n",
      " 0.2962963  0.3908046  0.30136986 0.81886792 0.81767956 0.63852243\n",
      " 0.68292683 0.55639098 0.35135135 0.83738318 0.8659071  0.88748019\n",
      " 0.84574468 0.6701847  0.85563576 0.68548387 0.835141   0.42696629\n",
      " 0.5026738  0.57959184 0.56386293 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 116/300, Loss: 0.2248, Accuracy: 0.9186, F1: 0.6705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95322132 0.76078431 0.76801532 0.2739212  0.34862385 0.27513228\n",
      " 0.33333333 0.41077441 0.41573034 0.67158385 0.73538886 0.57382716\n",
      " 0.65268615 0.43622722 0.27602906 0.69642857 0.80494399 0.76538759\n",
      " 0.76946753 0.73766488 0.90328619 0.58146067 0.76548991 0.52258636\n",
      " 0.6254417  0.48543689 0.51102617 0.99322544 0.93214419 0.95328885]\n",
      "Training Epoch 117/300, Loss: 0.2114, Accuracy: 0.9004, F1: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96149854 0.88713911 0.83943662 0.37333333 0.32258065 0.34615385\n",
      " 0.32653061 0.33333333 0.16393443 0.8219697  0.81329923 0.63101604\n",
      " 0.66739606 0.57915058 0.43243243 0.84601113 0.86963979 0.87888199\n",
      " 0.85572139 0.65963061 0.87027915 0.61983471 0.7978022  0.38509317\n",
      " 0.46987952 0.58254717 0.53121175 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 117/300, Loss: 0.2249, Accuracy: 0.9175, F1: 0.6621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95451257 0.76232742 0.78275947 0.32688928 0.39016393 0.21787709\n",
      " 0.31118881 0.41680672 0.42323651 0.66796419 0.72423146 0.58271605\n",
      " 0.67687957 0.47516641 0.27477477 0.69835035 0.80428016 0.77703742\n",
      " 0.77217711 0.71567673 0.89985561 0.56241234 0.74181684 0.52715939\n",
      " 0.63799283 0.47917249 0.53262787 0.99278046 0.93736744 0.95731817]\n",
      "Training Epoch 118/300, Loss: 0.2110, Accuracy: 0.9022, F1: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96108519 0.8976378  0.84393064 0.37333333 0.31746032 0.38596491\n",
      " 0.34234234 0.41304348 0.32098765 0.83047619 0.82644628 0.62068966\n",
      " 0.68427095 0.56153846 0.42666667 0.83116883 0.864494   0.88198758\n",
      " 0.85398981 0.64415584 0.85960658 0.65306122 0.8079034  0.4137931\n",
      " 0.48913043 0.57777778 0.54698457 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 118/300, Loss: 0.2215, Accuracy: 0.9181, F1: 0.6743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95359307 0.76365442 0.77428852 0.30347349 0.33442623 0.27154047\n",
      " 0.32894737 0.44067797 0.47011952 0.67253252 0.7318612  0.59280855\n",
      " 0.67497116 0.48079958 0.27118644 0.69662921 0.80038499 0.76352234\n",
      " 0.76315789 0.71358268 0.89988576 0.59722222 0.76019576 0.50790861\n",
      " 0.6056338  0.50041471 0.53644143 0.99271906 0.93201098 0.95368823]\n",
      "Training Epoch 119/300, Loss: 0.2109, Accuracy: 0.9015, F1: 0.6363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96147935 0.88020833 0.83473389 0.30555556 0.26229508 0.33333333\n",
      " 0.31775701 0.3908046  0.25       0.82954545 0.81818182 0.63535912\n",
      " 0.70405728 0.60350877 0.43902439 0.84150943 0.87147887 0.88714734\n",
      " 0.86056459 0.65789474 0.86321526 0.66403162 0.80508475 0.45263158\n",
      " 0.53398058 0.58543046 0.56350365 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 119/300, Loss: 0.2221, Accuracy: 0.9198, F1: 0.6717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95406146 0.768      0.76915373 0.28996283 0.34385965 0.22811671\n",
      " 0.30333333 0.44407895 0.44145873 0.68947756 0.75409836 0.58702065\n",
      " 0.67190751 0.4448142  0.26573427 0.67940718 0.79202502 0.77908497\n",
      " 0.77628116 0.70691334 0.9014362  0.61678322 0.78171091 0.52467532\n",
      " 0.63241807 0.4840484  0.51058892 0.99215268 0.93725833 0.95581465]\n",
      "Training Epoch 120/300, Loss: 0.2136, Accuracy: 0.9021, F1: 0.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95837381 0.91105121 0.85321101 0.39506173 0.28985507 0.36363636\n",
      " 0.42477876 0.2962963  0.29411765 0.82945736 0.82451253 0.63098592\n",
      " 0.69543773 0.58       0.34567901 0.84310019 0.86809269 0.8798752\n",
      " 0.85467128 0.69421488 0.85387994 0.67741935 0.83920705 0.44827586\n",
      " 0.54255319 0.56671252 0.55305466 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 120/300, Loss: 0.2307, Accuracy: 0.9194, F1: 0.6770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95298647 0.76753507 0.77695351 0.29872495 0.35587189 0.25613079\n",
      " 0.31543624 0.45528455 0.47672253 0.67709497 0.74193548 0.59259259\n",
      " 0.69722222 0.47847411 0.29       0.70705521 0.78637413 0.77564944\n",
      " 0.77050461 0.72385542 0.89793182 0.6011236  0.7558651  0.50130548\n",
      " 0.59860384 0.49720045 0.52326284 0.9927859  0.92727046 0.94955137]\n",
      "Training Epoch 121/300, Loss: 0.2101, Accuracy: 0.9008, F1: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96128477 0.8994709  0.84365782 0.4        0.28985507 0.33898305\n",
      " 0.30769231 0.33333333 0.16393443 0.83018868 0.82739726 0.62295082\n",
      " 0.69194313 0.56505576 0.36363636 0.83703704 0.85933504 0.87735849\n",
      " 0.85763293 0.68834688 0.86134333 0.65625    0.81713689 0.38509317\n",
      " 0.44578313 0.58629442 0.55833333 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 121/300, Loss: 0.2238, Accuracy: 0.9193, F1: 0.6622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95392525 0.75347913 0.77761414 0.30434783 0.33571429 0.2729805\n",
      " 0.3363472  0.44369748 0.45783133 0.         0.67678638 0.72759857\n",
      " 0.59555985 0.66384495 0.46035242 0.24886878 0.70498084 0.80486877\n",
      " 0.76959125 0.77530333 0.72894482 0.89762236 0.57344633 0.74580645\n",
      " 0.54105445 0.64020708 0.4860179  0.51711027 0.99284639 0.93438942\n",
      " 0.95544525]\n",
      "Training Epoch 122/300, Loss: 0.2093, Accuracy: 0.9009, F1: 0.6154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96067793 0.89361702 0.85074627 0.36842105 0.3030303  0.38596491\n",
      " 0.34234234 0.3908046  0.39473684 0.81624758 0.79792746 0.64824121\n",
      " 0.6779661  0.60207612 0.43589744 0.84052533 0.86467487 0.87598116\n",
      " 0.8588137  0.69945355 0.85623922 0.6692607  0.80482897 0.39285714\n",
      " 0.45454545 0.58777633 0.56703911 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 122/300, Loss: 0.2234, Accuracy: 0.9182, F1: 0.6780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9544357  0.76576577 0.77460947 0.29856115 0.3630363  0.26558266\n",
      " 0.35555556 0.4602649  0.48096192 0.67990833 0.74955117 0.58014528\n",
      " 0.66849943 0.45623342 0.2372093  0.69024485 0.78944327 0.78691059\n",
      " 0.78263566 0.71498531 0.90386797 0.56701754 0.74990978 0.52453167\n",
      " 0.64791289 0.50778051 0.54291417 0.99303508 0.93132913 0.95307935]\n",
      "Training Epoch 123/300, Loss: 0.2075, Accuracy: 0.9020, F1: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96109071 0.90133333 0.85285285 0.32876712 0.25       0.36111111\n",
      " 0.38410596 0.4        0.36144578 0.83011583 0.79895561 0.63783784\n",
      " 0.68980963 0.5904059  0.37974684 0.84074074 0.8714409  0.87323944\n",
      " 0.85378151 0.68463612 0.86176143 0.65587045 0.81433225 0.39759036\n",
      " 0.46242775 0.60636943 0.5755814  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 123/300, Loss: 0.2234, Accuracy: 0.9192, F1: 0.6741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95394122 0.75775776 0.77611194 0.27624309 0.38666667 0.28804348\n",
      " 0.36814159 0.4602649  0.48854962 0.         0.66016387 0.74418605\n",
      " 0.57666345 0.66882367 0.47619048 0.26728111 0.69331284 0.79339478\n",
      " 0.77636032 0.77535781 0.73684211 0.90501223 0.59379408 0.75991426\n",
      " 0.53169014 0.64086409 0.5001371  0.53215339 0.99347635 0.93048796\n",
      " 0.95104978]\n",
      "Training Epoch 124/300, Loss: 0.2081, Accuracy: 0.9020, F1: 0.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95991415 0.90909091 0.85325265 0.38356164 0.28070175 0.2962963\n",
      " 0.30188679 0.37113402 0.30434783 0.83428571 0.81521739 0.63687151\n",
      " 0.693302   0.59854015 0.37037037 0.83239171 0.86994728 0.87402799\n",
      " 0.84940778 0.69021739 0.85993673 0.64541833 0.80603448 0.40449438\n",
      " 0.45989305 0.60880829 0.57099237 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 124/300, Loss: 0.2252, Accuracy: 0.9192, F1: 0.6693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95322263 0.78170065 0.7865     0.29562044 0.34887737 0.21727019\n",
      " 0.32235702 0.42414356 0.4141791  0.6865556  0.75011297 0.59856802\n",
      " 0.68850967 0.46589717 0.25775656 0.69029996 0.79868243 0.77330563\n",
      " 0.76966118 0.69858329 0.89557943 0.55414909 0.74904459 0.54163015\n",
      " 0.64700626 0.49256198 0.53119634 0.99379194 0.93325848 0.95400239]\n",
      "Training Epoch 125/300, Loss: 0.2059, Accuracy: 0.9010, F1: 0.6338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95763836 0.896      0.84695394 0.35616438 0.27586207 0.2962963\n",
      " 0.3047619  0.36956522 0.3        0.83141762 0.82913165 0.64066852\n",
      " 0.70321812 0.5625     0.36585366 0.84052533 0.85987815 0.88818898\n",
      " 0.85035211 0.7        0.84953634 0.664      0.81601732 0.4\n",
      " 0.46327684 0.55858311 0.55       0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 125/300, Loss: 0.2329, Accuracy: 0.9173, F1: 0.6658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95435286 0.76673228 0.77333987 0.30451128 0.36727273 0.2979798\n",
      " 0.36190476 0.46231156 0.51807229 0.67435602 0.76135352 0.60814743\n",
      " 0.69246813 0.4623431  0.24       0.68737864 0.80054012 0.77258567\n",
      " 0.76735951 0.72541383 0.90267413 0.59094077 0.77176804 0.55087719\n",
      " 0.66254417 0.48506838 0.52755673 0.99334923 0.93731678 0.95612147]\n",
      "Training Epoch 126/300, Loss: 0.2081, Accuracy: 0.9033, F1: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96093657 0.89709763 0.84379562 0.36363636 0.29850746 0.35087719\n",
      " 0.30909091 0.35714286 0.31428571 0.81936685 0.82258065 0.63783784\n",
      " 0.69160998 0.58736059 0.40506329 0.84210526 0.8704028  0.87850467\n",
      " 0.85451505 0.67213115 0.86631944 0.656      0.80683031 0.4047619\n",
      " 0.48       0.58854167 0.56439942 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 126/300, Loss: 0.2222, Accuracy: 0.9198, F1: 0.6714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95426569 0.75328615 0.77481108 0.32       0.37894737 0.21142857\n",
      " 0.31407942 0.43803056 0.45436105 0.67725258 0.73967684 0.60029426\n",
      " 0.65554511 0.48474946 0.33255269 0.68176494 0.79343629 0.77668394\n",
      " 0.77145494 0.74366472 0.9088927  0.55455177 0.75251076 0.4881475\n",
      " 0.59213974 0.50772627 0.54476524 0.9941733  0.93339985 0.95467304]\n",
      "Training Epoch 127/300, Loss: 0.2050, Accuracy: 0.9029, F1: 0.6362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96085804 0.89238845 0.85507246 0.37974684 0.26315789 0.36363636\n",
      " 0.33333333 0.37209302 0.38461538 0.81584158 0.78787879 0.65957447\n",
      " 0.6960452  0.59385666 0.4137931  0.8358209  0.87016337 0.87912088\n",
      " 0.85690377 0.69021739 0.86144236 0.64661654 0.77425552 0.47524752\n",
      " 0.51982379 0.59050064 0.57266187 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 127/300, Loss: 0.2232, Accuracy: 0.9179, F1: 0.6781\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95429267 0.74713217 0.77650572 0.3027027  0.35800344 0.28723404\n",
      " 0.38383838 0.46504065 0.49407115 0.         0.69056328 0.74910394\n",
      " 0.59287411 0.67785083 0.49540292 0.32671082 0.68493151 0.8025651\n",
      " 0.77728343 0.77402518 0.73065622 0.89822042 0.60113154 0.75504958\n",
      " 0.51877729 0.60977778 0.49596438 0.52324897 0.99367049 0.93047328\n",
      " 0.95197858]\n",
      "Training Epoch 128/300, Loss: 0.2047, Accuracy: 0.9022, F1: 0.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96140972 0.89839572 0.85628743 0.35616438 0.27118644 0.34482759\n",
      " 0.30357143 0.32098765 0.31428571 0.83333333 0.82513661 0.63157895\n",
      " 0.6969697  0.61111111 0.43373494 0.82745826 0.86005089 0.87774295\n",
      " 0.85472973 0.68333333 0.85043988 0.6614786  0.80375783 0.40236686\n",
      " 0.48314607 0.59683313 0.55737705 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 128/300, Loss: 0.2245, Accuracy: 0.9189, F1: 0.6705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95486842 0.77325289 0.78546366 0.34594595 0.4        0.23783784\n",
      " 0.32590051 0.44657097 0.48042705 0.         0.67346939 0.73195402\n",
      " 0.59922556 0.67970548 0.4512987  0.27015251 0.704643   0.79851765\n",
      " 0.77150881 0.77605526 0.72869736 0.90367283 0.61581526 0.77713076\n",
      " 0.57415438 0.67429577 0.50498339 0.534689   0.99372805 0.9388137\n",
      " 0.95607482]\n",
      "Training Epoch 129/300, Loss: 0.2059, Accuracy: 0.9042, F1: 0.6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96112347 0.90133333 0.85112782 0.40540541 0.28070175 0.39285714\n",
      " 0.33333333 0.26315789 0.27692308 0.82539683 0.82051282 0.63707572\n",
      " 0.68206821 0.56704981 0.33802817 0.84052533 0.87062937 0.88076312\n",
      " 0.85349233 0.69918699 0.86495726 0.66929134 0.81496881 0.40677966\n",
      " 0.47619048 0.59600998 0.5674548  0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 129/300, Loss: 0.2267, Accuracy: 0.9198, F1: 0.6691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95454545 0.76039604 0.78550296 0.30035336 0.38255034 0.2745098\n",
      " 0.34432234 0.44006568 0.44710579 0.64015595 0.71992898 0.58531842\n",
      " 0.67620345 0.49317837 0.27790433 0.68578071 0.80215966 0.77466251\n",
      " 0.76868656 0.71141597 0.90239468 0.59586207 0.77687381 0.54672489\n",
      " 0.64091308 0.49002529 0.5354516  0.99309912 0.93344976 0.95285212]\n",
      "Training Epoch 130/300, Loss: 0.2055, Accuracy: 0.9022, F1: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96082197 0.896      0.84502924 0.38961039 0.25       0.3943662\n",
      " 0.36666667 0.38095238 0.36619718 0.80933852 0.78772379 0.62871287\n",
      " 0.6687631  0.56537102 0.43589744 0.83615819 0.87260035 0.86862442\n",
      " 0.8526749  0.70136986 0.86376646 0.6374502  0.79170984 0.40677966\n",
      " 0.48387097 0.57022472 0.56474259 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 130/300, Loss: 0.2257, Accuracy: 0.9174, F1: 0.6731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project='NLP_AS2-Q3-P2', name='GV-oo-3', config={'epoch': 130, 'batch_size': batch_size})\n",
    "\n",
    "# Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / sum(sen_lengths)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "\n",
    "# WandB Config\n",
    "config = wandb.config\n",
    "\n",
    "# Watch the model\n",
    "wandb.watch(model)\n",
    "\n",
    "for epoch in range(config.epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    correct_predictions_train = 0\n",
    "    total_sentences_train = 0\n",
    "    predictions_q = []\n",
    "    traget_q = []\n",
    "\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss = torch.sum(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print('loss ',loss)\n",
    "        # Accumulate loss for the epoch\n",
    "        total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "        # Prediction\n",
    "        predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "        temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "#         print(temp_pred)\n",
    "#         print(temp_trag)\n",
    "#         print(\"$$$$\")\n",
    "        predictions_q.extend(temp_pred)\n",
    "        traget_q.extend(temp_trag)\n",
    "\n",
    "        # Update total sentences count\n",
    "        # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for training\n",
    "    average_loss_train = total_loss_train / len(dataloader)\n",
    "    accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "    f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "    print(f1_score(traget_q, predictions_q, average=None))\n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Train Loss': average_loss_train, 'Train Accuracy': accuracy_train, 'Train F1': f1_Score}, step=epoch)\n",
    "    print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    correct_predictions_val = 0\n",
    "    total_sentences_val = 0\n",
    "    predictions_p = []\n",
    "    traget_p = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "            sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "            total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "            # Prediction\n",
    "            predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "            correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            predictions_p.extend(temp_pred)\n",
    "            traget_p.extend(temp_trag)\n",
    "\n",
    "            # Update total sentences count\n",
    "            # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for validation\n",
    "    average_loss_val = total_loss_val / len(dataloader_val)\n",
    "    accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "    f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "    print(f1_score(traget_p, predictions_p, average=None))\n",
    "    \n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Validation Loss': average_loss_val, 'Validation Accuracy': accuracy_val, 'Validation F1': f1_Score}, step=epoch)\n",
    "    print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len([0.95128599,0.20926244,0.13918377 ,   0.    ,              0.    ,             0.       ,             0.     ,         0.      ,   0.   ,        0.99964677 ,     1.        ]))\n",
    "# print(len({'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "#     # Print cumulative value counts after each batch\n",
    "#     print(\"Cumulative Value Counts:\")\n",
    "#     print(cumulative_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Mapping from numeric values to labels\n",
    "# numeric_to_labels = {\n",
    "#     0: 'O', 1: 'B_COURT', 2: 'I_COURT', 3: 'B_PETITIONER', 4: 'I_PETITIONER',\n",
    "#     5: 'B_RESPONDENT', 6: 'I_RESPONDENT', 7: 'B_JUDGE', 8: 'I_JUDGE',\n",
    "#     9: 'B_LAWYER', 10: 'I_LAWYER', 11: 'B_DATE', 12: 'I_DATE',\n",
    "#     13: 'B_ORG', 14: 'I_ORG', 15: 'B_GPE', 16: 'I_GPE',\n",
    "#     17: 'B_STATUTE', 18: 'I_STATUTE', 19: 'B_PROVISION', 20: 'I_PROVISION',\n",
    "#     21: 'B_PRECEDENT', 22: 'I_PRECEDENT', 23: 'B_CASE_NUMBER', 24: 'I_CASE_NUMBER',\n",
    "#     25: 'B_WITNESS', 26: 'I_WITNESS', 27: 'B_OTHER_PERSON', 28: 'I_OTHER_PERSON',\n",
    "#     29: '<START>', 30: '<STOP>', 31: '<PAD>'\n",
    "# }\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "# # Convert numeric values to labels in the cumulative counts\n",
    "# cumulative_counts_labels = {numeric_to_labels[key]: value for key, value in cumulative_counts.items()}\n",
    "\n",
    "# # Remove <PAD> from the counts\n",
    "# cumulative_counts_labels.pop('<PAD>', None)\n",
    "# cumulative_counts_labels.pop('O', None)\n",
    "# # Plot the final cumulative counts with labels (excluding <PAD>) and add count on top of each bar\n",
    "# labels, values = zip(*cumulative_counts_labels.items())\n",
    "# plt.bar(labels, values)\n",
    "# plt.xlabel('Label')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Final Cumulative Value Counts (Excluding <PAD>)')\n",
    "# plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "\n",
    "# # Add count on top of each bar\n",
    "# for label, value in zip(labels, values):\n",
    "#     plt.text(label, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn import metrics\n",
    "# import numpy as np\n",
    "\n",
    "# # Example\n",
    "# cm = confusion_matrix(traget_p, predictions_p, labels=range(12))\n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# # Plot confusion matrix with heat map\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm, annot=True, cmap=\"Blues\",)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(traget_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# # Plot confusion matrix using imshow\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# # sns.set(font_scale=1.2)\n",
    "# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# plt.title('Normalized Confusion Matrix')\n",
    "# plt.colorbar()\n",
    "\n",
    "# classes = range(13)\n",
    "# tick_marks = np.arange(len(classes))\n",
    "# plt.xticks(tick_marks, classes, rotation=45)\n",
    "# plt.yticks(tick_marks, classes)\n",
    "\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(29),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jsluZV6ArICu"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Function to calculate accuracy\n",
    "# import torch\n",
    "\n",
    "# def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         acc += torch.sum(prex == trex)\n",
    "\n",
    "#     # Move the division outside the loop to calculate the average accuracy\n",
    "#     acc = acc.float() / sum(sen_lengths)\n",
    "#     # print(acc)\n",
    "#     return acc\n",
    "\n",
    "# def aggregater(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "#     aggr_pred = []\n",
    "#     aggr_targ = []\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         aggr_pred.extend(prex)\n",
    "#         aggr_targ.extend(trex)\n",
    "#     return aggr_pred,aggr_targ\n",
    "\n",
    "\n",
    "# for epoch in range(300):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss_train = 0\n",
    "#     correct_predictions_train = 0\n",
    "#     total_sentences_train = 0\n",
    "#     predictions_q = []\n",
    "#     traget_q = []\n",
    "\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print('loss ',loss)\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "#         # Prediction\n",
    "#         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "#         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         predictions_q.extend(temp_pred)\n",
    "#         traget_q.extend(temp_trag)\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for training\n",
    "\n",
    "#     average_loss_train = total_loss_train / len(dataloader)\n",
    "#     accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "#     f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "#     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     total_loss_val = 0\n",
    "#     correct_predictions_val = 0\n",
    "#     total_sentences_val = 0\n",
    "#     predictions_p = []\n",
    "#     traget_p = []\n",
    "#     with torch.no_grad():\n",
    "#         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "#             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "#             total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "#             # Prediction\n",
    "#             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "#             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "\n",
    "#             temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "#             predictions_p.extend(temp_pred)\n",
    "#             traget_p.extend(temp_trag)\n",
    "\n",
    "#             # Update total sentences count\n",
    "#             # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for validation\n",
    "#     average_loss_val = total_loss_val / len(dataloader_val)\n",
    "#     accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "#     f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "#     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "\n",
    "#     print()\n",
    "\n",
    "# # # Training and validation loop\n",
    "# # for epoch in range(300):\n",
    "# #     # Training\n",
    "# #     model.train()\n",
    "# #     total_loss_train = 0\n",
    "# #     correct_predictions_train = 0\n",
    "# #     total_sentences_train = 0\n",
    "\n",
    "# #     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #         model.zero_grad()\n",
    "\n",
    "# #         # Forward pass\n",
    "# #         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "# #         # Backward pass and optimization\n",
    "# #         loss = torch.sum(loss)\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "\n",
    "# #         # Accumulate loss for the epoch\n",
    "# #         total_loss_train += loss.item()\n",
    "\n",
    "# #         # Prediction\n",
    "# #         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #         print()\n",
    "# #         # print(len(predictions_train[0]),'predi_len')\n",
    "# #         # print(sen_lengths[0],'sen_len')\n",
    "# #         # print(targets[0][:sen_lengths[0]].shape,'targets_len')\n",
    "# #         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "# #         # Update total sentences count\n",
    "# #         total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for training\n",
    "# #     average_loss_train = total_loss_train / total_sentences_train\n",
    "# #     accuracy_train = correct_predictions_train / len(dataloader)\n",
    "\n",
    "# #     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}')\n",
    "\n",
    "# #     # Validation\n",
    "# #     model.eval()\n",
    "# #     total_loss_val = 0\n",
    "# #     correct_predictions_val = 0\n",
    "# #     total_sentences_val = 0\n",
    "\n",
    "# #     with torch.no_grad():\n",
    "# #         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #             # Forward pass\n",
    "# #             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "# #             total_loss_val += torch.sum(loss_val).item()\n",
    "\n",
    "# #             # Prediction\n",
    "# #             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "# #             # Update total sentences count\n",
    "# #             total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for validation\n",
    "# #     average_loss_val = total_loss_val / total_sentences_val\n",
    "# #     accuracy_val = correct_predictions_val / len(dataloader_val)\n",
    "\n",
    "# #     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wQB_sic2fKxK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: pytorch save model code\n",
    "\n",
    "torch.save(model.state_dict(), 't1_model4_glove.pt')\n",
    "\n",
    "# Save the model to W&B\n",
    "wandb.save(\"t1_model4_glove.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMCRF(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): LSTM(300, 256, bidirectional=True)\n",
       "  (hidden2emit_score): Linear(in_features=512, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "# import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "#import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / (sum(sen_lengths)+10)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n",
    "\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NI0fUN85rWNj"
   },
   "outputs": [],
   "source": [
    "model_state_dict = torch.load('t1_model4_glove.pt')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "json_path = 'NER_test.json'\n",
    "embedding_type = 'glove'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "sentiment_dataset =sentiment_dataset_test\n",
    "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
    "batch_size  = 512\n",
    "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LtLXbDKMZ1bG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9561\n",
      "Test F1:  0.634601841513961\n",
      "[0.95704249 0.86746988 0.82467532 0.28571429 0.55555556 0.\n",
      " 0.         0.4        0.57142857 0.84261501 0.81818182 0.6\n",
      " 0.63951735 0.5448505  0.23255814 0.78411911 0.84076433 0.85654886\n",
      " 0.82568807 0.71974522 0.87146764 0.62135922 0.7574124  0.39534884\n",
      " 0.35294118 0.62955032 0.6088993  1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_sentences_val = 0\n",
    "predictions_r = []\n",
    "traget_r = []\n",
    "epoch=1\n",
    "device='cuda'\n",
    "with torch.no_grad():\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        # Prediction\n",
    "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "        predictions_r.extend(temp_pred)\n",
    "        traget_r.extend(temp_trag)\n",
    "\n",
    "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
    "print()\n",
    "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
    "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6O3vYN9J-BBQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train F1</td><td></td></tr><tr><td>Train Loss</td><td></td></tr><tr><td>Validation Accuracy</td><td></td></tr><tr><td>Validation F1</td><td></td></tr><tr><td>Validation Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.90215</td></tr><tr><td>Train F1</td><td>0.63975</td></tr><tr><td>Train Loss</td><td>0.20549</td></tr><tr><td>Validation Accuracy</td><td>0.91741</td></tr><tr><td>Validation F1</td><td>0.67311</td></tr><tr><td>Validation Loss</td><td>0.2257</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GV-oo-3</strong> at: <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/1i1jg30w' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/1i1jg30w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240309_130531-1i1jg30w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0befd16ce747402b8fd074f82ac58bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "126562022a634f218a533eb2d0cb68ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e627c3c18f7453d843197124428d4e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dab3d6fa9be463b81add125fc796b1b",
      "placeholder": "",
      "style": "IPY_MODEL_f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "value": "0.013 MB of 0.013 MB uploaded\r"
     }
    },
    "5c0c4e0669724ef0a85788b9e1d372b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dab3d6fa9be463b81add125fc796b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a41f20afb91441ebb9d824625a4280e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0befd16ce747402b8fd074f82ac58bef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c0c4e0669724ef0a85788b9e1d372b4",
      "value": 1
     }
    },
    "f97c3e9cd95c4f97a253dda0a8f9b9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fed62b3a309a402dba270a79ae613fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e627c3c18f7453d843197124428d4e3",
       "IPY_MODEL_a41f20afb91441ebb9d824625a4280e1"
      ],
      "layout": "IPY_MODEL_126562022a634f218a533eb2d0cb68ce"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
