{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTExoSN2ShWl",
    "outputId": "ed7eb4df-8c10-442d-cd12-f17da071a3d8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# for i in [\"TRAIN\", \"TEST\"]:\n",
    "#     with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#         raw_data = json.load(json_file)\n",
    "\n",
    "#     # Convert to BILOU format\n",
    "#     bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#     if i == \"TRAIN\":\n",
    "#         # Extract indices from bilou_data\n",
    "#         indices = list(bilou_data.keys())\n",
    "\n",
    "#         # Calculate the number of samples for training\n",
    "#         total_samples = len(indices)\n",
    "#         train_size = int(0.85 * total_samples)\n",
    "\n",
    "#         # Set a fixed seed for reproducibility\n",
    "#         np.random.seed(42)\n",
    "\n",
    "#         # Shuffle the indices\n",
    "#         np.random.shuffle(indices)\n",
    "\n",
    "#         # Split indices into training and validation sets\n",
    "#         train_indices = indices[:train_size]\n",
    "#         val_indices = indices[train_size:]\n",
    "\n",
    "#         # Create training and validation datasets in BILOU format with reset indices\n",
    "#         train_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(train_indices)\n",
    "#         }\n",
    "#         val_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(val_indices)\n",
    "#         }\n",
    "\n",
    "#         # Save the output to JSON files for training\n",
    "#         with open(f'bilou_data_TRAIN.json', 'w') as json_file:\n",
    "#             json.dump(train_bilou_data, json_file, indent=2)\n",
    "\n",
    "#         with open(f'bilou_data_VAL.json', 'w') as json_file:\n",
    "#             json.dump(val_bilou_data, json_file, indent=2)\n",
    "#     elif i == \"TEST\":\n",
    "#         # Save the output to a JSON file for testing\n",
    "#         with open(f'bilou_data_TEST.json', 'w') as json_file:\n",
    "#             json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1JXz9D9SEdxy"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "            \n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import re\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Lowercasing\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # Remove special characters and escape sequences\n",
    "#     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     # Tokenize the text and lemmatize each word\n",
    "#     words = nltk.word_tokenize(text)\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "#     return ' '.join(lemmatized_words)\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         text = preprocess_text(text)  # Apply lowercasing and remove special characters\n",
    "#         text = lemmatize_text(text)   # Apply lemmatization\n",
    "\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Eym7hCkbtYO",
    "outputId": "00a8ff0b-818a-47ea-f438-005230c5afa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B_COURT', 'I_COURT', 'B_PETITIONER', 'I_PETITIONER', 'B_RESPONDENT', 'I_RESPONDENT', 'B_JUDGE', 'I_JUDGE', 'B_LAWYER', 'I_LAWYER', 'B_DATE', 'I_DATE', 'B_ORG', 'I_ORG', 'B_GPE', 'I_GPE', 'B_STATUTE', 'I_STATUTE', 'B_PROVISION', 'I_PROVISION', 'B_PRECEDENT', 'I_PRECEDENT', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'B_WITNESS', 'I_WITNESS', 'B_OTHER_PERSON', 'I_OTHER_PERSON', '<START>', '<STOP>', '<PAD>']\n",
      "{'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n"
     ]
    }
   ],
   "source": [
    "named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER', 'DATE', 'ORG', 'GPE', 'STATUTE', 'PROVISION', 'PRECEDENT', 'CASE_NUMBER', 'WITNESS', 'OTHER_PERSON']\n",
    "# named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER']\n",
    "\n",
    "named_entity_combinations = ['O']\n",
    "\n",
    "for entity in named_entities:\n",
    "    b_entity = \"B_\" + entity\n",
    "    i_entity = \"I_\" + entity\n",
    "    named_entity_combinations.extend([b_entity, i_entity])\n",
    "named_entity_combinations.append('<START>')\n",
    "named_entity_combinations.append('<STOP>')\n",
    "named_entity_combinations.append('<PAD>')\n",
    "print(named_entity_combinations)\n",
    "\n",
    "named_entity_encoding = {entity: idx for idx, entity in enumerate(named_entity_combinations)}\n",
    "\n",
    "print(named_entity_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lQkdf-XdEnfJ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install fasttext\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# !pip install fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWR6lMXiEpYS",
    "outputId": "a95c7dbc-6a41-45df-b306-2cf0a3d6a731",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "#import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# sentiment_dataset.embedding_model= temp.embedding_model\n",
    "# Accessing a sample from the dataset\n",
    "# sample_text_embeddings, sample_labels, mask,s_len = sentiment_dataset[0]\n",
    "# print(\"Sample Text Embeddings:\", sample_text_embeddings)\n",
    "# print(\"Sample Labels:\", sample_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sentiment_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sentiment_dataset)):\n",
    "#     print(sentiment_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xV1g4_jteXTp"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # Set a seed for reproducibility\n",
    "# torch.manual_seed(42)  # You can choose any seed value\n",
    "\n",
    "# total_size = len(sentiment_dataset)\n",
    "# indices = list(range(total_size))\n",
    "\n",
    "# # Define the split sizes\n",
    "# train_size = int(0.85 * total_size)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# # Use the seed for reproducibility when shuffling\n",
    "# torch.randperm(total_size)\n",
    "\n",
    "# # Split the indices\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "\n",
    "# # Create Subset datasets using the indices\n",
    "# train_dataset = torch.utils.data.Subset(sentiment_dataset, train_indices)\n",
    "# val_dataset = torch.utils.data.Subset(sentiment_dataset, val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "__2DRx7cZCHc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03,  ..., -1.0000e+03,\n",
       "          -1.0000e+03, -1.0000e+03],\n",
       "         [ 1.8457e-01,  2.4805e-01,  1.9043e-01,  ..., -1.3086e-01,\n",
       "           1.6797e-01, -2.6953e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]),\n",
       " tensor([29,  0,  0,  0,  0,  0,  0, 19, 20, 17, 18, 18, 18, 30, 31, 31, 31, 31,\n",
       "         31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "         31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "         31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "         31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "         31, 31, 31, 31, 31, 31, 31, 31, 31, 31]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]),\n",
       " tensor(14))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QOxk1a5sTXtN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "batch_size  = 512\n",
    "json_path = \"bilou_data_TRAIN.json\"\n",
    "embedding_type = 'word2vec'\n",
    "sentiment_dataset = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "dataloader = DataLoader(sentiment_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wdA2HAHVqBrT"
   },
   "outputs": [],
   "source": [
    "json_path = \"bilou_data_VAL.json\"\n",
    "sentiment_dataset_val = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_val.embedding_model = sentiment_dataset.embedding_model\n",
    "dataloader_val = DataLoader(sentiment_dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'bilou_data_TEST.json'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7PRU5YYtEtqs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "    # def predict(self, sentences,mask, sen_lengths):\n",
    "    #     \"\"\"\n",
    "    #     Args:\n",
    "    #         sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "    #                             of the longest sentence\n",
    "    #         sen_lengths (list): sentence lengths\n",
    "    #     Returns:\n",
    "    #         tags (list[list[str]]): predicted tags for the batch\n",
    "    #     \"\"\"\n",
    "    #     batch_size = sentences.shape[0]\n",
    "    #     # w = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)\n",
    "    #     w = mask\n",
    "    #     sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "    #     # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "    #     emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "    #     tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "    #     d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "    #     for i in range(1, sen_lengths[0]):\n",
    "    #         n_unfinished = mask[:, i].sum()\n",
    "    #         d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "    #         emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "    #         new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "    #         d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "    #         max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "    #         tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "    #         d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "    #     d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "    #     _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "    #     max_idx = max_idx.tolist()\n",
    "    #     tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "    #     print(tags,sen_lengths,'((()))')\n",
    "    #     return tags\n",
    "\n",
    "    # def save(self, filepath):\n",
    "    #     params = {\n",
    "    #         'sent_vocab': self.sent_vocab,\n",
    "    #         'tag_vocab': self.tag_vocab,\n",
    "    #         'args': dict(dropout_rate=self.dropout_rate, embed_size=self.embed_size, hidden_size=self.hidden_size),\n",
    "    #         'state_dict': self.state_dict()\n",
    "    #     }\n",
    "    #     torch.save(params, filepath)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     sent_vocab = Vocab.load('./vocab/sent_vocab.json')\n",
    "#     tag_vocab = Vocab.load('./vocab/tag_vocab.json')\n",
    "#     train_data, dev_data = utils.generate_train_dev_dataset('./data/train.txt', sent_vocab, tag_vocab)\n",
    "#     device = torch.device('cpu')\n",
    "#     model = BiLSTMCRF(sent_vocab, tag_vocab)\n",
    "#     model.to(device)\n",
    "#     model.save('./model/model.pth')\n",
    "#     model = model.load('./model/model.pth', device)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "argnny6HH0Tu"
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9  # Optional: You can adjust the momentum term\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oHr2iehwItKL"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Check predictions before training\n",
    "# for epoch in range(300):\n",
    "#     total_loss = 0\n",
    "#     correct_predictions = 0\n",
    "#     total_sentences = 0\n",
    "\n",
    "#     # Wrap your dataloader with tqdm for a progress bar\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         # Move input data to GPU\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         total_sentences += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss for the epoch\n",
    "#     average_loss = total_loss / total_sentences\n",
    "\n",
    "#     # Print loss for each epoch\n",
    "#     print(f'Epoch {epoch + 1}/{300}, Loss: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8465903IIQiP",
    "outputId": "59fc2395-654e-4f03-e9f2-6d821084fef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])==torch.tensor([1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2mAtfLRzkl3",
    "outputId": "c8c91803-9f7b-4d97-8972-dec9ac4651d4"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fed62b3a309a402dba270a79ae613fec",
      "4e627c3c18f7453d843197124428d4e3",
      "a41f20afb91441ebb9d824625a4280e1",
      "126562022a634f218a533eb2d0cb68ce",
      "9dab3d6fa9be463b81add125fc796b1b",
      "f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "0befd16ce747402b8fd074f82ac58bef",
      "5c0c4e0669724ef0a85788b9e1d372b4"
     ]
    },
    "id": "5tA2FjdzzM4R",
    "outputId": "c35f5f15-59c2-4ce8-dc71-731ffef8e94f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanvendra\u001b[0m (\u001b[33miiitd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Manvendra Nema\\Notebooks\\Untitled Folder\\wandb\\run-20240309_182441-zu6icu5u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/zu6icu5u' target=\"_blank\">W2V-oo-3</a></strong> to <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/zu6icu5u' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/zu6icu5u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62317632 0.00501567 0.01016043 0.00166667 0.         0.00264901\n",
      " 0.00437637 0.00213789 0.         0.         0.         0.00598546\n",
      " 0.00226757 0.00473093 0.01035971 0.00661157 0.00434783 0.00995025\n",
      " 0.02074178 0.01499395 0.02550037 0.00869222 0.0542711  0.00260247\n",
      " 0.01801477 0.         0.00246914 0.01117035 0.00633357 0.52318283\n",
      " 0.36224953 0.32061006]\n",
      "Training Epoch 1/300, Loss: 23.9654, Accuracy: 0.4186, F1: 0.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84680397 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 1/300, Loss: 11.8440, Accuracy: 0.7589, F1: 0.1281\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76084135 0.00138217 0.01365747 0.         0.00766284 0.\n",
      " 0.00396432 0.00322581 0.         0.         0.00884956 0.0117773\n",
      " 0.00587659 0.01609553 0.00923788 0.00437637 0.01465738 0.01143557\n",
      " 0.01275917 0.0241442  0.00852619 0.06483221 0.00940439 0.\n",
      " 0.00214592 0.01231717 0.01986755 0.00896496 0.80820917 0.78027365\n",
      " 0.47754563]\n",
      "Training Epoch 2/300, Loss: 11.1401, Accuracy: 0.5759, F1: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87469158 0.         0.02527076 0.         0.         0.\n",
      " 0.04545455 0.         0.         0.         0.         0.02988792\n",
      " 0.         0.         0.         0.         0.02415932 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 2/300, Loss: 9.4508, Accuracy: 0.7354, F1: 0.1332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78959414 0.00734908 0.00829563 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00602047\n",
      " 0.01478113 0.         0.01101018 0.01485411 0.         0.00580833\n",
      " 0.02176602 0.00100503 0.02119853 0.01192606 0.09136581 0.00825877\n",
      " 0.03133903 0.00931099 0.         0.00436491 0.02415609 0.79706939\n",
      " 0.76198157 0.5105042 ]\n",
      "Training Epoch 3/300, Loss: 9.2531, Accuracy: 0.6131, F1: 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85207321 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.3127572  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 3/300, Loss: 6.7490, Accuracy: 0.7624, F1: 0.1387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79186587 0.00533689 0.01048565 0.00508906 0.0034965  0.00526316\n",
      " 0.         0.00547945 0.         0.         0.         0.01945525\n",
      " 0.01192606 0.0111828  0.01745411 0.00785855 0.         0.01434034\n",
      " 0.03411306 0.05480277 0.02496608 0.01991701 0.16468246 0.00228571\n",
      " 0.00137033 0.00641026 0.         0.01233141 0.00331492 0.78293249\n",
      " 0.79714001 0.66594586]\n",
      "Training Epoch 4/300, Loss: 6.5286, Accuracy: 0.6182, F1: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85374673 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01010101 0.         0.4\n",
      " 0.         0.         0.         0.01346801 0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 4/300, Loss: 4.7258, Accuracy: 0.7589, F1: 0.1425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78224499 0.01528384 0.02197425 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01797753 0.01546157\n",
      " 0.0203193  0.03102008 0.01946193 0.         0.00707026 0.\n",
      " 0.064531   0.06258422 0.01278409 0.11033717 0.01203008 0.03500222\n",
      " 0.         0.00518807 0.02797486 0.01738088 0.87631405 0.88574499\n",
      " 0.90825138]\n",
      "Training Epoch 5/300, Loss: 6.3079, Accuracy: 0.6174, F1: 0.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75739272 0.         0.         0.         0.         0.01764057\n",
      " 0.         0.         0.         0.01104972 0.         0.02824134\n",
      " 0.02677376 0.         0.         0.         0.         0.12440191\n",
      " 0.06635071 0.         0.         0.         0.         0.\n",
      " 0.         0.06139873 0.0483692  0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 5/300, Loss: 7.3257, Accuracy: 0.5316, F1: 0.1379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.28910509e-01 0.00000000e+00 8.95656068e-04 0.00000000e+00\n",
      " 5.11508951e-03 0.00000000e+00 0.00000000e+00 6.34920635e-03\n",
      " 0.00000000e+00 0.00000000e+00 5.92654424e-02 1.01626016e-02\n",
      " 1.64489598e-02 1.90340233e-02 7.66283525e-03 0.00000000e+00\n",
      " 2.10696921e-02 2.31895077e-02 8.47029077e-02 7.37704918e-02\n",
      " 4.51843044e-02 2.76887567e-01 6.09137056e-03 0.00000000e+00\n",
      " 2.39234450e-03 0.00000000e+00 3.43957808e-02 2.82728949e-02\n",
      " 9.12739434e-01 9.05282443e-01 9.20689655e-01]\n",
      "Training Epoch 6/300, Loss: 5.9967, Accuracy: 0.6732, F1: 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8694197  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.02013423 0.         0.08472687\n",
      " 0.07420043 0.         0.         0.0239521  0.00342466 0.0652819\n",
      " 0.03648425 0.08560311 0.56652361 0.         0.         0.\n",
      " 0.         0.00419287 0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 6/300, Loss: 3.7490, Accuracy: 0.6776, F1: 0.1610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.10323454e-01 2.88461538e-02 2.68714012e-02 0.00000000e+00\n",
      " 5.54016620e-03 0.00000000e+00 3.63636364e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.08690787e-02 0.00000000e+00\n",
      " 2.92825769e-03 8.03535556e-04 1.01010101e-02 0.00000000e+00\n",
      " 1.61460161e-02 3.26167532e-02 1.00392157e-01 9.35904708e-02\n",
      " 6.13656007e-02 3.60997467e-01 1.07692308e-02 3.49137076e-02\n",
      " 5.15463918e-03 2.71370421e-03 3.09455587e-02 2.63246709e-02\n",
      " 8.77267730e-01 9.26862782e-01 9.36612942e-01]\n",
      "Training Epoch 7/300, Loss: 3.8732, Accuracy: 0.6493, F1: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51040564 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04761905 0.         0.\n",
      " 0.         0.         0.         0.01237624 0.04410058 0.02312139\n",
      " 0.04411765 0.06491885 0.30066655 0.         0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 7/300, Loss: 4.0228, Accuracy: 0.3885, F1: 0.1348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.34276469e-01 3.14442413e-02 3.66719243e-02 4.38596491e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.65820234e-02 3.12744332e-03\n",
      " 2.24150398e-02 3.62307326e-02 1.37254902e-02 0.00000000e+00\n",
      " 1.15709835e-02 1.26200274e-02 1.40482574e-01 1.15100671e-01\n",
      " 4.93583416e-02 2.70202020e-01 2.10748156e-03 6.76361177e-04\n",
      " 2.60416667e-03 2.82485876e-03 2.90322581e-02 3.88856645e-02\n",
      " 8.92198208e-01 9.13846922e-01 9.20191159e-01]\n",
      "Training Epoch 8/300, Loss: 4.5630, Accuracy: 0.6873, F1: 0.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87200445 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.37691002 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5735568\n",
      " 0.40909091 0.05357143 0.61151079 0.         0.         0.\n",
      " 0.         0.         0.         0.99858557 0.99964677 0.99823757]\n",
      "Validation Epoch 8/300, Loss: 3.4469, Accuracy: 0.7922, F1: 0.1964\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83624239 0.03008204 0.04094631 0.         0.         0.\n",
      " 0.         0.         0.         0.07438017 0.03994789 0.01197605\n",
      " 0.00932401 0.01675258 0.         0.01786439 0.05080545 0.21416881\n",
      " 0.1630964  0.06644239 0.44484924 0.         0.00129282 0.00242718\n",
      " 0.00228571 0.02664446 0.02188982 0.94873096 0.92919749 0.93349797]\n",
      "Training Epoch 9/300, Loss: 2.9239, Accuracy: 0.6982, F1: 0.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85187024 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01219512\n",
      " 0.00673401 0.         0.29139073 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 9/300, Loss: 3.8098, Accuracy: 0.7674, F1: 0.1387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82955134 0.03013393 0.03589269 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13061224 0.02325581\n",
      " 0.01457018 0.01948788 0.01238739 0.         0.00594943 0.01991591\n",
      " 0.11712846 0.0744249  0.05491585 0.41955426 0.00674764 0.04558767\n",
      " 0.00248756 0.00521512 0.02795286 0.02897694 0.91729323 0.92063293\n",
      " 0.942745  ]\n",
      "Training Epoch 10/300, Loss: 3.5968, Accuracy: 0.6863, F1: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87832599 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2567325  0.         0.\n",
      " 0.         0.         0.         0.07775378 0.04318489 0.12\n",
      " 0.06818182 0.07459207 0.64223287 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 10/300, Loss: 3.2511, Accuracy: 0.7808, F1: 0.1720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8303797  0.0157767  0.01109467 0.00472813 0.         0.00687285\n",
      " 0.00968523 0.         0.         0.         0.06392694 0.02140078\n",
      " 0.03046974 0.03207428 0.01240835 0.         0.01718582 0.04310732\n",
      " 0.12530473 0.09979267 0.07770134 0.45612173 0.         0.\n",
      " 0.00946746 0.00564972 0.04042611 0.03183349 0.95631553 0.92655226\n",
      " 0.93569872]\n",
      "Training Epoch 11/300, Loss: 3.7348, Accuracy: 0.6888, F1: 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88305756 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01384083 0.         0.\n",
      " 0.01279318 0.         0.         0.         0.         0.31876607\n",
      " 0.         0.0234375  0.46083222 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 11/300, Loss: 2.6067, Accuracy: 0.7569, F1: 0.1570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82454932 0.01746324 0.0218963  0.00487805 0.         0.\n",
      " 0.         0.004662   0.00626959 0.11558669 0.01917211 0.02129817\n",
      " 0.02527358 0.00892288 0.         0.0203476  0.04281854 0.22137791\n",
      " 0.15761413 0.04485777 0.36985507 0.01588142 0.04897478 0.00508259\n",
      " 0.00284091 0.02713064 0.02791302 0.90219507 0.92427937 0.93810562]\n",
      "Training Epoch 12/300, Loss: 2.6833, Accuracy: 0.6779, F1: 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87347413 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.52534562 0.         0.\n",
      " 0.         0.         0.         0.02710027 0.00665557 0.60285132\n",
      " 0.41534392 0.17492711 0.67800729 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 12/300, Loss: 2.1569, Accuracy: 0.7982, F1: 0.2101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84011312 0.02554028 0.02414929 0.         0.         0.01315789\n",
      " 0.01348315 0.         0.         0.         0.19903126 0.0184528\n",
      " 0.02130178 0.01958651 0.02379461 0.         0.02299703 0.04106776\n",
      " 0.25806452 0.19167235 0.06838906 0.36864994 0.01111111 0.04630175\n",
      " 0.00716846 0.00269542 0.0279965  0.0275172  0.9527027  0.921375\n",
      " 0.93800989]\n",
      "Training Epoch 13/300, Loss: 2.6907, Accuracy: 0.6924, F1: 0.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88292896 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.47544204 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.64187867\n",
      " 0.46482412 0.         0.2515908  0.         0.01876466 0.02949853\n",
      " 0.02380952 0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 13/300, Loss: 2.3976, Accuracy: 0.7689, F1: 0.1929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80518957 0.01929571 0.0370923  0.         0.0042735  0.\n",
      " 0.00906002 0.         0.         0.         0.13035241 0.04165171\n",
      " 0.01804124 0.0305742  0.01339585 0.         0.01515917 0.00827762\n",
      " 0.17177298 0.12138959 0.04916421 0.38120061 0.00939518 0.05152027\n",
      " 0.01244444 0.00415369 0.01794297 0.02060568 0.90725351 0.92556594\n",
      " 0.94532065]\n",
      "Training Epoch 14/300, Loss: 3.4952, Accuracy: 0.6523, F1: 0.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83431097 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07510647 0.         0.\n",
      " 0.         0.01162791 0.02312139 0.04137931 0.07278743 0.25347759\n",
      " 0.         0.16860465 0.66979965 0.02536743 0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 14/300, Loss: 3.7209, Accuracy: 0.6436, F1: 0.1724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.848255   0.03921569 0.04425669 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.08992416 0.0058309\n",
      " 0.00721154 0.00917081 0.01623985 0.         0.01896858 0.04228137\n",
      " 0.08857645 0.07351908 0.05901374 0.43899197 0.00817661 0.04573503\n",
      " 0.         0.00481928 0.04421385 0.04410719 0.9609918  0.92307692\n",
      " 0.93367226]\n",
      "Training Epoch 15/300, Loss: 3.5002, Accuracy: 0.7069, F1: 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87281582 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.47713718 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.57749469\n",
      " 0.38326586 0.         0.64060357 0.         0.         0.\n",
      " 0.         0.         0.         0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 15/300, Loss: 2.1750, Accuracy: 0.7952, F1: 0.1983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82867152 0.02331606 0.0173454  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.18389166 0.06443299\n",
      " 0.01784038 0.02935995 0.02541296 0.01775148 0.02066116 0.05038394\n",
      " 0.30452846 0.23522028 0.05369966 0.49749124 0.00821918 0.03784666\n",
      " 0.00831601 0.00979192 0.02638846 0.02189531 0.94340824 0.93254142\n",
      " 0.94456303]\n",
      "Training Epoch 16/300, Loss: 2.5310, Accuracy: 0.6855, F1: 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90066639 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25071225 0.1154185  0.\n",
      " 0.         0.04469274 0.         0.05442177 0.         0.52375152\n",
      " 0.38645112 0.         0.69717191 0.         0.         0.\n",
      " 0.         0.12909633 0.09395018 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 16/300, Loss: 2.6325, Accuracy: 0.7605, F1: 0.2065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86632498 0.05638767 0.05426207 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15463042 0.07723395\n",
      " 0.03056027 0.03919434 0.01897019 0.         0.05639913 0.01839518\n",
      " 0.36842105 0.28977722 0.10090817 0.53780111 0.00364631 0.00976205\n",
      " 0.00451467 0.00741656 0.05710886 0.04349259 0.97019176 0.92137362\n",
      " 0.93595707]\n",
      "Training Epoch 17/300, Loss: 3.0393, Accuracy: 0.7311, F1: 0.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87413492 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.40243902 0.         0.\n",
      " 0.         0.02247191 0.         0.11989101 0.         0.66156788\n",
      " 0.45721584 0.         0.37623098 0.03802281 0.         0.\n",
      " 0.         0.12269939 0.06578947 0.99929329 0.99964677 0.9989418 ]\n",
      "Validation Epoch 17/300, Loss: 2.3929, Accuracy: 0.7217, F1: 0.2046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8173282  0.02670776 0.03368894 0.         0.         0.00623053\n",
      " 0.00716846 0.         0.         0.         0.17602041 0.04925125\n",
      " 0.01846154 0.02959455 0.02486911 0.00641026 0.03436929 0.02795864\n",
      " 0.37584255 0.30939586 0.02850627 0.37488481 0.00715564 0.03484379\n",
      " 0.0097561  0.00416233 0.03715567 0.04043646 0.9596846  0.92311551\n",
      " 0.93858013]\n",
      "Training Epoch 18/300, Loss: 3.1531, Accuracy: 0.6776, F1: 0.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89368888 0.         0.         0.00881057 0.         0.\n",
      " 0.         0.         0.         0.11464968 0.         0.\n",
      " 0.0747236  0.03238866 0.         0.         0.         0.66666667\n",
      " 0.46683673 0.         0.65830583 0.         0.         0.\n",
      " 0.         0.16183412 0.12038835 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 18/300, Loss: 2.6964, Accuracy: 0.7377, F1: 0.2066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.856626   0.05348048 0.05152409 0.0047619  0.         0.\n",
      " 0.         0.         0.         0.26272292 0.02391629 0.01698514\n",
      " 0.03722504 0.0339196  0.         0.04663024 0.05447324 0.41621912\n",
      " 0.32925507 0.10204902 0.56433866 0.00576369 0.00459318 0.01230769\n",
      " 0.01771872 0.03262159 0.03296703 0.96638602 0.92641072 0.94752187]\n",
      "Training Epoch 19/300, Loss: 3.4045, Accuracy: 0.7275, F1: 0.1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86495129 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.51124744 0.         0.\n",
      " 0.         0.0106383  0.         0.         0.         0.66878981\n",
      " 0.49694501 0.00925926 0.08447614 0.         0.         0.\n",
      " 0.         0.00928074 0.0058651  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 19/300, Loss: 2.8168, Accuracy: 0.7774, F1: 0.1887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82041332 0.03707865 0.03806805 0.         0.         0.\n",
      " 0.00469484 0.         0.         0.         0.23689641 0.0513186\n",
      " 0.03458213 0.03864734 0.03105152 0.         0.04329974 0.04454487\n",
      " 0.26583493 0.19379241 0.08082707 0.35586481 0.00682012 0.00557276\n",
      " 0.01342282 0.0172043  0.02903027 0.02824664 0.96641318 0.9322868\n",
      " 0.9371192 ]\n",
      "Training Epoch 20/300, Loss: 2.9369, Accuracy: 0.6765, F1: 0.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88720743 0.05050505 0.02832861 0.         0.         0.\n",
      " 0.         0.         0.         0.26923077 0.0195122  0.06642066\n",
      " 0.         0.09266409 0.         0.04545455 0.         0.3107089\n",
      " 0.16676701 0.09615385 0.67778477 0.         0.         0.\n",
      " 0.         0.04670913 0.05759162 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 20/300, Loss: 2.0339, Accuracy: 0.7243, F1: 0.1938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86979635 0.08389585 0.07034173 0.         0.         0.\n",
      " 0.         0.00904977 0.01176471 0.25924542 0.06838407 0.03309481\n",
      " 0.04320637 0.03119584 0.00591716 0.03277061 0.01645049 0.21972374\n",
      " 0.12770916 0.15510556 0.5960773  0.02328042 0.05891264 0.02155887\n",
      " 0.01643385 0.05454545 0.05832187 0.97029208 0.93254068 0.94809603]\n",
      "Training Epoch 21/300, Loss: 2.7223, Accuracy: 0.7348, F1: 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89372952 0.38823529 0.24908425 0.         0.         0.\n",
      " 0.         0.         0.         0.47665848 0.08372093 0.00917431\n",
      " 0.         0.08823529 0.         0.06756757 0.         0.10982659\n",
      " 0.0620915  0.13550136 0.68370607 0.         0.         0.\n",
      " 0.         0.13026316 0.11506141 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 21/300, Loss: 2.5366, Accuracy: 0.7824, F1: 0.2164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8411215  0.03383277 0.04273504 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.25711821 0.07624113\n",
      " 0.02128992 0.01624815 0.02225519 0.         0.07640608 0.04789316\n",
      " 0.32363636 0.25654745 0.12969589 0.48164611 0.00287977 0.0270936\n",
      " 0.00598205 0.00632244 0.02826855 0.03391685 0.96585924 0.92662552\n",
      " 0.93602292]\n",
      "Training Epoch 22/300, Loss: 2.3390, Accuracy: 0.6987, F1: 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29648841 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.02061856 0.         0.\n",
      " 0.         0.01156069 0.         0.08372093 0.08862378 0.61447563\n",
      " 0.47179487 0.00847458 0.37724289 0.         0.         0.\n",
      " 0.         0.03786575 0.03021759 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 22/300, Loss: 3.5617, Accuracy: 0.2511, F1: 0.1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83048791 0.02390438 0.02961019 0.         0.         0.\n",
      " 0.         0.00468384 0.         0.23196493 0.03907496 0.01918265\n",
      " 0.02645291 0.03454039 0.         0.02649508 0.02714067 0.18515382\n",
      " 0.14934155 0.06842349 0.32801003 0.01985816 0.04991294 0.00531444\n",
      " 0.00761905 0.01406564 0.01393405 0.97411085 0.92496555 0.94529459]\n",
      "Training Epoch 23/300, Loss: 2.5181, Accuracy: 0.6869, F1: 0.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88290124 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.40159574 0.         0.\n",
      " 0.         0.08247423 0.         0.05882353 0.         0.51890034\n",
      " 0.02337229 0.01634877 0.63780859 0.         0.         0.\n",
      " 0.         0.0890411  0.00606061 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 23/300, Loss: 2.0005, Accuracy: 0.7921, F1: 0.1905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86307487 0.03073662 0.02288022 0.         0.00485437 0.\n",
      " 0.         0.         0.         0.         0.23094512 0.07122391\n",
      " 0.02961396 0.04469274 0.02647546 0.00606061 0.0590928  0.05887507\n",
      " 0.29066265 0.24344317 0.12471132 0.53134699 0.01758242 0.05107477\n",
      " 0.00898876 0.00504414 0.04917235 0.05230623 0.96697725 0.93302512\n",
      " 0.94780793]\n",
      "Training Epoch 24/300, Loss: 2.2897, Accuracy: 0.7204, F1: 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90719666 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.30515063 0.13060179 0.\n",
      " 0.         0.12345679 0.         0.06756757 0.         0.74641148\n",
      " 0.55432373 0.44917258 0.72329603 0.         0.         0.\n",
      " 0.         0.07459207 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 24/300, Loss: 1.5766, Accuracy: 0.7931, F1: 0.2360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84696634 0.08040593 0.06889034 0.         0.         0.\n",
      " 0.         0.         0.         0.21232306 0.04368932 0.03488372\n",
      " 0.04144852 0.0372093  0.00609756 0.05810928 0.05204918 0.4567399\n",
      " 0.35704372 0.10734177 0.48935428 0.02631579 0.0699423  0.00419287\n",
      " 0.00435256 0.03517139 0.03641092 0.9616172  0.9288038  0.94254839]\n",
      "Training Epoch 25/300, Loss: 1.7322, Accuracy: 0.7154, F1: 0.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86201466 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.08754209 0.         0.\n",
      " 0.         0.03448276 0.         0.08       0.         0.53125\n",
      " 0.34166667 0.08530806 0.50118203 0.         0.         0.\n",
      " 0.         0.         0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 25/300, Loss: 2.5973, Accuracy: 0.7849, F1: 0.1841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83582381 0.12331081 0.10323638 0.00308642 0.00296296 0.\n",
      " 0.         0.         0.         0.         0.21900665 0.02394366\n",
      " 0.02305476 0.01534356 0.0202977  0.         0.06935201 0.04503518\n",
      " 0.31756389 0.2961768  0.08405342 0.31774067 0.01962264 0.05056969\n",
      " 0.00876232 0.00912201 0.04258993 0.04533611 0.96900346 0.92385787\n",
      " 0.94131355]\n",
      "Training Epoch 26/300, Loss: 3.1051, Accuracy: 0.6874, F1: 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87767917 0.14790287 0.09244936 0.         0.         0.\n",
      " 0.         0.         0.         0.06802721 0.         0.07351077\n",
      " 0.05546995 0.07207207 0.         0.1300813  0.         0.52914798\n",
      " 0.56356877 0.10041841 0.65833854 0.         0.         0.\n",
      " 0.         0.01098901 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 26/300, Loss: 2.2588, Accuracy: 0.7046, F1: 0.2126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86429531 0.09043113 0.06296152 0.         0.         0.\n",
      " 0.         0.         0.         0.2551409  0.06398617 0.03204047\n",
      " 0.05425007 0.03463759 0.         0.06467458 0.06223663 0.41971154\n",
      " 0.34944027 0.14236283 0.51078977 0.02220851 0.06861925 0.00227015\n",
      " 0.         0.04301075 0.02794272 0.96994726 0.93575682 0.95487555]\n",
      "Training Epoch 27/300, Loss: 1.6407, Accuracy: 0.7213, F1: 0.2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89850077 0.01030928 0.00573066 0.         0.         0.\n",
      " 0.         0.         0.         0.3286119  0.04878049 0.18181818\n",
      " 0.13661202 0.         0.         0.         0.         0.6167979\n",
      " 0.46369554 0.52493438 0.75856574 0.         0.         0.\n",
      " 0.         0.07906977 0.02366864 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 27/300, Loss: 0.9819, Accuracy: 0.7882, F1: 0.2359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.837948   0.04318489 0.03092006 0.         0.00514139 0.\n",
      " 0.00470588 0.         0.00557103 0.28494382 0.03611111 0.02965599\n",
      " 0.02676978 0.03739612 0.00607903 0.08578237 0.04970087 0.46830383\n",
      " 0.38448567 0.14528302 0.49493981 0.0041841  0.03352797 0.01363636\n",
      " 0.0125     0.04763179 0.04678709 0.97089964 0.92876352 0.94569942]\n",
      "Training Epoch 28/300, Loss: 1.6075, Accuracy: 0.7092, F1: 0.1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85146595 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.12297735 0.01980198 0.\n",
      " 0.         0.         0.         0.0738255  0.         0.5158371\n",
      " 0.32440056 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 28/300, Loss: 3.7601, Accuracy: 0.7672, F1: 0.1636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85723997 0.13415794 0.11352488 0.00723327 0.00363636 0.00508906\n",
      " 0.01197605 0.         0.         0.27074236 0.10685104 0.04135554\n",
      " 0.02642948 0.03       0.0195122  0.13094245 0.04723032 0.44164524\n",
      " 0.37274196 0.14325069 0.54979621 0.02103418 0.00262209 0.01803607\n",
      " 0.02340426 0.04009721 0.04257768 0.97290827 0.91924453 0.94254446]\n",
      "Training Epoch 29/300, Loss: 3.2815, Accuracy: 0.7341, F1: 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89493185 0.53676471 0.33718245 0.         0.         0.\n",
      " 0.         0.         0.         0.38895558 0.         0.03703704\n",
      " 0.02364066 0.04166667 0.         0.23631124 0.         0.76007005\n",
      " 0.55197133 0.04891304 0.63712491 0.         0.         0.02087683\n",
      " 0.02794411 0.07906977 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 29/300, Loss: 2.6180, Accuracy: 0.8046, F1: 0.2540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87295487 0.22643063 0.19763023 0.         0.         0.\n",
      " 0.         0.         0.         0.31378764 0.10263158 0.06806986\n",
      " 0.06357301 0.03672131 0.         0.14182344 0.12160494 0.47325328\n",
      " 0.35987362 0.19963866 0.62464183 0.01569859 0.01278928 0.00890869\n",
      " 0.01196172 0.04965431 0.04221825 0.97613636 0.92962152 0.94731018]\n",
      "Training Epoch 30/300, Loss: 2.2966, Accuracy: 0.7483, F1: 0.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90386982 0.58358663 0.35413153 0.         0.         0.\n",
      " 0.         0.         0.         0.37465565 0.01980198 0.\n",
      " 0.         0.05347594 0.         0.10457516 0.04682274 0.66795367\n",
      " 0.47607053 0.48148148 0.72556298 0.         0.         0.\n",
      " 0.         0.12872238 0.07992734 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 30/300, Loss: 1.3538, Accuracy: 0.8086, F1: 0.2666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86713328 0.31071983 0.20045977 0.         0.         0.01186944\n",
      " 0.00744879 0.         0.         0.32217408 0.15247964 0.04272517\n",
      " 0.03150407 0.04574333 0.00537634 0.24209651 0.18366549 0.47083775\n",
      " 0.39486731 0.1430575  0.45665511 0.02413273 0.09214372 0.02254098\n",
      " 0.01505376 0.03658152 0.02834258 0.97595025 0.93560464 0.95063436]\n",
      "Training Epoch 31/300, Loss: 1.2371, Accuracy: 0.7349, F1: 0.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.893712   0.45060659 0.18881119 0.         0.         0.\n",
      " 0.         0.         0.         0.32400932 0.10967742 0.\n",
      " 0.         0.08910891 0.03389831 0.44782609 0.42557652 0.67966574\n",
      " 0.5745554  0.17045455 0.6939433  0.         0.01234568 0.04266667\n",
      " 0.00537634 0.06557377 0.00593472 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 31/300, Loss: 0.6272, Accuracy: 0.7445, F1: 0.2737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86067909 0.15556938 0.09807692 0.00784314 0.00394477 0.00727273\n",
      " 0.00519481 0.         0.         0.33018057 0.09375    0.05771249\n",
      " 0.04867345 0.0446304  0.         0.15833005 0.08734053 0.49810219\n",
      " 0.37842713 0.10415826 0.35481024 0.02932961 0.07576602 0.00747198\n",
      " 0.00816327 0.05285802 0.04896422 0.97513952 0.92816919 0.94749785]\n",
      "Training Epoch 32/300, Loss: 1.3145, Accuracy: 0.7190, F1: 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89115506 0.01030928 0.00573066 0.         0.         0.\n",
      " 0.01886792 0.         0.         0.20842572 0.11436541 0.\n",
      " 0.         0.07511737 0.         0.06756757 0.         0.67003367\n",
      " 0.4874552  0.45909091 0.66802444 0.07290401 0.13857845 0.\n",
      " 0.         0.15980025 0.08064516 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 32/300, Loss: 1.4070, Accuracy: 0.7336, F1: 0.2376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86403696 0.16425572 0.12066508 0.00808081 0.00390625 0.\n",
      " 0.         0.00411523 0.         0.36357117 0.1511879  0.05030181\n",
      " 0.04910418 0.04604854 0.         0.20666385 0.06929798 0.42619746\n",
      " 0.30215637 0.17529138 0.58128535 0.02321981 0.06680664 0.01419878\n",
      " 0.01472135 0.05618303 0.06095703 0.96922012 0.924566   0.9388322 ]\n",
      "Training Epoch 33/300, Loss: 1.5075, Accuracy: 0.7376, F1: 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89578382 0.65562914 0.43196544 0.         0.         0.\n",
      " 0.         0.         0.         0.53658537 0.32618026 0.\n",
      " 0.         0.15853659 0.         0.49694501 0.         0.75922671\n",
      " 0.5508982  0.21138211 0.70207254 0.         0.         0.\n",
      " 0.01273885 0.07906977 0.0123839  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 33/300, Loss: 1.2233, Accuracy: 0.8197, F1: 0.2943\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87995545 0.31189084 0.22005642 0.         0.         0.00682594\n",
      " 0.00493827 0.         0.         0.38583333 0.16675298 0.0623608\n",
      " 0.04242564 0.0477193  0.         0.15661376 0.13728995 0.48992336\n",
      " 0.37958253 0.31627907 0.66666667 0.03858121 0.10080351 0.00443459\n",
      " 0.01193317 0.05064124 0.05010586 0.97816317 0.92950522 0.94929252]\n",
      "Training Epoch 34/300, Loss: 0.9360, Accuracy: 0.7608, F1: 0.2463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90780142 0.53228963 0.37810945 0.         0.         0.\n",
      " 0.         0.         0.         0.59388646 0.15454545 0.\n",
      " 0.         0.12121212 0.         0.30958231 0.20468557 0.73431734\n",
      " 0.53003534 0.55102041 0.76418733 0.         0.         0.\n",
      " 0.         0.10546875 0.06557377 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 34/300, Loss: 0.6312, Accuracy: 0.8275, F1: 0.2984\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86395317 0.16025067 0.08896628 0.00433839 0.         0.\n",
      " 0.         0.         0.         0.35849818 0.10181257 0.06261682\n",
      " 0.04317269 0.04758757 0.00595238 0.18421053 0.08862459 0.49863313\n",
      " 0.40688423 0.18862816 0.49284595 0.02876609 0.06356245 0.01724138\n",
      " 0.01975851 0.05593923 0.0436205  0.9781731  0.92437395 0.9420854 ]\n",
      "Training Epoch 35/300, Loss: 1.0103, Accuracy: 0.7323, F1: 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90243135 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.48498845 0.07619048 0.07407407\n",
      " 0.0658083  0.11904762 0.         0.00696864 0.         0.7266055\n",
      " 0.52281134 0.45929019 0.68571429 0.         0.         0.\n",
      " 0.         0.08678501 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 35/300, Loss: 0.9579, Accuracy: 0.8129, F1: 0.2403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88376709 0.09596929 0.05727377 0.0046729  0.         0.\n",
      " 0.         0.         0.         0.40078895 0.21794872 0.07134768\n",
      " 0.0621118  0.06382979 0.0119403  0.23544198 0.18538257 0.53784219\n",
      " 0.44663229 0.19631336 0.57110702 0.07634543 0.12879239 0.01089325\n",
      " 0.01643192 0.06407465 0.06689378 0.97976732 0.93064849 0.94963331]\n",
      "Training Epoch 36/300, Loss: 0.9069, Accuracy: 0.7623, F1: 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90427956 0.02040816 0.01139601 0.         0.         0.\n",
      " 0.         0.         0.         0.52929293 0.37333333 0.21749409\n",
      " 0.1373494  0.11111111 0.         0.18987342 0.01715266 0.75302245\n",
      " 0.54897494 0.02307692 0.3966725  0.1796875  0.2329422  0.\n",
      " 0.         0.09174312 0.0123839  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 36/300, Loss: 0.6905, Accuracy: 0.7911, F1: 0.2583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85776208 0.20906568 0.14403893 0.         0.         0.\n",
      " 0.         0.         0.         0.37545126 0.22365765 0.06124498\n",
      " 0.07363886 0.03800786 0.         0.12564991 0.06599757 0.50876201\n",
      " 0.41448487 0.17652411 0.47072206 0.03697749 0.08976378 0.01079914\n",
      " 0.01594533 0.04841348 0.03776224 0.97841909 0.92523657 0.94502795]\n",
      "Training Epoch 37/300, Loss: 1.0851, Accuracy: 0.7304, F1: 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89510182 0.66883117 0.45356371 0.         0.         0.\n",
      " 0.         0.         0.         0.43763676 0.32156863 0.\n",
      " 0.         0.11111111 0.         0.45548654 0.         0.64043419\n",
      " 0.48441674 0.22888283 0.72431078 0.         0.         0.\n",
      " 0.         0.00938967 0.01169591 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 37/300, Loss: 1.5034, Accuracy: 0.8194, F1: 0.2814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89127159 0.30019493 0.23535039 0.01965602 0.01595745 0.00735294\n",
      " 0.01044386 0.         0.         0.40569992 0.30619796 0.06541555\n",
      " 0.07429765 0.04983165 0.02680965 0.18059072 0.07185273 0.50518842\n",
      " 0.39554742 0.33082707 0.66801502 0.06056435 0.12791069 0.01758794\n",
      " 0.01646091 0.08341    0.07430341 0.98029308 0.92817955 0.9442708 ]\n",
      "Training Epoch 38/300, Loss: 1.2766, Accuracy: 0.7730, F1: 0.2598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91684504 0.53875969 0.44274809 0.         0.         0.\n",
      " 0.         0.         0.         0.6252588  0.48910412 0.11612903\n",
      " 0.13502935 0.20720721 0.         0.22222222 0.         0.79396985\n",
      " 0.59292035 0.53521127 0.74878758 0.         0.         0.\n",
      " 0.         0.11428571 0.05157593 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 38/300, Loss: 0.8649, Accuracy: 0.8295, F1: 0.3176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83868649 0.31910352 0.21496599 0.00898876 0.0046729  0.\n",
      " 0.         0.         0.         0.32085561 0.18245923 0.04297851\n",
      " 0.05165525 0.04180715 0.01139601 0.14477563 0.0979126  0.46183844\n",
      " 0.34745495 0.13039216 0.27944157 0.04354588 0.08230153 0.00808898\n",
      " 0.01209677 0.03935957 0.0349076  0.9791838  0.93463561 0.95389586]\n",
      "Training Epoch 39/300, Loss: 1.6255, Accuracy: 0.7010, F1: 0.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85120385 0.59598854 0.36686391 0.         0.         0.\n",
      " 0.         0.         0.         0.19186047 0.05607477 0.09977324\n",
      " 0.07280267 0.03314917 0.         0.25958702 0.18259629 0.66248038\n",
      " 0.52703732 0.         0.         0.         0.         0.\n",
      " 0.         0.11530815 0.02933985 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 39/300, Loss: 1.4886, Accuracy: 0.6491, F1: 0.2348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87995544 0.26541176 0.18447218 0.00852878 0.0091954  0.0058309\n",
      " 0.00324149 0.         0.         0.30750104 0.16303005 0.04727273\n",
      " 0.02353834 0.05156538 0.01764706 0.16179585 0.09895944 0.48368201\n",
      " 0.38346469 0.1301821  0.44143694 0.05259698 0.11463096 0.00897868\n",
      " 0.00498753 0.06813255 0.07209527 0.97828831 0.93324166 0.95301688]\n",
      "Training Epoch 40/300, Loss: 1.2848, Accuracy: 0.7440, F1: 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91353795 0.69680851 0.46391753 0.         0.         0.\n",
      " 0.         0.         0.         0.38547486 0.04878049 0.\n",
      " 0.         0.1        0.         0.38289963 0.28376535 0.73700306\n",
      " 0.59060403 0.41590214 0.63944749 0.01136364 0.         0.\n",
      " 0.         0.16569767 0.13680782 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 40/300, Loss: 0.9482, Accuracy: 0.8105, F1: 0.2990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87902942 0.39395575 0.31660011 0.0049505  0.00537634 0.\n",
      " 0.         0.         0.         0.36548223 0.25549081 0.06773773\n",
      " 0.05178446 0.0503876  0.00536193 0.20433437 0.12603648 0.50576606\n",
      " 0.37672614 0.22767237 0.62149459 0.06133333 0.12601207 0.01333333\n",
      " 0.02298851 0.05200433 0.05860534 0.98472563 0.93602399 0.95429749]\n",
      "Training Epoch 41/300, Loss: 0.8592, Accuracy: 0.7619, F1: 0.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89145082 0.74418605 0.55493482 0.         0.         0.\n",
      " 0.         0.         0.         0.60728745 0.3697479  0.\n",
      " 0.         0.12121212 0.         0.04109589 0.         0.67716535\n",
      " 0.45994832 0.31197772 0.73119645 0.         0.         0.\n",
      " 0.         0.00959233 0.00611621 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 41/300, Loss: 0.8299, Accuracy: 0.8182, F1: 0.2841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8604716  0.32739528 0.20825924 0.         0.         0.00419287\n",
      " 0.00593472 0.         0.         0.3673947  0.07425919 0.03405755\n",
      " 0.02537914 0.05183312 0.00503778 0.14581458 0.08570251 0.45599527\n",
      " 0.34682884 0.23905429 0.56757558 0.02730819 0.04565631 0.02125604\n",
      " 0.02294455 0.05392005 0.05137728 0.9745897  0.92205597 0.94288846]\n",
      "Training Epoch 42/300, Loss: 1.2139, Accuracy: 0.7298, F1: 0.2289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91655616 0.48576214 0.22757112 0.         0.         0.\n",
      " 0.         0.         0.         0.56880734 0.20512821 0.10191083\n",
      " 0.07788945 0.1182266  0.         0.20625    0.02725724 0.79518072\n",
      " 0.64808362 0.57662338 0.78418803 0.         0.         0.01226994\n",
      " 0.         0.21822272 0.1993205  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 42/300, Loss: 1.1862, Accuracy: 0.8037, F1: 0.3056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8843452  0.29972145 0.17989656 0.         0.         0.\n",
      " 0.         0.         0.         0.42171027 0.20321285 0.08242045\n",
      " 0.063984   0.0443828  0.         0.15737204 0.13644676 0.51719469\n",
      " 0.43106796 0.30703826 0.68239527 0.03816132 0.01802922 0.00745342\n",
      " 0.00794702 0.07225721 0.06277721 0.98685121 0.93161967 0.95160517]\n",
      "Training Epoch 43/300, Loss: 1.4092, Accuracy: 0.7698, F1: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90460571 0.55350554 0.35211268 0.         0.         0.\n",
      " 0.         0.         0.         0.59962756 0.26382979 0.230563\n",
      " 0.         0.11764706 0.         0.43044619 0.16074189 0.80067568\n",
      " 0.59917355 0.51454139 0.74165029 0.         0.         0.\n",
      " 0.         0.11650485 0.0521327  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 43/300, Loss: 0.9899, Accuracy: 0.8306, F1: 0.3145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86407305 0.35294118 0.26481656 0.00412371 0.00394477 0.\n",
      " 0.         0.00437637 0.00564972 0.38061466 0.20792079 0.05175601\n",
      " 0.0537722  0.04145078 0.         0.20627451 0.12320806 0.49878804\n",
      " 0.40450737 0.28638278 0.57603711 0.03606103 0.0642598  0.00454545\n",
      " 0.00687285 0.08077437 0.06371563 0.97828427 0.92345185 0.94113416]\n",
      "Training Epoch 44/300, Loss: 0.9487, Accuracy: 0.7387, F1: 0.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88161156 0.41310541 0.1575325  0.03225806 0.03636364 0.\n",
      " 0.         0.         0.         0.44743935 0.1799569  0.1\n",
      " 0.08538588 0.07253886 0.         0.43421053 0.40618557 0.76547231\n",
      " 0.62165775 0.50273224 0.77863962 0.         0.         0.03468208\n",
      " 0.         0.20743034 0.12587413 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 44/300, Loss: 0.6534, Accuracy: 0.7405, F1: 0.3094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86781371 0.37397485 0.29103609 0.00468384 0.         0.00493827\n",
      " 0.00674536 0.         0.         0.40244898 0.18474576 0.0634175\n",
      " 0.04038138 0.04429967 0.0060423  0.19115192 0.09990357 0.48647201\n",
      " 0.37774984 0.1222031  0.31484776 0.06246246 0.10618913 0.0123839\n",
      " 0.01564246 0.05279503 0.0474934  0.98143603 0.92875923 0.95117585]\n",
      "Training Epoch 45/300, Loss: 1.3157, Accuracy: 0.7349, F1: 0.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90267447 0.68292683 0.53045187 0.         0.         0.\n",
      " 0.         0.         0.         0.47321429 0.02955665 0.03883495\n",
      " 0.01937046 0.1826484  0.         0.44044944 0.         0.70899471\n",
      " 0.51567944 0.46586345 0.67330931 0.         0.         0.\n",
      " 0.         0.08675799 0.00613497 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 45/300, Loss: 0.9861, Accuracy: 0.8221, F1: 0.2918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87460635 0.4122894  0.32248593 0.01724138 0.00412371 0.00643087\n",
      " 0.00385356 0.00452489 0.         0.         0.41989816 0.24642557\n",
      " 0.06362237 0.03978543 0.04758842 0.         0.2130714  0.14627165\n",
      " 0.5471597  0.45277691 0.22064688 0.59636215 0.02319358 0.05570681\n",
      " 0.01277955 0.00986193 0.07400722 0.0701953  0.98078256 0.93188079\n",
      " 0.9534398 ]\n",
      "Training Epoch 46/300, Loss: 1.0081, Accuracy: 0.7538, F1: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89958985 0.64678899 0.52236652 0.         0.         0.\n",
      " 0.         0.         0.         0.65437788 0.344      0.22068966\n",
      " 0.         0.11818182 0.         0.2125     0.00345423 0.79109589\n",
      " 0.60233298 0.21965318 0.69444444 0.20253165 0.25845411 0.\n",
      " 0.         0.08796296 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 46/300, Loss: 0.8142, Accuracy: 0.8238, F1: 0.3159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88169808 0.43249059 0.3282423  0.         0.         0.\n",
      " 0.00507614 0.         0.         0.4613424  0.36765445 0.05991285\n",
      " 0.06218564 0.07073509 0.         0.2373817  0.1090448  0.56685115\n",
      " 0.4664018  0.3273703  0.65168539 0.06481481 0.05873402 0.01179245\n",
      " 0.01930036 0.06750767 0.06802244 0.982751   0.92916823 0.94617932]\n",
      "Training Epoch 47/300, Loss: 0.9592, Accuracy: 0.7638, F1: 0.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88866248 0.72727273 0.56994819 0.         0.04081633 0.\n",
      " 0.         0.         0.         0.64668094 0.43165468 0.20991254\n",
      " 0.         0.17098446 0.         0.20121951 0.08723748 0.79931973\n",
      " 0.60153677 0.21192053 0.55057517 0.         0.         0.\n",
      " 0.         0.08796296 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 47/300, Loss: 0.7956, Accuracy: 0.8155, F1: 0.3075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85402941 0.31520223 0.21589899 0.         0.         0.\n",
      " 0.         0.00854701 0.01069519 0.42444444 0.2295416  0.05740181\n",
      " 0.02747362 0.05083612 0.01554404 0.16881919 0.05204236 0.47317209\n",
      " 0.37203376 0.26821346 0.58082736 0.04144282 0.04905523 0.\n",
      " 0.00263158 0.05974653 0.04424495 0.98017677 0.93046792 0.94966019]\n",
      "Training Epoch 48/300, Loss: 1.1971, Accuracy: 0.7378, F1: 0.2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88518919 0.4743083  0.29411765 0.         0.         0.\n",
      " 0.         0.         0.         0.43678161 0.09478673 0.21611002\n",
      " 0.         0.05714286 0.         0.31111111 0.10828025 0.644\n",
      " 0.42819843 0.29069767 0.6979687  0.         0.         0.\n",
      " 0.         0.         0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 48/300, Loss: 1.2472, Accuracy: 0.8118, F1: 0.2646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88200354 0.36216216 0.308338   0.01304348 0.01716738 0.00573066\n",
      " 0.00655738 0.         0.         0.         0.4378794  0.32261072\n",
      " 0.08134921 0.06825187 0.04632153 0.         0.17878338 0.09574127\n",
      " 0.51440121 0.41704101 0.35466667 0.64767487 0.07368421 0.0945441\n",
      " 0.02571711 0.02680965 0.09323308 0.08533654 0.98245835 0.93341654\n",
      " 0.95107982]\n",
      "Training Epoch 49/300, Loss: 1.1691, Accuracy: 0.7592, F1: 0.2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90805754 0.79245283 0.63508772 0.         0.         0.\n",
      " 0.         0.         0.         0.48877805 0.52980132 0.\n",
      " 0.         0.12380952 0.         0.11726384 0.         0.41812401\n",
      " 0.29176723 0.50328228 0.71326413 0.         0.         0.\n",
      " 0.         0.27838828 0.21492007 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 49/300, Loss: 0.9375, Accuracy: 0.7814, F1: 0.3005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87528356 0.40274117 0.2843649  0.00487805 0.00520833 0.00687285\n",
      " 0.00959233 0.         0.         0.46639344 0.35724889 0.07941484\n",
      " 0.0662768  0.0629275  0.01775148 0.14916048 0.09168967 0.54111558\n",
      " 0.4427673  0.3064144  0.61479191 0.0626506  0.13592773 0.01767956\n",
      " 0.01390498 0.05438283 0.06363636 0.98471064 0.93007866 0.95016531]\n",
      "Training Epoch 50/300, Loss: 0.8801, Accuracy: 0.7580, F1: 0.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91474596 0.69021739 0.55147059 0.         0.         0.\n",
      " 0.         0.         0.         0.55       0.29288703 0.00995025\n",
      " 0.00490196 0.10679612 0.         0.00696864 0.         0.69230769\n",
      " 0.50185414 0.44318182 0.74109114 0.18027211 0.23831468 0.\n",
      " 0.         0.13419913 0.04664723 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 50/300, Loss: 0.8498, Accuracy: 0.8103, F1: 0.3035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.892637   0.37545126 0.3021649  0.         0.         0.00722022\n",
      " 0.00502513 0.00452489 0.         0.4911267  0.38607595 0.0870021\n",
      " 0.09287764 0.05718271 0.01796407 0.20289855 0.1087848  0.5574315\n",
      " 0.46404512 0.42883895 0.70731707 0.08138659 0.11885895 0.00767263\n",
      " 0.0110957  0.07991661 0.0575056  0.98605414 0.92656143 0.94532502]\n",
      "Training Epoch 51/300, Loss: 0.7311, Accuracy: 0.7847, F1: 0.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90060625 0.68167203 0.49064449 0.         0.         0.\n",
      " 0.         0.         0.         0.65148064 0.49122807 0.02870813\n",
      " 0.03301887 0.23015873 0.         0.4605475  0.33011583 0.79663866\n",
      " 0.59053498 0.35036496 0.56264775 0.         0.         0.\n",
      " 0.         0.14893617 0.05813953 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 51/300, Loss: 0.4668, Accuracy: 0.8161, F1: 0.3268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88989282 0.3869969  0.31017849 0.02369668 0.01459854 0.\n",
      " 0.0167364  0.01263158 0.00518135 0.48106533 0.36586516 0.07845367\n",
      " 0.06643275 0.0826087  0.03164557 0.22186235 0.17385563 0.5840605\n",
      " 0.49752939 0.37619264 0.6264199  0.09847936 0.161558   0.01428571\n",
      " 0.01747815 0.08302645 0.09016661 0.98770724 0.92663367 0.94509539]\n",
      "Training Epoch 52/300, Loss: 0.7203, Accuracy: 0.7803, F1: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91247867 0.62971175 0.47727273 0.         0.         0.\n",
      " 0.         0.         0.         0.65384615 0.58858859 0.\n",
      " 0.         0.14912281 0.         0.20560748 0.15141956 0.740625\n",
      " 0.61129032 0.6424581  0.83153102 0.29591837 0.40723982 0.\n",
      " 0.         0.17886179 0.19421488 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 52/300, Loss: 0.5413, Accuracy: 0.8423, F1: 0.3556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8932198  0.45123258 0.36679245 0.00469484 0.00484262 0.\n",
      " 0.01279318 0.00464037 0.         0.47996762 0.3690671  0.10951894\n",
      " 0.08112954 0.07890961 0.00645161 0.22157676 0.18       0.59208654\n",
      " 0.51351351 0.44849066 0.67070401 0.10884354 0.18040971 0.02163462\n",
      " 0.02298851 0.07258065 0.06291781 0.98566829 0.93441802 0.95217763]\n",
      "Training Epoch 53/300, Loss: 0.5674, Accuracy: 0.7885, F1: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91726429 0.76829268 0.59029126 0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.62928349 0.31558935\n",
      " 0.22686152 0.13402062 0.         0.5320197  0.5        0.8\n",
      " 0.57763301 0.64066852 0.82601351 0.06451613 0.11313869 0.\n",
      " 0.         0.12888889 0.05389222 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 53/300, Loss: 0.3733, Accuracy: 0.8442, F1: 0.3828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86985841 0.40570175 0.28902031 0.         0.         0.\n",
      " 0.         0.00911162 0.00584795 0.4516129  0.28745318 0.09337676\n",
      " 0.06725664 0.06978367 0.00626959 0.16738197 0.0913803  0.51737668\n",
      " 0.44267516 0.22743682 0.41272959 0.08933333 0.15461201 0.01498127\n",
      " 0.01058201 0.08761789 0.07526555 0.98236521 0.92803598 0.9451694 ]\n",
      "Training Epoch 54/300, Loss: 0.8963, Accuracy: 0.7442, F1: 0.2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90352289 0.75305623 0.62376238 0.         0.         0.\n",
      " 0.         0.         0.         0.70175439 0.59183673 0.02898551\n",
      " 0.03240741 0.25531915 0.         0.42519685 0.06873977 0.7\n",
      " 0.5899076  0.33623188 0.71479909 0.         0.         0.\n",
      " 0.         0.17457306 0.12009238 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 54/300, Loss: 0.5937, Accuracy: 0.8307, F1: 0.3340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89427451 0.43335049 0.35608309 0.         0.         0.\n",
      " 0.         0.00915332 0.         0.52462956 0.42908762 0.12331606\n",
      " 0.11869436 0.0691602  0.00636943 0.26702168 0.21061978 0.5868704\n",
      " 0.50504049 0.35234591 0.66703894 0.06754772 0.12250771 0.01393728\n",
      " 0.01726264 0.06898955 0.07559395 0.9890442  0.93215266 0.95127169]\n",
      "Training Epoch 55/300, Loss: 0.6095, Accuracy: 0.7865, F1: 0.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90132365 0.6371308  0.50325945 0.         0.         0.\n",
      " 0.         0.         0.         0.7        0.58227848 0.11764706\n",
      " 0.10152284 0.21789883 0.         0.53140097 0.2        0.80479452\n",
      " 0.6061246  0.37572254 0.69632224 0.         0.         0.\n",
      " 0.         0.18823529 0.08648649 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 55/300, Loss: 0.4559, Accuracy: 0.8304, F1: 0.3416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87828326 0.37336024 0.27038814 0.00465116 0.01385681 0.00613497\n",
      " 0.00852273 0.         0.         0.500205   0.37253289 0.07680798\n",
      " 0.07238559 0.07560628 0.04046243 0.31463415 0.22474597 0.5688175\n",
      " 0.52050078 0.33100233 0.60044418 0.03392706 0.05606759 0.00954654\n",
      " 0.01891253 0.11037528 0.10015748 0.98739443 0.92118718 0.9385934 ]\n",
      "Training Epoch 56/300, Loss: 0.7265, Accuracy: 0.7605, F1: 0.2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91690544 0.59124088 0.37762238 0.         0.         0.\n",
      " 0.         0.         0.         0.62470862 0.52961672 0.18141097\n",
      " 0.10673178 0.07865169 0.         0.5215311  0.38292683 0.81680672\n",
      " 0.68738899 0.26337449 0.31160425 0.         0.         0.\n",
      " 0.         0.168      0.1060241  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 56/300, Loss: 0.4711, Accuracy: 0.7593, F1: 0.3221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87301291 0.40248319 0.30895091 0.01834862 0.02764977 0.\n",
      " 0.         0.         0.         0.49389748 0.33244444 0.08063531\n",
      " 0.03644647 0.06743088 0.         0.29193733 0.22251788 0.57047354\n",
      " 0.48942013 0.21719039 0.40483788 0.08380682 0.18043899 0.01479915\n",
      " 0.0261194  0.08362818 0.08423661 0.98779874 0.9326905  0.951537  ]\n",
      "Training Epoch 57/300, Loss: 0.7474, Accuracy: 0.7522, F1: 0.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88062229 0.75471698 0.54867257 0.         0.         0.\n",
      " 0.         0.         0.         0.57345972 0.49567723 0.\n",
      " 0.         0.07692308 0.         0.334      0.2909981  0.7787307\n",
      " 0.57932446 0.29733164 0.495485   0.02547771 0.01876173 0.\n",
      " 0.         0.05673759 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 57/300, Loss: 0.6424, Accuracy: 0.7440, F1: 0.3069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89705397 0.48333333 0.40793941 0.         0.         0.\n",
      " 0.         0.00447427 0.         0.51228353 0.3998199  0.08756219\n",
      " 0.0681593  0.07178751 0.0247678  0.33536585 0.33333333 0.58499147\n",
      " 0.49874896 0.43555974 0.74251066 0.14672835 0.249447   0.01882353\n",
      " 0.01652893 0.07676349 0.08206245 0.98910511 0.93617021 0.95716649]\n",
      "Training Epoch 58/300, Loss: 0.7159, Accuracy: 0.7979, F1: 0.3120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91465854 0.73205742 0.57729138 0.         0.         0.\n",
      " 0.         0.         0.         0.71457906 0.69252078 0.15625\n",
      " 0.         0.16042781 0.         0.59713701 0.49785408 0.77198212\n",
      " 0.69350863 0.58981233 0.80145822 0.02797203 0.041841   0.\n",
      " 0.         0.18436874 0.13705584 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 58/300, Loss: 0.6003, Accuracy: 0.8512, F1: 0.3763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87648723 0.44624746 0.30948779 0.00461894 0.01456311 0.\n",
      " 0.00475059 0.         0.         0.48230988 0.36677909 0.07976366\n",
      " 0.05876639 0.06818182 0.00621118 0.34402566 0.29672187 0.58439716\n",
      " 0.48667212 0.35027223 0.60218175 0.07901907 0.13967767 0.01226994\n",
      " 0.01038961 0.10209834 0.08274232 0.98578738 0.92556513 0.94499851]\n",
      "Training Epoch 59/300, Loss: 0.7287, Accuracy: 0.7640, F1: 0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91917276 0.59117083 0.47427293 0.         0.         0.\n",
      " 0.         0.         0.         0.67886179 0.60340633 0.\n",
      " 0.         0.20754717 0.         0.55205811 0.43631778 0.81072027\n",
      " 0.63364293 0.5030426  0.70747114 0.         0.         0.\n",
      " 0.         0.11312217 0.         0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 59/300, Loss: 0.4956, Accuracy: 0.8399, F1: 0.3410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89853473 0.44587353 0.34694383 0.         0.00501253 0.00675676\n",
      " 0.00357782 0.00473934 0.00615385 0.52210175 0.42843602 0.07363292\n",
      " 0.05663049 0.08327452 0.00595238 0.35093555 0.35488152 0.58495212\n",
      " 0.53593101 0.4196868  0.67326928 0.08383234 0.16111513 0.01647059\n",
      " 0.03073286 0.11132561 0.10214505 0.9879685  0.93284142 0.95204565]\n",
      "Training Epoch 60/300, Loss: 0.5473, Accuracy: 0.7925, F1: 0.3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91904019 0.78034682 0.61710037 0.         0.         0.\n",
      " 0.         0.         0.         0.68995633 0.64215686 0.\n",
      " 0.         0.19487179 0.         0.62666667 0.63784822 0.80713128\n",
      " 0.69626998 0.37596302 0.53371051 0.17857143 0.22865014 0.\n",
      " 0.         0.16170213 0.09651475 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 60/300, Loss: 0.4303, Accuracy: 0.8200, F1: 0.3728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88422175 0.43873518 0.32899359 0.00455581 0.00928074 0.00696864\n",
      " 0.00445434 0.00465116 0.         0.51628468 0.39014025 0.09096349\n",
      " 0.08800219 0.08224812 0.01226994 0.33233147 0.30272569 0.58871627\n",
      " 0.51849459 0.38950947 0.64678685 0.11607143 0.18879946 0.01385681\n",
      " 0.02120141 0.10536913 0.08937035 0.98974262 0.93368401 0.95458758]\n",
      "Training Epoch 61/300, Loss: 0.5816, Accuracy: 0.7825, F1: 0.3018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92173712 0.68027211 0.44988864 0.         0.         0.\n",
      " 0.         0.         0.         0.71487603 0.57563025 0.03902439\n",
      " 0.01941748 0.17       0.         0.51256281 0.4654498  0.81506849\n",
      " 0.64439655 0.60913706 0.79968701 0.         0.         0.\n",
      " 0.         0.26605505 0.19969278 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 61/300, Loss: 0.4213, Accuracy: 0.8459, F1: 0.3627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89462537 0.37612256 0.24281921 0.00503778 0.02139037 0.\n",
      " 0.         0.00486618 0.00643087 0.53706755 0.42421211 0.14473684\n",
      " 0.12351216 0.0801718  0.03154574 0.34203875 0.31095679 0.61278513\n",
      " 0.54066986 0.46711153 0.72119875 0.14232765 0.25794106 0.02681564\n",
      " 0.03657143 0.11061491 0.09700111 0.98834058 0.93221924 0.94907215]\n",
      "Training Epoch 62/300, Loss: 0.5059, Accuracy: 0.7930, F1: 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89451956 0.46825397 0.28992629 0.         0.         0.\n",
      " 0.         0.         0.         0.53937947 0.25641026 0.\n",
      " 0.         0.19246862 0.         0.54044118 0.30978934 0.78464107\n",
      " 0.6124197  0.51234568 0.70234807 0.20253165 0.22803738 0.\n",
      " 0.         0.18355641 0.04154303 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 62/300, Loss: 0.5849, Accuracy: 0.8285, F1: 0.3252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88940136 0.42607313 0.375      0.01357466 0.02625821 0.\n",
      " 0.0195258  0.         0.         0.49839228 0.31825658 0.09784946\n",
      " 0.08651805 0.05405405 0.00589971 0.35004248 0.32125143 0.59922822\n",
      " 0.53181964 0.3226087  0.54068492 0.15077605 0.23855891 0.01515152\n",
      " 0.01650619 0.10238908 0.080513   0.98872725 0.92678661 0.9481828 ]\n",
      "Training Epoch 63/300, Loss: 0.5985, Accuracy: 0.7783, F1: 0.2981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92092703 0.82420749 0.6597582  0.         0.         0.\n",
      " 0.         0.         0.         0.70155039 0.54166667 0.07582938\n",
      " 0.06117647 0.23770492 0.03174603 0.53691275 0.47961957 0.7925117\n",
      " 0.69209809 0.625      0.81283422 0.         0.         0.01538462\n",
      " 0.016      0.14569536 0.04833837 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 63/300, Loss: 0.3761, Accuracy: 0.8520, F1: 0.3739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88627728 0.47668394 0.37224782 0.00898876 0.02352941 0.00692042\n",
      " 0.00913242 0.00462963 0.         0.50160256 0.3857362  0.08129176\n",
      " 0.06566851 0.06393329 0.02266289 0.33082707 0.30685491 0.58725299\n",
      " 0.52847004 0.37084282 0.65443051 0.07219662 0.08906352 0.01891253\n",
      " 0.03921569 0.11591419 0.10691004 0.98675747 0.93031968 0.95147147]\n",
      "Training Epoch 64/300, Loss: 0.6607, Accuracy: 0.7796, F1: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91795292 0.79885057 0.63821892 0.         0.         0.04255319\n",
      " 0.16842105 0.         0.         0.71129707 0.63815789 0.00985222\n",
      " 0.00488998 0.20512821 0.         0.50079745 0.41651263 0.79746835\n",
      " 0.70855148 0.49856734 0.76129854 0.         0.         0.\n",
      " 0.         0.23263889 0.18220339 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 64/300, Loss: 0.4823, Accuracy: 0.8452, F1: 0.3744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89956588 0.46733935 0.40195574 0.00954654 0.00487805 0.\n",
      " 0.00407332 0.00477327 0.00617284 0.53908795 0.43967093 0.15061475\n",
      " 0.13539565 0.09123307 0.02484472 0.30499325 0.26805778 0.61114206\n",
      " 0.55829926 0.39867424 0.65181426 0.10986102 0.20758817 0.00258065\n",
      " 0.01104972 0.11889738 0.12082349 0.98898193 0.92444222 0.94368396]\n",
      "Training Epoch 65/300, Loss: 0.4888, Accuracy: 0.7948, F1: 0.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91364375 0.74686717 0.62557781 0.         0.         0.\n",
      " 0.         0.         0.         0.69827586 0.60927152 0.05769231\n",
      " 0.03827751 0.21359223 0.         0.60504202 0.51048951 0.81771721\n",
      " 0.65102041 0.52225519 0.76888747 0.38497653 0.51851852 0.\n",
      " 0.         0.23076923 0.18142549 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 65/300, Loss: 0.3512, Accuracy: 0.8517, F1: 0.4031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90483207 0.49712193 0.44071299 0.         0.00511509 0.\n",
      " 0.         0.00486618 0.00645161 0.55491329 0.46755725 0.13243547\n",
      " 0.15302326 0.09259259 0.03519062 0.36951894 0.40103397 0.627384\n",
      " 0.5838103  0.46826516 0.73450977 0.24880383 0.42643263 0.02310655\n",
      " 0.05989583 0.13773913 0.12723949 0.98872583 0.9362684  0.95257364]\n",
      "Training Epoch 66/300, Loss: 0.4208, Accuracy: 0.8132, F1: 0.3460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92901613 0.82248521 0.65427509 0.         0.         0.\n",
      " 0.         0.         0.         0.71583514 0.62796834 0.3659306\n",
      " 0.38327526 0.2        0.         0.64435146 0.68739206 0.83250415\n",
      " 0.73408893 0.62140992 0.80154839 0.35971223 0.43605359 0.\n",
      " 0.         0.32704403 0.2853067  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 66/300, Loss: 0.3109, Accuracy: 0.8565, F1: 0.4476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89833878 0.51203501 0.44917258 0.00980392 0.01038961 0.01444043\n",
      " 0.04326923 0.         0.         0.53547855 0.44749755 0.16409037\n",
      " 0.18907104 0.09880028 0.03647416 0.39359862 0.45275742 0.63997712\n",
      " 0.5927169  0.43041607 0.6694219  0.24107143 0.39535287 0.02048656\n",
      " 0.02475928 0.11123228 0.11093871 0.98928796 0.93176852 0.95267194]\n",
      "Training Epoch 67/300, Loss: 0.4176, Accuracy: 0.8091, F1: 0.3455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87675779 0.7388535  0.55465587 0.         0.         0.\n",
      " 0.         0.         0.         0.51401869 0.32128514 0.18110236\n",
      " 0.11637931 0.11525424 0.         0.59836066 0.30268741 0.78368794\n",
      " 0.59327926 0.07655502 0.05490196 0.15686275 0.17829457 0.\n",
      " 0.         0.17118998 0.04848485 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 67/300, Loss: 0.5398, Accuracy: 0.8019, F1: 0.3127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8691077  0.3954863  0.27962085 0.01716738 0.01520913 0.00544959\n",
      " 0.00773694 0.00414938 0.         0.48055669 0.32448378 0.10492108\n",
      " 0.08870232 0.04775281 0.         0.26360544 0.18943276 0.55061867\n",
      " 0.47053124 0.1486014  0.3111002  0.06394884 0.11828358 0.02588235\n",
      " 0.03156708 0.11279143 0.07920792 0.98618732 0.92594679 0.94848783]\n",
      "Training Epoch 68/300, Loss: 0.9122, Accuracy: 0.7354, F1: 0.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92161716 0.80701754 0.63773585 0.         0.         0.\n",
      " 0.         0.         0.         0.59345794 0.3153527  0.21122112\n",
      " 0.20470829 0.10055866 0.         0.20496894 0.08866995 0.68856767\n",
      " 0.51252408 0.03555556 0.30762082 0.         0.         0.\n",
      " 0.         0.26200873 0.1392211  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 68/300, Loss: 0.5700, Accuracy: 0.7769, F1: 0.3010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89744965 0.47111554 0.40625764 0.         0.         0.\n",
      " 0.         0.00472813 0.00613497 0.5097561  0.36379385 0.0921659\n",
      " 0.08500992 0.09305556 0.02932551 0.34172964 0.3351373  0.54941022\n",
      " 0.46286595 0.29213483 0.68594705 0.1722551  0.32663947 0.03601695\n",
      " 0.04285714 0.0928043  0.08814204 0.98721582 0.92994823 0.94861754]\n",
      "Training Epoch 69/300, Loss: 0.5827, Accuracy: 0.7929, F1: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9230124  0.71593533 0.62433862 0.         0.         0.\n",
      " 0.         0.         0.         0.68722467 0.32786885 0.14222222\n",
      " 0.17374517 0.20627803 0.         0.54320988 0.46938776 0.82534247\n",
      " 0.66533467 0.54901961 0.75961312 0.32432432 0.49929478 0.\n",
      " 0.         0.22734761 0.22248244 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 69/300, Loss: 0.3802, Accuracy: 0.8497, F1: 0.3962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90477035 0.49864499 0.45620634 0.01392111 0.00824742 0.00673401\n",
      " 0.00421941 0.00956938 0.00619195 0.56032389 0.47106691 0.16236972\n",
      " 0.20132013 0.08634112 0.         0.35187581 0.39458414 0.62510873\n",
      " 0.5519802  0.45815399 0.74966574 0.28296703 0.43443577 0.02888087\n",
      " 0.03902439 0.11848341 0.10957936 0.99037675 0.92902582 0.9488168 ]\n",
      "Training Epoch 70/300, Loss: 0.4325, Accuracy: 0.8140, F1: 0.3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92084378 0.72115385 0.59397418 0.         0.         0.\n",
      " 0.         0.         0.         0.71794872 0.65168539 0.23529412\n",
      " 0.3271028  0.23696682 0.03703704 0.52525253 0.36944444 0.82838284\n",
      " 0.69797422 0.62125341 0.81605544 0.40689655 0.53141559 0.\n",
      " 0.         0.18907563 0.11494253 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 70/300, Loss: 0.3259, Accuracy: 0.8571, F1: 0.4180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90613271 0.50189292 0.44721485 0.02386635 0.01456311 0.\n",
      " 0.00831601 0.         0.         0.55641548 0.53314258 0.1877095\n",
      " 0.22946038 0.09572154 0.01834862 0.38179408 0.42882527 0.63056966\n",
      " 0.58494624 0.50726676 0.76261531 0.27969925 0.47182359 0.025\n",
      " 0.03585147 0.13786078 0.12914863 0.99018621 0.92919968 0.9495648 ]\n",
      "Training Epoch 71/300, Loss: 0.3957, Accuracy: 0.8202, F1: 0.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92648218 0.81792717 0.68243243 0.         0.         0.\n",
      " 0.         0.         0.         0.69361702 0.67673716 0.32413793\n",
      " 0.35612083 0.21428571 0.         0.59574468 0.5905421  0.83250415\n",
      " 0.72       0.59649123 0.7989899  0.42570281 0.56059204 0.\n",
      " 0.         0.20816327 0.14948454 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 71/300, Loss: 0.3099, Accuracy: 0.8661, F1: 0.4390\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90824958 0.52941176 0.47427171 0.00490196 0.01550388 0.\n",
      " 0.         0.         0.         0.55081967 0.53279786 0.18872138\n",
      " 0.20608347 0.10749646 0.01818182 0.38799478 0.5012678  0.66237041\n",
      " 0.61617623 0.49626168 0.73254398 0.28613139 0.48198717 0.02570694\n",
      " 0.04965517 0.14465195 0.14365411 0.98961284 0.93013972 0.94783587]\n",
      "Training Epoch 72/300, Loss: 0.3805, Accuracy: 0.8209, F1: 0.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93126544 0.85393258 0.70882353 0.         0.         0.\n",
      " 0.         0.         0.         0.71457906 0.5719697  0.39037433\n",
      " 0.34974533 0.20192308 0.03636364 0.63013699 0.67673716 0.84590164\n",
      " 0.74696707 0.62857143 0.82349936 0.4372093  0.63031625 0.\n",
      " 0.         0.27777778 0.26369168 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 72/300, Loss: 0.2878, Accuracy: 0.8668, F1: 0.4573\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.905611   0.50299401 0.43294615 0.02905569 0.02469136 0.\n",
      " 0.         0.00487805 0.         0.58088235 0.5154827  0.1936912\n",
      " 0.21169916 0.11111111 0.01851852 0.39549003 0.43250635 0.64036333\n",
      " 0.60740251 0.50352941 0.72970703 0.27638573 0.44587583 0.03431373\n",
      " 0.04358974 0.16078984 0.14350797 0.98853182 0.93132913 0.94769887]\n",
      "Training Epoch 73/300, Loss: 0.3809, Accuracy: 0.8186, F1: 0.3604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92533401 0.77777778 0.60996355 0.         0.         0.\n",
      " 0.         0.         0.         0.70168067 0.68823529 0.17167382\n",
      " 0.1356674  0.19791667 0.         0.6371308  0.66220096 0.81469649\n",
      " 0.73232323 0.64850136 0.82836241 0.44117647 0.62271062 0.\n",
      " 0.         0.20703125 0.14888337 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 73/300, Loss: 0.2941, Accuracy: 0.8687, F1: 0.4317\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91057994 0.53389385 0.49973698 0.01477833 0.01574803 0.\n",
      " 0.         0.         0.         0.57466613 0.56043956 0.21201814\n",
      " 0.23766707 0.12011577 0.03692308 0.40386304 0.492225   0.65600914\n",
      " 0.61225861 0.49883883 0.73960927 0.31176471 0.46736557 0.02614379\n",
      " 0.03636364 0.15795016 0.14041746 0.99177084 0.93158715 0.94909824]\n",
      "Training Epoch 74/300, Loss: 0.3654, Accuracy: 0.8253, F1: 0.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92911777 0.85070423 0.70326409 0.         0.         0.\n",
      " 0.         0.         0.         0.72349272 0.65168539 0.38196286\n",
      " 0.34692246 0.16831683 0.         0.65342163 0.70900474 0.83606557\n",
      " 0.74074074 0.65405405 0.82261104 0.42023346 0.54415274 0.\n",
      " 0.         0.2033195  0.167979   0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 74/300, Loss: 0.2826, Accuracy: 0.8636, F1: 0.4502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90276328 0.51707317 0.4857685  0.01438849 0.01459854 0.00722022\n",
      " 0.01492537 0.         0.         0.54522822 0.52808989 0.19767442\n",
      " 0.22284692 0.11931818 0.02424242 0.40157137 0.45111247 0.64295795\n",
      " 0.59802113 0.4601432  0.65686857 0.30404889 0.44358524 0.02528445\n",
      " 0.0343461  0.15078534 0.13318369 0.99106918 0.93933342 0.95529186]\n",
      "Training Epoch 75/300, Loss: 0.3844, Accuracy: 0.8149, F1: 0.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92652863 0.83102493 0.71253823 0.         0.         0.\n",
      " 0.         0.         0.         0.69807281 0.67988669 0.33449477\n",
      " 0.36098981 0.21538462 0.         0.64166667 0.69955947 0.80844156\n",
      " 0.72887324 0.60122699 0.77913715 0.4351145  0.51336898 0.\n",
      " 0.         0.2306163  0.19143577 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 75/300, Loss: 0.2903, Accuracy: 0.8651, F1: 0.4462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89408498 0.51840332 0.44324058 0.00968523 0.02358491 0.\n",
      " 0.         0.00478469 0.         0.56594528 0.48136507 0.15865922\n",
      " 0.17753304 0.10699001 0.01265823 0.40422833 0.41380604 0.62577031\n",
      " 0.58560311 0.41716659 0.61600545 0.23651146 0.37451147 0.02948403\n",
      " 0.04628502 0.15880399 0.13498533 0.99106694 0.92892356 0.94860534]\n",
      "Training Epoch 76/300, Loss: 0.4403, Accuracy: 0.7961, F1: 0.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93363588 0.85555556 0.73481481 0.         0.         0.\n",
      " 0.         0.         0.         0.70663812 0.66666667 0.33791749\n",
      " 0.22518914 0.15706806 0.         0.61643836 0.66797642 0.82911392\n",
      " 0.71783296 0.4852459  0.68567503 0.41836735 0.6225     0.\n",
      " 0.         0.36009732 0.3062352  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 76/300, Loss: 0.3088, Accuracy: 0.8385, F1: 0.4442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90994591 0.51847941 0.48555499 0.02870813 0.03931204 0.01438849\n",
      " 0.05909091 0.         0.         0.59149278 0.54128035 0.19282271\n",
      " 0.21433416 0.1350211  0.0247678  0.4323641  0.45665399 0.6572536\n",
      " 0.61681937 0.49770432 0.73883692 0.25332291 0.40558912 0.02756892\n",
      " 0.03187251 0.16299704 0.15421035 0.991641   0.93107965 0.95113542]\n",
      "Training Epoch 77/300, Loss: 0.3949, Accuracy: 0.8212, F1: 0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93200671 0.74823529 0.51171509 0.         0.         0.\n",
      " 0.         0.         0.         0.75918367 0.72432432 0.14592275\n",
      " 0.13445378 0.21212121 0.         0.64621677 0.68878357 0.84502447\n",
      " 0.75042159 0.62591687 0.80749574 0.35602094 0.58221024 0.\n",
      " 0.         0.29577465 0.24444444 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 77/300, Loss: 0.2856, Accuracy: 0.8677, F1: 0.4336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90518741 0.5357524  0.49024325 0.00973236 0.01496259 0.\n",
      " 0.         0.00973236 0.00636943 0.5798285  0.54415061 0.18457944\n",
      " 0.21248066 0.12571429 0.03174603 0.41323024 0.46768281 0.65432099\n",
      " 0.61721941 0.48764259 0.7269717  0.26647145 0.45103756 0.03282828\n",
      " 0.0400534  0.16814764 0.14742898 0.99208443 0.9348396  0.95179499]\n",
      "Training Epoch 78/300, Loss: 0.3854, Accuracy: 0.8204, F1: 0.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92076932 0.70378619 0.57236842 0.         0.         0.\n",
      " 0.         0.         0.         0.64732143 0.67256637 0.13973799\n",
      " 0.16135881 0.23041475 0.03448276 0.61111111 0.64712269 0.80713128\n",
      " 0.72806255 0.57777778 0.74056443 0.44705882 0.5840708  0.\n",
      " 0.         0.1663113  0.11111111 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 78/300, Loss: 0.3024, Accuracy: 0.8576, F1: 0.4167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86888785 0.36625514 0.26252772 0.02880658 0.03773585 0.01604278\n",
      " 0.01818182 0.00411523 0.00473934 0.49301955 0.40222576 0.11252654\n",
      " 0.11961625 0.06245564 0.01840491 0.3209776  0.27299912 0.59434475\n",
      " 0.5398313  0.14950635 0.2398428  0.14556041 0.22695738 0.02974828\n",
      " 0.03977901 0.11901682 0.0935397  0.98785017 0.92916536 0.94845361]\n",
      "Training Epoch 79/300, Loss: 1.0154, Accuracy: 0.7379, F1: 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87496315 0.37130802 0.2244898  0.         0.         0.\n",
      " 0.         0.         0.         0.38764045 0.25751073 0.05825243\n",
      " 0.02905569 0.04519774 0.         0.30057803 0.19207317 0.75265018\n",
      " 0.64816473 0.13782991 0.32249626 0.08695652 0.12121212 0.\n",
      " 0.         0.12903226 0.04904632 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 79/300, Loss: 0.7323, Accuracy: 0.7091, F1: 0.2662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89771182 0.36965812 0.28226379 0.04246285 0.04081633 0.\n",
      " 0.         0.00936768 0.00606061 0.54208619 0.42074199 0.13326551\n",
      " 0.11973201 0.08823529 0.01785714 0.33292831 0.3028786  0.5708234\n",
      " 0.50599035 0.28150407 0.71380258 0.1789549  0.30500088 0.03340757\n",
      " 0.03437164 0.12727273 0.11859491 0.99056841 0.93384971 0.95491456]\n",
      "Training Epoch 80/300, Loss: 0.5985, Accuracy: 0.7924, F1: 0.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93133195 0.66435986 0.43243243 0.         0.         0.\n",
      " 0.         0.         0.         0.70640177 0.62       0.00995025\n",
      " 0.00490196 0.17647059 0.         0.45753425 0.34611172 0.78157504\n",
      " 0.67862069 0.65745856 0.81570338 0.04166667 0.04192872 0.\n",
      " 0.         0.31844215 0.26848975 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 80/300, Loss: 0.3915, Accuracy: 0.8265, F1: 0.3651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90920151 0.45882962 0.36586587 0.01408451 0.02020202 0.02994012\n",
      " 0.05137615 0.01877934 0.02373887 0.57650384 0.54420522 0.18688525\n",
      " 0.22364054 0.13125406 0.02873563 0.31468849 0.33047305 0.62908681\n",
      " 0.5800066  0.44267375 0.75512362 0.27571429 0.45056065 0.03665521\n",
      " 0.05219454 0.16055046 0.14386555 0.99171271 0.92434354 0.94678269]\n",
      "Training Epoch 81/300, Loss: 0.4286, Accuracy: 0.8165, F1: 0.3539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92672047 0.85082873 0.72727273 0.         0.         0.\n",
      " 0.         0.         0.         0.75303644 0.70684932 0.37671233\n",
      " 0.38304553 0.28571429 0.03508772 0.63983051 0.66796495 0.83666667\n",
      " 0.73239437 0.60335196 0.82449941 0.45070423 0.64739884 0.\n",
      " 0.         0.29194631 0.26104418 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 81/300, Loss: 0.2946, Accuracy: 0.8726, F1: 0.4667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91249964 0.53602903 0.50293021 0.02463054 0.02673797 0.00706714\n",
      " 0.0228833  0.01415094 0.02461538 0.57759674 0.56030033 0.21315193\n",
      " 0.2698373  0.13016095 0.0295858  0.42540984 0.49503916 0.64687588\n",
      " 0.61756001 0.48159927 0.76138829 0.31202435 0.50880626 0.03295311\n",
      " 0.04365621 0.1616706  0.15139442 0.99081992 0.92590279 0.94656672]\n",
      "Training Epoch 82/300, Loss: 0.3715, Accuracy: 0.8282, F1: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9326143  0.78880407 0.63376623 0.         0.         0.\n",
      " 0.         0.         0.         0.75776398 0.71168831 0.28136882\n",
      " 0.29530201 0.19689119 0.         0.64705882 0.66806723 0.82574568\n",
      " 0.72810358 0.56744186 0.77422457 0.44155844 0.59624877 0.\n",
      " 0.         0.29370629 0.24742268 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 82/300, Loss: 0.2841, Accuracy: 0.8675, F1: 0.4462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9135869  0.5562701  0.53453773 0.02857143 0.02797203 0.\n",
      " 0.         0.         0.         0.57223796 0.54537406 0.23747277\n",
      " 0.29394149 0.1633218  0.04833837 0.45196784 0.54787645 0.67030568\n",
      " 0.63111392 0.53307949 0.76976394 0.32729906 0.51417336 0.02544529\n",
      " 0.04087193 0.17909431 0.16951619 0.99043544 0.92733737 0.94570162]\n",
      "Training Epoch 83/300, Loss: 0.3556, Accuracy: 0.8311, F1: 0.3882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93110677 0.83378747 0.67759563 0.         0.         0.\n",
      " 0.         0.         0.         0.74949084 0.63948498 0.3884058\n",
      " 0.38371041 0.19095477 0.03636364 0.66666667 0.73783091 0.83636364\n",
      " 0.73767606 0.65546218 0.82895505 0.38006231 0.40780911 0.\n",
      " 0.         0.3032491  0.3009901  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 83/300, Loss: 0.2800, Accuracy: 0.8594, F1: 0.4562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91004492 0.54389722 0.49159327 0.04235294 0.05250597 0.01355932\n",
      " 0.0311284  0.00484262 0.         0.57646576 0.55509451 0.2093157\n",
      " 0.265552   0.15478615 0.03647416 0.41067585 0.48825735 0.6601617\n",
      " 0.61965949 0.4765279  0.70582184 0.29680365 0.48738858 0.03955501\n",
      " 0.04669261 0.16491347 0.15412315 0.99075297 0.93126248 0.95101653]\n",
      "Training Epoch 84/300, Loss: 0.3646, Accuracy: 0.8236, F1: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92810638 0.84033613 0.72727273 0.         0.         0.\n",
      " 0.         0.         0.         0.74789916 0.71590909 0.3986711\n",
      " 0.41167883 0.25454545 0.03636364 0.65367965 0.69556452 0.82736156\n",
      " 0.75347222 0.64788732 0.82442748 0.45814978 0.62686567 0.\n",
      " 0.         0.23320158 0.21945137 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 84/300, Loss: 0.2805, Accuracy: 0.8755, F1: 0.4666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91361752 0.54091392 0.51335778 0.02933985 0.02538071 0.01470588\n",
      " 0.00982801 0.         0.         0.57189946 0.55570966 0.24387464\n",
      " 0.28241082 0.16320885 0.05325444 0.44320617 0.54342055 0.65319865\n",
      " 0.62335958 0.51289134 0.74098486 0.34498141 0.51248036 0.03940887\n",
      " 0.03952569 0.18144471 0.17818182 0.99043905 0.92943158 0.94653419]\n",
      "Training Epoch 85/300, Loss: 0.3520, Accuracy: 0.8298, F1: 0.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93549755 0.86363636 0.74277017 0.         0.         0.\n",
      " 0.         0.         0.         0.75518672 0.71549296 0.35789474\n",
      " 0.37320574 0.26415094 0.03636364 0.65560166 0.73827792 0.84385382\n",
      " 0.75710357 0.54988914 0.7463752  0.39583333 0.60962567 0.\n",
      " 0.         0.28409091 0.25943396 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 85/300, Loss: 0.2728, Accuracy: 0.8738, F1: 0.4628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91516273 0.54555315 0.51202565 0.03333333 0.05057471 0.\n",
      " 0.         0.01411765 0.0119403  0.57731959 0.56641366 0.23351955\n",
      " 0.26408039 0.13924051 0.04863222 0.43835616 0.53058044 0.66480603\n",
      " 0.62835748 0.55800845 0.76888824 0.30653644 0.514246   0.03316327\n",
      " 0.04365621 0.19232076 0.19180088 0.99195879 0.9303225  0.9510107 ]\n",
      "Training Epoch 86/300, Loss: 0.3422, Accuracy: 0.8332, F1: 0.3885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93609935 0.85950413 0.71368124 0.         0.         0.\n",
      " 0.         0.         0.         0.75403226 0.69975186 0.35810811\n",
      " 0.39285714 0.17894737 0.         0.65010352 0.72984206 0.8282504\n",
      " 0.7258567  0.55803571 0.74775583 0.37234043 0.57865169 0.\n",
      " 0.         0.28897338 0.27876106 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 86/300, Loss: 0.2690, Accuracy: 0.8706, F1: 0.4550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91471136 0.5648198  0.51996826 0.01459854 0.01503759 0.02857143\n",
      " 0.04176334 0.00970874 0.00643087 0.57944697 0.57156091 0.21382917\n",
      " 0.26456372 0.13135593 0.04255319 0.41810345 0.5185895  0.65219811\n",
      " 0.63002594 0.51597962 0.72594988 0.30828221 0.49327517 0.04320203\n",
      " 0.05804749 0.18330494 0.17144933 0.99221301 0.93350798 0.95270431]\n",
      "Training Epoch 87/300, Loss: 0.3494, Accuracy: 0.8300, F1: 0.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93327037 0.81690141 0.698941   0.         0.         0.\n",
      " 0.         0.         0.         0.71610169 0.72727273 0.14349776\n",
      " 0.11235955 0.27555556 0.03636364 0.62985685 0.71380471 0.84488449\n",
      " 0.7528992  0.49003984 0.66999202 0.20125786 0.30659537 0.\n",
      " 0.         0.20491803 0.1657754  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 87/300, Loss: 0.2877, Accuracy: 0.8592, F1: 0.4146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9131596  0.53991597 0.50415094 0.01456311 0.02475248 0.00711744\n",
      " 0.03791469 0.01405152 0.01183432 0.57494867 0.54866455 0.23217247\n",
      " 0.25435074 0.14651002 0.06079027 0.41450777 0.49800418 0.66221852\n",
      " 0.63492576 0.49297821 0.71072884 0.29575403 0.47912825 0.06318348\n",
      " 0.08058608 0.18644068 0.17293777 0.99214775 0.93138723 0.94995245]\n",
      "Training Epoch 88/300, Loss: 0.3565, Accuracy: 0.8254, F1: 0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93701864 0.81012658 0.64182692 0.         0.         0.\n",
      " 0.         0.         0.         0.75396825 0.6088632  0.21862348\n",
      " 0.24952741 0.21782178 0.03571429 0.63157895 0.66758621 0.81889764\n",
      " 0.72222222 0.60807601 0.78352446 0.44776119 0.64864865 0.01639344\n",
      " 0.04651163 0.30769231 0.33402062 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 88/300, Loss: 0.2716, Accuracy: 0.8698, F1: 0.4502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91258185 0.56042216 0.51687764 0.04316547 0.04050633 0.\n",
      " 0.00982801 0.         0.         0.59142395 0.56415007 0.24671053\n",
      " 0.29029218 0.13080169 0.01892744 0.44254592 0.51840607 0.66592054\n",
      " 0.62621991 0.51365597 0.74718636 0.34048853 0.5192767  0.06153846\n",
      " 0.07398568 0.18819562 0.18298447 0.9909434  0.93388224 0.94739336]\n",
      "Training Epoch 89/300, Loss: 0.3536, Accuracy: 0.8296, F1: 0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93078362 0.83977901 0.73059361 0.         0.         0.\n",
      " 0.         0.         0.         0.75959596 0.72351421 0.36363636\n",
      " 0.39839572 0.25       0.03571429 0.63596491 0.68477207 0.83360791\n",
      " 0.74777975 0.65317919 0.82774978 0.47413793 0.61891117 0.\n",
      " 0.         0.24266145 0.235      0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 89/300, Loss: 0.2737, Accuracy: 0.8761, F1: 0.4661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91437018 0.55729167 0.53480606 0.0477327  0.03526448 0.01428571\n",
      " 0.02843602 0.01909308 0.0126183  0.58961882 0.59082892 0.21316249\n",
      " 0.28975811 0.15405968 0.01807229 0.43790013 0.55851369 0.66054024\n",
      " 0.63255361 0.54803597 0.77100284 0.33207547 0.51082102 0.03768844\n",
      " 0.04521277 0.20107962 0.18964893 0.99265583 0.92919968 0.94836683]\n",
      "Training Epoch 90/300, Loss: 0.3438, Accuracy: 0.8343, F1: 0.3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92433873 0.83529412 0.72340426 0.         0.         0.\n",
      " 0.         0.         0.         0.73100616 0.74643875 0.39616613\n",
      " 0.40787623 0.25742574 0.         0.62100457 0.6273224  0.83194676\n",
      " 0.73449612 0.63360882 0.82303133 0.42708333 0.63648834 0.\n",
      " 0.         0.23506744 0.2039801  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 90/300, Loss: 0.2845, Accuracy: 0.8729, F1: 0.4598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91450315 0.55791711 0.53622068 0.0195122  0.02570694 0.01454545\n",
      " 0.01463415 0.01428571 0.01869159 0.56955273 0.54223052 0.21857305\n",
      " 0.26828087 0.15277778 0.05454545 0.43683084 0.54014044 0.66294954\n",
      " 0.62261042 0.53333333 0.73975053 0.35155096 0.52437996 0.05445545\n",
      " 0.07682119 0.18980074 0.19343326 0.99227533 0.92912403 0.94813056]\n",
      "Training Epoch 91/300, Loss: 0.3418, Accuracy: 0.8305, F1: 0.3906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9334332  0.84122563 0.67759563 0.         0.         0.\n",
      " 0.         0.         0.         0.75052411 0.67772512 0.37288136\n",
      " 0.37843137 0.18461538 0.         0.64719101 0.7204611  0.82658023\n",
      " 0.72374798 0.55580866 0.72913936 0.432      0.58928571 0.\n",
      " 0.         0.27058824 0.25242718 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 91/300, Loss: 0.2728, Accuracy: 0.8615, F1: 0.4521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91558681 0.56191467 0.52684904 0.02309469 0.04454343 0.00714286\n",
      " 0.01814059 0.00938967 0.01851852 0.57559789 0.57683641 0.23644752\n",
      " 0.30451223 0.17768871 0.04776119 0.45777968 0.56185467 0.68178048\n",
      " 0.65676884 0.54250239 0.74893535 0.35311573 0.53253394 0.0476788\n",
      " 0.0576671  0.18813216 0.1928494  0.99252653 0.92934206 0.95085089]\n",
      "Training Epoch 92/300, Loss: 0.3425, Accuracy: 0.8347, F1: 0.3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92980878 0.83760684 0.75118859 0.         0.         0.\n",
      " 0.         0.         0.         0.69601677 0.69544365 0.36491228\n",
      " 0.42700157 0.2464455  0.03508772 0.65086207 0.73003802 0.83168317\n",
      " 0.74347435 0.64387464 0.82415317 0.47509579 0.61443662 0.\n",
      " 0.         0.19665272 0.18617021 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 92/300, Loss: 0.2705, Accuracy: 0.8759, F1: 0.4626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91564866 0.56282999 0.5483871  0.05381166 0.0856531  0.0070922\n",
      " 0.00481928 0.01408451 0.0060423  0.57177914 0.56165026 0.24214734\n",
      " 0.28719723 0.16449623 0.03614458 0.43830889 0.56242752 0.67610325\n",
      " 0.63636364 0.53979872 0.73971063 0.33307271 0.50847458 0.05350318\n",
      " 0.07496653 0.20013755 0.19209859 0.99404127 0.92910634 0.94824213]\n",
      "Training Epoch 93/300, Loss: 0.3364, Accuracy: 0.8340, F1: 0.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93612793 0.84065934 0.71244635 0.         0.         0.\n",
      " 0.         0.         0.         0.75918367 0.68877551 0.3297491\n",
      " 0.38222222 0.24413146 0.03571429 0.6637931  0.76657584 0.83087028\n",
      " 0.75369887 0.54304636 0.73726009 0.46829268 0.64963504 0.\n",
      " 0.         0.22903885 0.20997375 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 93/300, Loss: 0.2656, Accuracy: 0.8727, F1: 0.4593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91770834 0.58400429 0.54985376 0.04555809 0.05555556 0.\n",
      " 0.         0.00966184 0.00632911 0.58861789 0.59187442 0.25672646\n",
      " 0.29459522 0.15165877 0.03039514 0.44645161 0.56830811 0.68151815\n",
      " 0.65140112 0.53416747 0.76069216 0.33919022 0.55545304 0.0470297\n",
      " 0.06426735 0.19073024 0.19461698 0.99372647 0.93536311 0.95234691]\n",
      "Training Epoch 94/300, Loss: 0.3375, Accuracy: 0.8377, F1: 0.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92641765 0.74038462 0.63511831 0.         0.         0.\n",
      " 0.         0.         0.         0.69098712 0.73239437 0.11214953\n",
      " 0.08391608 0.2962963  0.03636364 0.64052288 0.6785361  0.82372323\n",
      " 0.73811743 0.62295082 0.81099271 0.47963801 0.67861142 0.\n",
      " 0.         0.22355289 0.18087855 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 94/300, Loss: 0.2746, Accuracy: 0.8706, F1: 0.4377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9140195  0.56224066 0.54288649 0.02933985 0.03562341 0.02867384\n",
      " 0.0195122  0.00475059 0.01230769 0.57351154 0.57986577 0.22296173\n",
      " 0.26983764 0.16071429 0.06395349 0.44171259 0.54269663 0.67379679\n",
      " 0.64133094 0.49618321 0.70996847 0.33285509 0.51187162 0.05825243\n",
      " 0.07730673 0.20410868 0.20185376 0.99189546 0.93489648 0.95425773]\n",
      "Training Epoch 95/300, Loss: 0.3449, Accuracy: 0.8285, F1: 0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93625662 0.82183908 0.73094868 0.         0.         0.\n",
      " 0.         0.         0.         0.75763747 0.66964286 0.26356589\n",
      " 0.28051002 0.21782178 0.03636364 0.6506986  0.7340591  0.83828383\n",
      " 0.7607362  0.45810056 0.63163779 0.35359116 0.48961424 0.\n",
      " 0.         0.29050279 0.29580574 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 95/300, Loss: 0.2759, Accuracy: 0.8572, F1: 0.4405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91406704 0.57802875 0.5526779  0.02870813 0.03755869 0.0137931\n",
      " 0.02079002 0.01860465 0.02949853 0.59910823 0.6008193  0.23116147\n",
      " 0.29363941 0.16197666 0.03680982 0.44839255 0.52631579 0.66610597\n",
      " 0.63901491 0.55290102 0.76630735 0.35724963 0.53147593 0.06264501\n",
      " 0.08275862 0.19346319 0.17821782 0.99214775 0.92633942 0.94488096]\n",
      "Training Epoch 96/300, Loss: 0.3457, Accuracy: 0.8326, F1: 0.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9376336  0.85399449 0.72622478 0.         0.         0.\n",
      " 0.         0.         0.         0.76578411 0.70588235 0.35460993\n",
      " 0.3957382  0.25837321 0.         0.64811133 0.71906615 0.84039088\n",
      " 0.75689655 0.67750678 0.83571621 0.46575342 0.66452304 0.\n",
      " 0.         0.34364261 0.33628319 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 96/300, Loss: 0.2567, Accuracy: 0.8815, F1: 0.4762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91606645 0.55124801 0.53528489 0.07058824 0.09389671 0.02142857\n",
      " 0.02877698 0.01900238 0.01869159 0.58752026 0.58565555 0.24272931\n",
      " 0.2886747  0.16621253 0.05797101 0.44779983 0.57081629 0.68652561\n",
      " 0.64956988 0.52333805 0.73742039 0.3488024  0.52157272 0.03096774\n",
      " 0.03851444 0.20554124 0.2067324  0.9916452  0.92787622 0.946034  ]\n",
      "Training Epoch 97/300, Loss: 0.3385, Accuracy: 0.8337, F1: 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93811958 0.84383562 0.72830725 0.         0.         0.\n",
      " 0.         0.         0.         0.76131687 0.69626168 0.36825397\n",
      " 0.39298246 0.24       0.         0.65461847 0.72343632 0.84262295\n",
      " 0.75304348 0.66473988 0.83538371 0.4526749  0.57437661 0.\n",
      " 0.         0.35168196 0.35072464 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 97/300, Loss: 0.2573, Accuracy: 0.8746, F1: 0.4724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90909469 0.55956873 0.51169041 0.04651163 0.07272727 0.\n",
      " 0.         0.02714932 0.04931507 0.57200811 0.56882407 0.19908987\n",
      " 0.21991505 0.16733068 0.0509915  0.45052632 0.51174242 0.66098433\n",
      " 0.62001287 0.38825149 0.58365274 0.28764045 0.40658757 0.05399061\n",
      " 0.08806489 0.18264543 0.17767348 0.99353948 0.93146243 0.95183664]\n",
      "Training Epoch 98/300, Loss: 0.3831, Accuracy: 0.8132, F1: 0.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9374718  0.84782609 0.74198047 0.         0.         0.\n",
      " 0.         0.         0.         0.75918367 0.68899522 0.39344262\n",
      " 0.3844697  0.17112299 0.         0.65324385 0.71952428 0.83954619\n",
      " 0.74426508 0.62952646 0.81987217 0.47302905 0.60600546 0.\n",
      " 0.         0.37741047 0.37760417 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 98/300, Loss: 0.2679, Accuracy: 0.8731, F1: 0.4721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9142919  0.55602537 0.54608234 0.03365385 0.05432099 0.00689655\n",
      " 0.03071017 0.00954654 0.00613497 0.58377497 0.57261411 0.25105485\n",
      " 0.28220339 0.17295189 0.04142012 0.45671267 0.56425741 0.67073848\n",
      " 0.63486948 0.46006695 0.73097772 0.33045977 0.48863071 0.06009615\n",
      " 0.07857143 0.18613733 0.18386876 0.99278318 0.92949838 0.94606104]\n",
      "Training Epoch 99/300, Loss: 0.3544, Accuracy: 0.8280, F1: 0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93905952 0.85142857 0.75159236 0.         0.         0.11320755\n",
      " 0.1588785  0.         0.         0.75463918 0.70904645 0.42685851\n",
      " 0.4        0.1865285  0.         0.64935065 0.74803836 0.84466019\n",
      " 0.75103391 0.65730337 0.83565936 0.41967213 0.46622033 0.\n",
      " 0.         0.38793103 0.35733333 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 99/300, Loss: 0.2705, Accuracy: 0.8649, F1: 0.4802\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91098599 0.57798165 0.55013484 0.04063205 0.05139186 0.01398601\n",
      " 0.00921659 0.0046729  0.01729107 0.58279221 0.57707865 0.21351505\n",
      " 0.24599186 0.15290934 0.03508772 0.43877551 0.53844671 0.66222592\n",
      " 0.62213801 0.51153846 0.75362614 0.32053176 0.51088281 0.07407407\n",
      " 0.09917355 0.18044122 0.17454798 0.99284728 0.93259338 0.95264757]\n",
      "Training Epoch 100/300, Loss: 0.3632, Accuracy: 0.8284, F1: 0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93993899 0.84764543 0.72753623 0.         0.         0.04081633\n",
      " 0.03409091 0.         0.         0.76363636 0.67672414 0.35897436\n",
      " 0.39494471 0.20833333 0.         0.65447154 0.71942446 0.81860465\n",
      " 0.72       0.66847826 0.83401695 0.43312102 0.48421053 0.048\n",
      " 0.09022556 0.38176638 0.3627907  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 100/300, Loss: 0.2702, Accuracy: 0.8676, F1: 0.4735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91839785 0.54717976 0.5336415  0.05176471 0.05188679 0.01433692\n",
      " 0.00484262 0.00954654 0.00621118 0.60956976 0.60475968 0.2668149\n",
      " 0.29594628 0.1755102  0.04733728 0.44623884 0.56653341 0.67019794\n",
      " 0.64010451 0.5124195  0.75762239 0.3648548  0.56713781 0.04926108\n",
      " 0.0698577  0.22003284 0.20701879 0.99322119 0.92884316 0.9482544 ]\n",
      "Training Epoch 101/300, Loss: 0.3316, Accuracy: 0.8376, F1: 0.4026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93705732 0.845953   0.69392813 0.         0.         0.\n",
      " 0.         0.         0.         0.77732794 0.70702179 0.37942122\n",
      " 0.42521632 0.28708134 0.03508772 0.67803838 0.77466063 0.84640523\n",
      " 0.75530933 0.63027295 0.81192547 0.50909091 0.67741935 0.\n",
      " 0.         0.3030303  0.31944444 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 101/300, Loss: 0.2561, Accuracy: 0.8808, F1: 0.4797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91895797 0.57538625 0.54032473 0.06542056 0.09375    0.02888087\n",
      " 0.02439024 0.         0.         0.59854015 0.62682482 0.25189189\n",
      " 0.30200236 0.18632708 0.09855072 0.4461408  0.56202826 0.681555\n",
      " 0.65059102 0.55228137 0.76528331 0.37329287 0.56114082 0.06617647\n",
      " 0.06762029 0.21177244 0.21317696 0.99322119 0.93188623 0.95139509]\n",
      "Training Epoch 102/300, Loss: 0.3285, Accuracy: 0.8391, F1: 0.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93352534 0.84530387 0.75419847 0.         0.         0.\n",
      " 0.         0.         0.         0.74526316 0.704      0.3902439\n",
      " 0.4137931  0.22660099 0.         0.65315315 0.68972746 0.832\n",
      " 0.7566638  0.65091864 0.83149026 0.48372093 0.67353952 0.\n",
      " 0.         0.24193548 0.21989529 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 102/300, Loss: 0.2601, Accuracy: 0.8794, F1: 0.4682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91912656 0.57445681 0.56696196 0.07025761 0.08430913 0.0212766\n",
      " 0.02891566 0.01392111 0.01197605 0.59061489 0.59065934 0.2625139\n",
      " 0.32554848 0.19958988 0.03669725 0.46055437 0.58280682 0.6591676\n",
      " 0.63952366 0.54861437 0.76399003 0.36793893 0.57285181 0.04285714\n",
      " 0.05128205 0.20146765 0.20912684 0.99234246 0.93550399 0.95235259]\n",
      "Training Epoch 103/300, Loss: 0.3268, Accuracy: 0.8400, F1: 0.4092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93256342 0.83287671 0.72910663 0.         0.         0.\n",
      " 0.         0.         0.         0.7348643  0.71891892 0.37992832\n",
      " 0.43260188 0.27184466 0.03636364 0.66666667 0.73843566 0.83469722\n",
      " 0.74464286 0.67241379 0.81328284 0.50413223 0.6380597  0.\n",
      " 0.         0.27413127 0.28639618 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 103/300, Loss: 0.2587, Accuracy: 0.8788, F1: 0.4747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91787428 0.58429319 0.56787617 0.02369668 0.02708804 0.02836879\n",
      " 0.04225352 0.01408451 0.01230769 0.59220146 0.58180188 0.25695217\n",
      " 0.34474616 0.20978121 0.08196721 0.45249254 0.55436685 0.66390041\n",
      " 0.63294423 0.52835408 0.74283058 0.37678975 0.55225209 0.04790419\n",
      " 0.06666667 0.22068054 0.23585876 0.99208443 0.93438942 0.95242065]\n",
      "Training Epoch 104/300, Loss: 0.3315, Accuracy: 0.8362, F1: 0.4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93847134 0.83146067 0.7        0.         0.         0.04444444\n",
      " 0.07317073 0.         0.         0.76386037 0.68008949 0.3902439\n",
      " 0.40674394 0.25242718 0.07142857 0.66666667 0.75706215 0.84244373\n",
      " 0.74235105 0.55679287 0.71725307 0.44343891 0.61164021 0.\n",
      " 0.         0.35276074 0.35849057 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 104/300, Loss: 0.2618, Accuracy: 0.8646, F1: 0.4733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91287074 0.56029489 0.54988459 0.02298851 0.03579418 0.01433692\n",
      " 0.00963855 0.02304147 0.01162791 0.60350318 0.56988764 0.24958769\n",
      " 0.31578947 0.16351351 0.02402402 0.43178921 0.55759923 0.67107438\n",
      " 0.64029119 0.54623044 0.74385725 0.34918161 0.53865516 0.07234539\n",
      " 0.09123649 0.21149571 0.19742489 0.99246326 0.92900811 0.94997029]\n",
      "Training Epoch 105/300, Loss: 0.3487, Accuracy: 0.8309, F1: 0.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93793373 0.8277635  0.64585834 0.         0.         0.08333333\n",
      " 0.17475728 0.         0.         0.76482618 0.67833698 0.39169139\n",
      " 0.41207076 0.17894737 0.         0.66810345 0.77005348 0.83860759\n",
      " 0.74923077 0.57270694 0.73278476 0.45248869 0.61702128 0.01666667\n",
      " 0.05042017 0.36038961 0.37643208 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 105/300, Loss: 0.2639, Accuracy: 0.8666, F1: 0.4766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91570934 0.58395722 0.56387199 0.04587156 0.08735632 0.00719424\n",
      " 0.04484305 0.01405152 0.02431611 0.5908727  0.61648746 0.25323579\n",
      " 0.30673005 0.18644068 0.03498542 0.45337896 0.57278421 0.68850639\n",
      " 0.65346211 0.52685661 0.75351841 0.36646884 0.54409463 0.08405172\n",
      " 0.09249743 0.19565943 0.19929577 0.9936002  0.93201098 0.94821661]\n",
      "Training Epoch 106/300, Loss: 0.3394, Accuracy: 0.8355, F1: 0.4093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93951125 0.84357542 0.73163418 0.         0.         0.\n",
      " 0.         0.         0.         0.75151515 0.69463869 0.39597315\n",
      " 0.43250328 0.23115578 0.         0.67381974 0.78091873 0.8352\n",
      " 0.7439222  0.5823389  0.7649683  0.43816254 0.54890511 0.01709402\n",
      " 0.03508772 0.35099338 0.36697248 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 106/300, Loss: 0.2588, Accuracy: 0.8715, F1: 0.4719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91961074 0.5817028  0.56510551 0.07075472 0.07785888 0.02867384\n",
      " 0.03373494 0.00932401 0.02416918 0.60890493 0.62254025 0.29062673\n",
      " 0.35445496 0.19695968 0.04892966 0.46246246 0.60142349 0.67625899\n",
      " 0.65315463 0.5535545  0.77329435 0.35671642 0.53850258 0.06585366\n",
      " 0.08673469 0.19893546 0.20262132 0.99391735 0.92599526 0.94908205]\n",
      "Training Epoch 107/300, Loss: 0.3231, Accuracy: 0.8417, F1: 0.4157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9344247  0.8356546  0.74178404 0.         0.         0.\n",
      " 0.         0.         0.         0.72536688 0.71891892 0.38032787\n",
      " 0.3977433  0.21890547 0.         0.65924276 0.72837022 0.84868421\n",
      " 0.75443511 0.62468514 0.81058148 0.48672566 0.69282511 0.\n",
      " 0.         0.236      0.21243523 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 107/300, Loss: 0.2610, Accuracy: 0.8797, F1: 0.4669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91891151 0.59614382 0.55431102 0.05581395 0.07834101 0.01393728\n",
      " 0.02678571 0.00465116 0.01146132 0.58717105 0.58515699 0.2585034\n",
      " 0.32050658 0.18503401 0.08219178 0.46540881 0.59124907 0.68325041\n",
      " 0.65993266 0.55231725 0.77411822 0.36009002 0.53839396 0.08286674\n",
      " 0.10114943 0.2089155  0.20356768 0.99429503 0.92907492 0.94863115]\n",
      "Training Epoch 108/300, Loss: 0.3236, Accuracy: 0.8400, F1: 0.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93854327 0.85245902 0.74425287 0.         0.         0.12765957\n",
      " 0.34       0.         0.         0.70258621 0.69417476 0.3986711\n",
      " 0.45006658 0.22110553 0.         0.67070707 0.74444444 0.84244373\n",
      " 0.76048951 0.63131313 0.81444583 0.47826087 0.6787234  0.\n",
      " 0.         0.27722772 0.2815534  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 108/300, Loss: 0.2523, Accuracy: 0.8820, F1: 0.4883\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92160104 0.57826313 0.5736551  0.06074766 0.07692308 0.\n",
      " 0.         0.01851852 0.03003003 0.59991958 0.60471442 0.27242152\n",
      " 0.32911392 0.20376379 0.06197183 0.45879354 0.57763975 0.68026831\n",
      " 0.65780084 0.54079696 0.7792884  0.35466461 0.57818182 0.07177033\n",
      " 0.09720535 0.23294509 0.23066202 0.99296924 0.93656833 0.95259083]\n",
      "Training Epoch 109/300, Loss: 0.3188, Accuracy: 0.8440, F1: 0.4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92953413 0.82573727 0.74164134 0.         0.         0.\n",
      " 0.         0.         0.         0.70842333 0.74651811 0.32824427\n",
      " 0.30654206 0.28054299 0.03571429 0.66805846 0.72977941 0.83469722\n",
      " 0.7520436  0.62983425 0.81087203 0.50678733 0.68486917 0.\n",
      " 0.         0.22845691 0.21025641 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 109/300, Loss: 0.2605, Accuracy: 0.8776, F1: 0.4652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92072988 0.57366771 0.55900935 0.05022831 0.06153846 0.01423488\n",
      " 0.00938967 0.02784223 0.05294118 0.58828349 0.59466912 0.25306577\n",
      " 0.313945   0.1745503  0.0247678  0.45194805 0.5922865  0.68527217\n",
      " 0.65957109 0.55083532 0.78015696 0.3561848  0.55975275 0.07285546\n",
      " 0.10849057 0.22207358 0.22805177 0.99423342 0.93513783 0.95410873]\n",
      "Training Epoch 110/300, Loss: 0.3217, Accuracy: 0.8421, F1: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93776783 0.85483871 0.71081081 0.         0.         0.08695652\n",
      " 0.28865979 0.         0.         0.75619835 0.70617284 0.40112994\n",
      " 0.40120968 0.19191919 0.         0.67956989 0.77402135 0.84364821\n",
      " 0.7650655  0.59708738 0.78854415 0.4573991  0.62379421 0.01724138\n",
      " 0.01785714 0.29296875 0.29776675 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 110/300, Loss: 0.2529, Accuracy: 0.8765, F1: 0.4830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92056243 0.59255319 0.58640374 0.07305936 0.10884354 0.02909091\n",
      " 0.03508772 0.01382488 0.02431611 0.59631902 0.62631077 0.26749436\n",
      " 0.31607099 0.18552632 0.05157593 0.4567533  0.57958246 0.69273743\n",
      " 0.65494435 0.54164683 0.78382066 0.39127163 0.56692913 0.07311321\n",
      " 0.09058403 0.21608725 0.22519913 0.99423342 0.92621468 0.948142  ]\n",
      "Training Epoch 111/300, Loss: 0.3205, Accuracy: 0.8433, F1: 0.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93748533 0.83798883 0.74382716 0.         0.         0.\n",
      " 0.         0.         0.         0.72611465 0.7100271  0.37458194\n",
      " 0.4039548  0.25352113 0.03571429 0.68432671 0.75848303 0.85385878\n",
      " 0.76069154 0.59069767 0.76866359 0.46078431 0.66906475 0.\n",
      " 0.         0.28790787 0.29928741 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 111/300, Loss: 0.2550, Accuracy: 0.8787, F1: 0.4719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92073922 0.59873284 0.57128019 0.07798165 0.10623557 0.02135231\n",
      " 0.03286385 0.01856148 0.01764706 0.61329063 0.60172179 0.27597956\n",
      " 0.34014252 0.18595318 0.06303725 0.46245734 0.58508604 0.67675918\n",
      " 0.64758208 0.54022989 0.77001704 0.39364118 0.59080419 0.05825243\n",
      " 0.08215661 0.23240372 0.23819591 0.99265306 0.93137867 0.95210865]\n",
      "Training Epoch 112/300, Loss: 0.3202, Accuracy: 0.8432, F1: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93262452 0.82816901 0.73990307 0.         0.         0.\n",
      " 0.         0.         0.         0.72536688 0.73623188 0.30952381\n",
      " 0.32653061 0.26923077 0.03636364 0.66806723 0.73142857 0.84210526\n",
      " 0.74579439 0.60591133 0.79554455 0.46728972 0.67478685 0.\n",
      " 0.         0.20661157 0.15342466 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 112/300, Loss: 0.2684, Accuracy: 0.8780, F1: 0.4598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92165113 0.59601259 0.59354177 0.03240741 0.04215457 0.02142857\n",
      " 0.01388889 0.02283105 0.04       0.59682022 0.61350249 0.28128461\n",
      " 0.33333333 0.2186452  0.06666667 0.48016878 0.60519179 0.69162507\n",
      " 0.67264287 0.57521287 0.77517508 0.37668161 0.58256963 0.06896552\n",
      " 0.09810479 0.21388615 0.22744556 0.99448345 0.93212726 0.94893112]\n",
      "Training Epoch 113/300, Loss: 0.3171, Accuracy: 0.8442, F1: 0.4212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93610358 0.85175202 0.74861878 0.         0.         0.04444444\n",
      " 0.07317073 0.         0.         0.76861167 0.69483568 0.41311475\n",
      " 0.46938776 0.24880383 0.03571429 0.69230769 0.77208481 0.84090909\n",
      " 0.75529213 0.65753425 0.83652269 0.49769585 0.69004525 0.\n",
      " 0.         0.30018762 0.30373832 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 113/300, Loss: 0.2501, Accuracy: 0.8842, F1: 0.4876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92175691 0.59425587 0.58882738 0.09633028 0.10810811 0.01413428\n",
      " 0.03174603 0.03652968 0.04069767 0.61446741 0.63427562 0.2744881\n",
      " 0.35896204 0.19482289 0.03571429 0.46942291 0.59367014 0.67450322\n",
      " 0.65595888 0.57007576 0.77958214 0.37188209 0.55674208 0.10465116\n",
      " 0.12559242 0.22302158 0.21546961 0.99404127 0.9300237  0.94854905]\n",
      "Training Epoch 114/300, Loss: 0.3161, Accuracy: 0.8443, F1: 0.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93903905 0.832      0.71117166 0.         0.         0.\n",
      " 0.         0.         0.         0.77235772 0.72222222 0.38487973\n",
      " 0.44130127 0.26086957 0.03636364 0.67342799 0.74033149 0.84858569\n",
      " 0.75232775 0.63       0.80009681 0.48275862 0.67506297 0.\n",
      " 0.         0.32293578 0.33860045 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 114/300, Loss: 0.2507, Accuracy: 0.8822, F1: 0.4788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92039502 0.58943966 0.57522594 0.08108108 0.10660981 0.00704225\n",
      " 0.0619469  0.0137931  0.02359882 0.59338843 0.60837552 0.25828571\n",
      " 0.31447171 0.17875648 0.06197183 0.45320624 0.60150376 0.68670006\n",
      " 0.66570467 0.55433222 0.77237752 0.37527923 0.58919861 0.0700565\n",
      " 0.10206298 0.2204568  0.23615978 0.9936002  0.9272886  0.94908012]\n",
      "Training Epoch 115/300, Loss: 0.3212, Accuracy: 0.8424, F1: 0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94136262 0.80407125 0.70184697 0.         0.         0.\n",
      " 0.         0.         0.         0.75776398 0.7047619  0.33834586\n",
      " 0.38397329 0.26415094 0.03571429 0.69052632 0.77866667 0.84789644\n",
      " 0.77653149 0.64303797 0.81225296 0.48372093 0.68771139 0.\n",
      " 0.         0.35075885 0.3572621  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 115/300, Loss: 0.2485, Accuracy: 0.8840, F1: 0.4786\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91960319 0.57813333 0.57038391 0.07207207 0.0845666  0.03533569\n",
      " 0.02836879 0.02745995 0.0518732  0.58765432 0.6040146  0.26410835\n",
      " 0.32683877 0.17419355 0.06648199 0.45617021 0.56782831 0.67805954\n",
      " 0.65303535 0.55491882 0.7646398  0.36002939 0.55071979 0.08058608\n",
      " 0.09438776 0.23521682 0.23733424 0.99492449 0.93424828 0.95260776]\n",
      "Training Epoch 116/300, Loss: 0.3206, Accuracy: 0.8403, F1: 0.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94109823 0.82901554 0.68886044 0.         0.         0.08695652\n",
      " 0.28865979 0.         0.         0.75052411 0.7020202  0.4\n",
      " 0.46057572 0.25120773 0.         0.69807281 0.78564857 0.84126984\n",
      " 0.76647681 0.65782493 0.83368311 0.48387097 0.60627178 0.\n",
      " 0.         0.3567753  0.38113208 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 116/300, Loss: 0.2468, Accuracy: 0.8831, F1: 0.4936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91942055 0.59203445 0.57188755 0.07289294 0.09438202 0.02857143\n",
      " 0.02850356 0.0228833  0.0509915  0.60235103 0.64587973 0.26481994\n",
      " 0.32492189 0.15497662 0.03550296 0.46923077 0.58571989 0.68644303\n",
      " 0.65104768 0.52108006 0.74084863 0.36964688 0.55683453 0.09069767\n",
      " 0.11217184 0.20740247 0.19760056 0.99536573 0.93395697 0.95249434]\n",
      "Training Epoch 117/300, Loss: 0.3184, Accuracy: 0.8397, F1: 0.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92993572 0.85483871 0.75675676 0.         0.         0.\n",
      " 0.         0.         0.         0.75313808 0.71168831 0.42076503\n",
      " 0.39815668 0.21782178 0.         0.67672414 0.75666075 0.85855263\n",
      " 0.76518586 0.57718121 0.67629015 0.47058824 0.64957265 0.\n",
      " 0.         0.34257749 0.34196891 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 117/300, Loss: 0.2613, Accuracy: 0.8681, F1: 0.4719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92048656 0.59748771 0.57423639 0.07111111 0.09704641 0.02846975\n",
      " 0.03818616 0.03644647 0.07162534 0.60288231 0.60769571 0.27041943\n",
      " 0.34617191 0.19205298 0.06340058 0.46179966 0.5949464  0.67787115\n",
      " 0.65919428 0.50372439 0.74369266 0.39969947 0.56052772 0.11538462\n",
      " 0.14027149 0.21011162 0.20013947 0.99410806 0.93212726 0.95229019]\n",
      "Training Epoch 118/300, Loss: 0.3228, Accuracy: 0.8407, F1: 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93778452 0.82215743 0.72413793 0.         0.         0.\n",
      " 0.         0.         0.         0.74468085 0.71309192 0.39310345\n",
      " 0.39685039 0.27272727 0.03571429 0.68776371 0.75069509 0.84364821\n",
      " 0.77135462 0.6        0.78938561 0.45226131 0.66666667 0.\n",
      " 0.         0.3100189  0.33488372 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 118/300, Loss: 0.2589, Accuracy: 0.8818, F1: 0.4749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91973665 0.59968102 0.57268722 0.09259259 0.10574713 0.04285714\n",
      " 0.06088993 0.03579418 0.06486486 0.61126648 0.58666667 0.27181208\n",
      " 0.31836327 0.19294744 0.06916427 0.47162673 0.58886551 0.6951989\n",
      " 0.66493253 0.50623202 0.74117763 0.37797619 0.58528785 0.07174888\n",
      " 0.08762322 0.23394056 0.22651391 0.99410658 0.93231863 0.95216564]\n",
      "Training Epoch 119/300, Loss: 0.3246, Accuracy: 0.8402, F1: 0.4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93033863 0.85479452 0.771261   0.         0.         0.04444444\n",
      " 0.13483146 0.         0.         0.75564682 0.71428571 0.4137931\n",
      " 0.41814596 0.23414634 0.         0.63425926 0.64659978 0.84628099\n",
      " 0.7537594  0.66860465 0.82232893 0.49565217 0.67106711 0.\n",
      " 0.         0.22360248 0.19618529 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 119/300, Loss: 0.2625, Accuracy: 0.8758, F1: 0.4743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92059586 0.59872611 0.59846547 0.12227074 0.13417191 0.02721088\n",
      " 0.03036876 0.03211009 0.05681818 0.59894779 0.62798021 0.27467811\n",
      " 0.31423895 0.21736334 0.03418803 0.45122475 0.55714574 0.68273543\n",
      " 0.65878925 0.59073724 0.79500195 0.38534799 0.58186182 0.09954751\n",
      " 0.13425926 0.21650518 0.2163513  0.9949881  0.93231019 0.95110054]\n",
      "Training Epoch 120/300, Loss: 0.3217, Accuracy: 0.8438, F1: 0.4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93877456 0.84097035 0.75923191 0.         0.         0.\n",
      " 0.         0.         0.         0.76734694 0.71428571 0.38754325\n",
      " 0.4454023  0.27358491 0.03636364 0.69473684 0.77466063 0.84565916\n",
      " 0.76724138 0.66492147 0.8343303  0.48868778 0.68995633 0.\n",
      " 0.         0.31460674 0.32794457 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 120/300, Loss: 0.2488, Accuracy: 0.8868, F1: 0.4855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92225616 0.57379596 0.587999   0.10087719 0.0952381  0.01369863\n",
      " 0.01244813 0.02745995 0.06413994 0.60921844 0.6123348  0.26518106\n",
      " 0.33525734 0.21194605 0.06179775 0.44920703 0.59371407 0.6870692\n",
      " 0.65775918 0.57115104 0.79365863 0.39207048 0.58541595 0.09669811\n",
      " 0.11360947 0.2187398  0.23565574 0.99517755 0.9246601  0.94697553]\n",
      "Training Epoch 121/300, Loss: 0.3119, Accuracy: 0.8443, F1: 0.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93948938 0.84593838 0.75650842 0.         0.         0.08695652\n",
      " 0.28865979 0.         0.         0.77113402 0.70257611 0.42461538\n",
      " 0.44       0.27488152 0.03571429 0.67549669 0.77376426 0.84057971\n",
      " 0.76616915 0.59277108 0.77213695 0.45490196 0.60088889 0.06504065\n",
      " 0.08064516 0.33208955 0.35185185 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 121/300, Loss: 0.2460, Accuracy: 0.8778, F1: 0.4957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92276386 0.592      0.58560924 0.10859729 0.11981567 0.01403509\n",
      " 0.05164319 0.04504505 0.04918033 0.58946522 0.61213235 0.27833895\n",
      " 0.34659636 0.19379845 0.04651163 0.47132692 0.61157345 0.68546158\n",
      " 0.6608     0.55007052 0.78476869 0.38893159 0.57829978 0.10262009\n",
      " 0.14209968 0.24613402 0.25843072 0.99410584 0.92727046 0.9430626 ]\n",
      "Training Epoch 122/300, Loss: 0.3103, Accuracy: 0.8454, F1: 0.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93633909 0.85714286 0.73157163 0.         0.         0.\n",
      " 0.         0.         0.         0.76701031 0.7146402  0.41666667\n",
      " 0.41626331 0.21568627 0.         0.66962306 0.743818   0.8608838\n",
      " 0.767713   0.67768595 0.83458856 0.46666667 0.61753731 0.06557377\n",
      " 0.0661157  0.33458647 0.35746606 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 122/300, Loss: 0.2481, Accuracy: 0.8799, F1: 0.4839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92230029 0.61369577 0.60950465 0.07025761 0.08035714 0.01408451\n",
      " 0.01342282 0.06392694 0.09329446 0.61569096 0.60365297 0.28256071\n",
      " 0.35925313 0.21912351 0.07317073 0.47219846 0.6256451  0.69343891\n",
      " 0.66078431 0.54536862 0.76762173 0.39101124 0.59154443 0.08545035\n",
      " 0.11570248 0.24500491 0.24870466 0.99505106 0.93213573 0.95446135]\n",
      "Training Epoch 123/300, Loss: 0.3144, Accuracy: 0.8457, F1: 0.4319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93939761 0.82739726 0.69272237 0.         0.         0.04444444\n",
      " 0.07317073 0.         0.         0.76348548 0.70192308 0.4\n",
      " 0.41447368 0.26666667 0.07142857 0.69894737 0.79173838 0.8538961\n",
      " 0.76315789 0.55187638 0.72731183 0.45132743 0.61983471 0.01724138\n",
      " 0.01801802 0.35253054 0.37379576 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 123/300, Loss: 0.2511, Accuracy: 0.8711, F1: 0.4804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92180287 0.60136197 0.58571784 0.08735632 0.09677419 0.01428571\n",
      " 0.01369863 0.0496614  0.05172414 0.59748683 0.60194175 0.26659168\n",
      " 0.34340457 0.21730644 0.09356725 0.46251588 0.59891178 0.69418283\n",
      " 0.65685794 0.52013264 0.74788197 0.38690476 0.56067089 0.08634772\n",
      " 0.09512485 0.21445068 0.21917808 0.9942936  0.93043858 0.94969413]\n",
      "Training Epoch 124/300, Loss: 0.3178, Accuracy: 0.8420, F1: 0.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93865365 0.83815029 0.75649351 0.         0.         0.\n",
      " 0.         0.         0.         0.74846626 0.70437018 0.3630137\n",
      " 0.39238653 0.23300971 0.         0.70613108 0.77871148 0.85528455\n",
      " 0.76842105 0.51260504 0.70979979 0.4021164  0.59310345 0.\n",
      " 0.         0.30078125 0.33175355 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 124/300, Loss: 0.2579, Accuracy: 0.8736, F1: 0.4644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92264283 0.59169732 0.58936224 0.08597285 0.08810573 0.02173913\n",
      " 0.03349282 0.03686636 0.03966006 0.62672448 0.59972106 0.26404494\n",
      " 0.33987554 0.21340273 0.06179775 0.48235782 0.60983482 0.69674888\n",
      " 0.6637037  0.556691   0.77158166 0.38632987 0.58231437 0.10774411\n",
      " 0.13636364 0.22996058 0.24044865 0.99523869 0.93569513 0.9522507 ]\n",
      "Training Epoch 125/300, Loss: 0.3126, Accuracy: 0.8460, F1: 0.4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92628022 0.82978723 0.76304024 0.         0.         0.\n",
      " 0.         0.         0.         0.74633124 0.72527473 0.3862069\n",
      " 0.44087591 0.28169014 0.03571429 0.68831169 0.73735409 0.83333333\n",
      " 0.74642857 0.65454545 0.77699229 0.50434783 0.67393675 0.\n",
      " 0.         0.27165354 0.2720403  0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 125/300, Loss: 0.2623, Accuracy: 0.8757, F1: 0.4764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92093236 0.5947644  0.59365709 0.05454545 0.10547667 0.\n",
      " 0.         0.02277904 0.03498542 0.60088602 0.60483871 0.25279642\n",
      " 0.29184126 0.21618123 0.0518732  0.46712803 0.59885894 0.70332692\n",
      " 0.66218164 0.54227681 0.77396162 0.38801498 0.57669146 0.11486486\n",
      " 0.13680782 0.23195034 0.24190801 0.99448483 0.93250998 0.95229587]\n",
      "Training Epoch 126/300, Loss: 0.3174, Accuracy: 0.8432, F1: 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93178667 0.84946237 0.72919419 0.         0.         0.04444444\n",
      " 0.13483146 0.         0.         0.76706827 0.73712737 0.42406877\n",
      " 0.44919786 0.24271845 0.         0.64253394 0.69400631 0.85106383\n",
      " 0.75514019 0.65507246 0.8279153  0.5        0.66809882 0.\n",
      " 0.         0.25498008 0.22279793 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 126/300, Loss: 0.2535, Accuracy: 0.8786, F1: 0.4793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92068085 0.61538462 0.59737587 0.09480813 0.10690423 0.\n",
      " 0.02953586 0.06852248 0.06217617 0.59450727 0.61860258 0.24269663\n",
      " 0.33040589 0.20645161 0.06340058 0.47487437 0.6078208  0.69471947\n",
      " 0.66773986 0.55598086 0.77169625 0.37414449 0.57941229 0.10365135\n",
      " 0.14234875 0.2273752  0.21698113 0.99404202 0.93000624 0.94847317]\n",
      "Training Epoch 127/300, Loss: 0.3150, Accuracy: 0.8431, F1: 0.4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93778672 0.85142857 0.75625    0.         0.         0.\n",
      " 0.         0.         0.         0.76033058 0.70408163 0.42331288\n",
      " 0.46209386 0.24038462 0.         0.66964286 0.70746888 0.8534202\n",
      " 0.76760563 0.62068966 0.80554205 0.47       0.68146214 0.\n",
      " 0.         0.33333333 0.35267857 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 127/300, Loss: 0.2515, Accuracy: 0.8824, F1: 0.4799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92192198 0.60445827 0.60720585 0.07142857 0.10154525 0.04152249\n",
      " 0.05309735 0.06736842 0.10632911 0.59838057 0.60368664 0.27272727\n",
      " 0.34123686 0.21155094 0.07446809 0.46949153 0.62224843 0.70051588\n",
      " 0.66537405 0.56425121 0.78765322 0.39082161 0.58346667 0.09261301\n",
      " 0.11815252 0.244375   0.26377187 0.99372883 0.93157862 0.94929728]\n",
      "Training Epoch 128/300, Loss: 0.3145, Accuracy: 0.8451, F1: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94217362 0.85795455 0.75454545 0.         0.         0.\n",
      " 0.         0.         0.         0.77709611 0.7099768  0.45402299\n",
      " 0.4501992  0.21674877 0.         0.68510638 0.78070175 0.86178862\n",
      " 0.78031634 0.65775401 0.84006293 0.45833333 0.62745098 0.01724138\n",
      " 0.01801802 0.41033435 0.41773963 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 128/300, Loss: 0.2434, Accuracy: 0.8837, F1: 0.4905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92399521 0.57596612 0.59767742 0.08237986 0.10714286 0.03448276\n",
      " 0.03181818 0.03174603 0.02873563 0.59878788 0.61980831 0.31113598\n",
      " 0.36917825 0.22730242 0.06853583 0.47189097 0.61631538 0.69510528\n",
      " 0.67416442 0.54226021 0.77474836 0.38467433 0.56904977 0.11111111\n",
      " 0.13870246 0.23476005 0.23412969 0.99473486 0.93232708 0.95119776]\n",
      "Training Epoch 129/300, Loss: 0.3088, Accuracy: 0.8467, F1: 0.4311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94287766 0.82687339 0.73684211 0.         0.         0.08163265\n",
      " 0.16793893 0.         0.         0.78557114 0.6025878  0.4109589\n",
      " 0.47938144 0.30555556 0.03571429 0.69491525 0.78283713 0.85024155\n",
      " 0.7708502  0.68208092 0.83920188 0.46931408 0.55303584 0.08130081\n",
      " 0.128      0.38404727 0.38761777 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 129/300, Loss: 0.2435, Accuracy: 0.8803, F1: 0.4999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92286972 0.60307366 0.59585492 0.08035714 0.09958506 0.03610108\n",
      " 0.04017857 0.0475162  0.09066667 0.6181672  0.60513282 0.27513812\n",
      " 0.33080499 0.19960861 0.06760563 0.48368201 0.61704503 0.70581778\n",
      " 0.68033854 0.56229117 0.77875934 0.39479725 0.57724771 0.11009174\n",
      " 0.10998878 0.21938441 0.21396001 0.99586829 0.93513783 0.95196714]\n",
      "Training Epoch 130/300, Loss: 0.3103, Accuracy: 0.8468, F1: 0.4316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94197904 0.84408602 0.73435327 0.         0.         0.125\n",
      " 0.32075472 0.         0.         0.7755102  0.69711538 0.44099379\n",
      " 0.47276941 0.26341463 0.03571429 0.7008547  0.78661844 0.8544\n",
      " 0.77265501 0.65633075 0.82997988 0.48372093 0.69178082 0.\n",
      " 0.         0.37802908 0.39579685 0.99964677 0.99964677 0.99929428]\n",
      "Validation Epoch 130/300, Loss: 0.2412, Accuracy: 0.8865, F1: 0.5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project='NLP_AS2-Q3-P2', name='W2V-oo-3', config={'epoch': 130, 'batch_size': batch_size})\n",
    "\n",
    "# Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / sum(sen_lengths)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "\n",
    "# WandB Config\n",
    "config = wandb.config\n",
    "\n",
    "# Watch the model\n",
    "wandb.watch(model)\n",
    "\n",
    "for epoch in range(config.epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    correct_predictions_train = 0\n",
    "    total_sentences_train = 0\n",
    "    predictions_q = []\n",
    "    traget_q = []\n",
    "\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss = torch.sum(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print('loss ',loss)\n",
    "        # Accumulate loss for the epoch\n",
    "        total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "        # Prediction\n",
    "        predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "        temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "#         print(temp_pred)\n",
    "#         print(temp_trag)\n",
    "#         print(\"$$$$\")\n",
    "        predictions_q.extend(temp_pred)\n",
    "        traget_q.extend(temp_trag)\n",
    "\n",
    "        # Update total sentences count\n",
    "        # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for training\n",
    "    average_loss_train = total_loss_train / len(dataloader)\n",
    "    accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "    f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "    print(f1_score(traget_q, predictions_q, average=None))\n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Train Loss': average_loss_train, 'Train Accuracy': accuracy_train, 'Train F1': f1_Score}, step=epoch)\n",
    "    print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    correct_predictions_val = 0\n",
    "    total_sentences_val = 0\n",
    "    predictions_p = []\n",
    "    traget_p = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "            sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "            total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "            # Prediction\n",
    "            predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "            correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            predictions_p.extend(temp_pred)\n",
    "            traget_p.extend(temp_trag)\n",
    "\n",
    "            # Update total sentences count\n",
    "            # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for validation\n",
    "    average_loss_val = total_loss_val / len(dataloader_val)\n",
    "    accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "    f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "    print(f1_score(traget_p, predictions_p, average=None))\n",
    "    \n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Validation Loss': average_loss_val, 'Validation Accuracy': accuracy_val, 'Validation F1': f1_Score}, step=epoch)\n",
    "    print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len([0.95128599,0.20926244,0.13918377 ,   0.    ,              0.    ,             0.       ,             0.     ,         0.      ,   0.   ,        0.99964677 ,     1.        ]))\n",
    "# print(len({'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "#     # Print cumulative value counts after each batch\n",
    "#     print(\"Cumulative Value Counts:\")\n",
    "#     print(cumulative_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Mapping from numeric values to labels\n",
    "# numeric_to_labels = {\n",
    "#     0: 'O', 1: 'B_COURT', 2: 'I_COURT', 3: 'B_PETITIONER', 4: 'I_PETITIONER',\n",
    "#     5: 'B_RESPONDENT', 6: 'I_RESPONDENT', 7: 'B_JUDGE', 8: 'I_JUDGE',\n",
    "#     9: 'B_LAWYER', 10: 'I_LAWYER', 11: 'B_DATE', 12: 'I_DATE',\n",
    "#     13: 'B_ORG', 14: 'I_ORG', 15: 'B_GPE', 16: 'I_GPE',\n",
    "#     17: 'B_STATUTE', 18: 'I_STATUTE', 19: 'B_PROVISION', 20: 'I_PROVISION',\n",
    "#     21: 'B_PRECEDENT', 22: 'I_PRECEDENT', 23: 'B_CASE_NUMBER', 24: 'I_CASE_NUMBER',\n",
    "#     25: 'B_WITNESS', 26: 'I_WITNESS', 27: 'B_OTHER_PERSON', 28: 'I_OTHER_PERSON',\n",
    "#     29: '<START>', 30: '<STOP>', 31: '<PAD>'\n",
    "# }\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "# # Convert numeric values to labels in the cumulative counts\n",
    "# cumulative_counts_labels = {numeric_to_labels[key]: value for key, value in cumulative_counts.items()}\n",
    "\n",
    "# # Remove <PAD> from the counts\n",
    "# cumulative_counts_labels.pop('<PAD>', None)\n",
    "# cumulative_counts_labels.pop('O', None)\n",
    "# # Plot the final cumulative counts with labels (excluding <PAD>) and add count on top of each bar\n",
    "# labels, values = zip(*cumulative_counts_labels.items())\n",
    "# plt.bar(labels, values)\n",
    "# plt.xlabel('Label')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Final Cumulative Value Counts (Excluding <PAD>)')\n",
    "# plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "\n",
    "# # Add count on top of each bar\n",
    "# for label, value in zip(labels, values):\n",
    "#     plt.text(label, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn import metrics\n",
    "# import numpy as np\n",
    "\n",
    "# # Example\n",
    "# cm = confusion_matrix(traget_p, predictions_p, labels=range(12))\n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# # Plot confusion matrix with heat map\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm, annot=True, cmap=\"Blues\",)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(traget_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# # Plot confusion matrix using imshow\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# # sns.set(font_scale=1.2)\n",
    "# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# plt.title('Normalized Confusion Matrix')\n",
    "# plt.colorbar()\n",
    "\n",
    "# classes = range(13)\n",
    "# tick_marks = np.arange(len(classes))\n",
    "# plt.xticks(tick_marks, classes, rotation=45)\n",
    "# plt.yticks(tick_marks, classes)\n",
    "\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(29),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jsluZV6ArICu"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Function to calculate accuracy\n",
    "# import torch\n",
    "\n",
    "# def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         acc += torch.sum(prex == trex)\n",
    "\n",
    "#     # Move the division outside the loop to calculate the average accuracy\n",
    "#     acc = acc.float() / sum(sen_lengths)\n",
    "#     # print(acc)\n",
    "#     return acc\n",
    "\n",
    "# def aggregater(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "#     aggr_pred = []\n",
    "#     aggr_targ = []\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         aggr_pred.extend(prex)\n",
    "#         aggr_targ.extend(trex)\n",
    "#     return aggr_pred,aggr_targ\n",
    "\n",
    "\n",
    "# for epoch in range(300):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss_train = 0\n",
    "#     correct_predictions_train = 0\n",
    "#     total_sentences_train = 0\n",
    "#     predictions_q = []\n",
    "#     traget_q = []\n",
    "\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print('loss ',loss)\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "#         # Prediction\n",
    "#         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "#         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         predictions_q.extend(temp_pred)\n",
    "#         traget_q.extend(temp_trag)\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for training\n",
    "\n",
    "#     average_loss_train = total_loss_train / len(dataloader)\n",
    "#     accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "#     f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "#     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     total_loss_val = 0\n",
    "#     correct_predictions_val = 0\n",
    "#     total_sentences_val = 0\n",
    "#     predictions_p = []\n",
    "#     traget_p = []\n",
    "#     with torch.no_grad():\n",
    "#         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "#             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "#             total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "#             # Prediction\n",
    "#             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "#             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "\n",
    "#             temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "#             predictions_p.extend(temp_pred)\n",
    "#             traget_p.extend(temp_trag)\n",
    "\n",
    "#             # Update total sentences count\n",
    "#             # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for validation\n",
    "#     average_loss_val = total_loss_val / len(dataloader_val)\n",
    "#     accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "#     f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "#     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "\n",
    "#     print()\n",
    "\n",
    "# # # Training and validation loop\n",
    "# # for epoch in range(300):\n",
    "# #     # Training\n",
    "# #     model.train()\n",
    "# #     total_loss_train = 0\n",
    "# #     correct_predictions_train = 0\n",
    "# #     total_sentences_train = 0\n",
    "\n",
    "# #     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #         model.zero_grad()\n",
    "\n",
    "# #         # Forward pass\n",
    "# #         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "# #         # Backward pass and optimization\n",
    "# #         loss = torch.sum(loss)\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "\n",
    "# #         # Accumulate loss for the epoch\n",
    "# #         total_loss_train += loss.item()\n",
    "\n",
    "# #         # Prediction\n",
    "# #         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #         print()\n",
    "# #         # print(len(predictions_train[0]),'predi_len')\n",
    "# #         # print(sen_lengths[0],'sen_len')\n",
    "# #         # print(targets[0][:sen_lengths[0]].shape,'targets_len')\n",
    "# #         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "# #         # Update total sentences count\n",
    "# #         total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for training\n",
    "# #     average_loss_train = total_loss_train / total_sentences_train\n",
    "# #     accuracy_train = correct_predictions_train / len(dataloader)\n",
    "\n",
    "# #     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}')\n",
    "\n",
    "# #     # Validation\n",
    "# #     model.eval()\n",
    "# #     total_loss_val = 0\n",
    "# #     correct_predictions_val = 0\n",
    "# #     total_sentences_val = 0\n",
    "\n",
    "# #     with torch.no_grad():\n",
    "# #         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #             # Forward pass\n",
    "# #             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "# #             total_loss_val += torch.sum(loss_val).item()\n",
    "\n",
    "# #             # Prediction\n",
    "# #             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "# #             # Update total sentences count\n",
    "# #             total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for validation\n",
    "# #     average_loss_val = total_loss_val / total_sentences_val\n",
    "# #     accuracy_val = correct_predictions_val / len(dataloader_val)\n",
    "\n",
    "# #     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wQB_sic2fKxK",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: pytorch save model code\n",
    "\n",
    "torch.save(model.state_dict(), 't1_model4_word2vec.pt')\n",
    "\n",
    "# Save the model to W&B\n",
    "wandb.save(\"t1_model4_word2vec.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMCRF(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): LSTM(300, 256, bidirectional=True)\n",
       "  (hidden2emit_score): Linear(in_features=512, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "# import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe\n",
    "# import fasttext\n",
    "import numpy as np\n",
    "#import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "            ft = fasttext.load_model('cc.en.300.bin')\n",
    "            return fasttext.load_model('cc.en.300.bin')  # Adjust the path based on your downloaded model\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(sentiment_dataset.embedding_model['a'].shape[0]) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / (sum(sen_lengths)+10)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n",
    "\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NI0fUN85rWNj"
   },
   "outputs": [],
   "source": [
    "model_state_dict = torch.load('t1_model4_word2vec.pt')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "json_path = 'NER_test.json'\n",
    "embedding_type = 'word2vec'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "sentiment_dataset =sentiment_dataset_test\n",
    "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
    "batch_size  = 512\n",
    "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LtLXbDKMZ1bG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9282\n",
      "Test F1:  0.4691779879215485\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_sentences_val = 0\n",
    "predictions_r = []\n",
    "traget_r = []\n",
    "epoch=1\n",
    "device='cuda'\n",
    "with torch.no_grad():\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        # Prediction\n",
    "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "        predictions_r.extend(temp_pred)\n",
    "        traget_r.extend(temp_trag)\n",
    "\n",
    "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
    "print()\n",
    "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
    "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6O3vYN9J-BBQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▂▄▄▃▄▄▅▄▅▆▆▅▅▆▆▅▆▇▆▇▇▇▇▇▇██████████████</td></tr><tr><td>Train F1</td><td>▁▁▂▂▂▂▂▃▃▄▄▄▄▄▄▅▄▅▅▅▆▆▇▆▅▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▃▃▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▄▄▅▅▁▄▃▅▅▆▆▆▆▄▆▆▆▄▆▇▇▇▇▇▆█████▇█████████</td></tr><tr><td>Validation F1</td><td>▁▁▂▂▂▂▂▃▂▄▄▄▄▄▄▄▅▅▅▆▇▆▇▇▅▇▇▇▇▇▇▇▇█▇███▇█</td></tr><tr><td>Validation Loss</td><td>█▄▃▃▄▃▂▂▄▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.84675</td></tr><tr><td>Train F1</td><td>0.43163</td></tr><tr><td>Train Loss</td><td>0.3103</td></tr><tr><td>Validation Accuracy</td><td>0.88647</td></tr><tr><td>Validation F1</td><td>0.50668</td></tr><tr><td>Validation Loss</td><td>0.24124</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">W2V-oo-3</strong> at: <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/zu6icu5u' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/zu6icu5u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240309_182441-zu6icu5u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0befd16ce747402b8fd074f82ac58bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "126562022a634f218a533eb2d0cb68ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e627c3c18f7453d843197124428d4e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dab3d6fa9be463b81add125fc796b1b",
      "placeholder": "​",
      "style": "IPY_MODEL_f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "value": "0.013 MB of 0.013 MB uploaded\r"
     }
    },
    "5c0c4e0669724ef0a85788b9e1d372b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dab3d6fa9be463b81add125fc796b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a41f20afb91441ebb9d824625a4280e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0befd16ce747402b8fd074f82ac58bef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c0c4e0669724ef0a85788b9e1d372b4",
      "value": 1
     }
    },
    "f97c3e9cd95c4f97a253dda0a8f9b9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fed62b3a309a402dba270a79ae613fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e627c3c18f7453d843197124428d4e3",
       "IPY_MODEL_a41f20afb91441ebb9d824625a4280e1"
      ],
      "layout": "IPY_MODEL_126562022a634f218a533eb2d0cb68ce"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
