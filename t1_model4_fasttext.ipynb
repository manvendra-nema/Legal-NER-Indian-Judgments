{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTExoSN2ShWl",
    "outputId": "ed7eb4df-8c10-442d-cd12-f17da071a3d8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# for i in [\"TRAIN\", \"TEST\"]:\n",
    "#     with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#         raw_data = json.load(json_file)\n",
    "\n",
    "#     # Convert to BILOU format\n",
    "#     bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#     if i == \"TRAIN\":\n",
    "#         # Extract indices from bilou_data\n",
    "#         indices = list(bilou_data.keys())\n",
    "\n",
    "#         # Calculate the number of samples for training\n",
    "#         total_samples = len(indices)\n",
    "#         train_size = int(0.85 * total_samples)\n",
    "\n",
    "#         # Set a fixed seed for reproducibility\n",
    "#         np.random.seed(42)\n",
    "\n",
    "#         # Shuffle the indices\n",
    "#         np.random.shuffle(indices)\n",
    "\n",
    "#         # Split indices into training and validation sets\n",
    "#         train_indices = indices[:train_size]\n",
    "#         val_indices = indices[train_size:]\n",
    "\n",
    "#         # Create training and validation datasets in BILOU format with reset indices\n",
    "#         train_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(train_indices)\n",
    "#         }\n",
    "#         val_bilou_data = {\n",
    "#             new_idx: {\"text\": bilou_data[idx][\"text\"], \"labels\": bilou_data[idx][\"labels\"]}\n",
    "#             for new_idx, idx in enumerate(val_indices)\n",
    "#         }\n",
    "\n",
    "#         # Save the output to JSON files for training\n",
    "#         with open(f'bilou_data_TRAIN.json', 'w') as json_file:\n",
    "#             json.dump(train_bilou_data, json_file, indent=2)\n",
    "\n",
    "#         with open(f'bilou_data_VAL.json', 'w') as json_file:\n",
    "#             json.dump(val_bilou_data, json_file, indent=2)\n",
    "#     elif i == \"TEST\":\n",
    "#         # Save the output to a JSON file for testing\n",
    "#         with open(f'bilou_data_TEST.json', 'w') as json_file:\n",
    "#             json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1JXz9D9SEdxy"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "            \n",
    "            \n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import re\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Lowercasing\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # Remove special characters and escape sequences\n",
    "#     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     # Tokenize the text and lemmatize each word\n",
    "#     words = nltk.word_tokenize(text)\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "#     return ' '.join(lemmatized_words)\n",
    "\n",
    "# def convert_to_bilou_format(data):\n",
    "#     bilou_data = {}\n",
    "\n",
    "#     for idx, case in enumerate(data):\n",
    "#         case_id = case[\"id\"]\n",
    "#         annotations = case[\"annotations\"][0][\"result\"]\n",
    "\n",
    "#         text = case[\"data\"][\"text\"]\n",
    "#         text = preprocess_text(text)  # Apply lowercasing and remove special characters\n",
    "#         text = lemmatize_text(text)   # Apply lemmatization\n",
    "\n",
    "#         words = text.split()\n",
    "\n",
    "#         bilou_labels = ['O'] * len(words)\n",
    "\n",
    "#         for annotation in annotations:\n",
    "#             label_start = annotation[\"value\"][\"start\"]\n",
    "#             label_end = annotation[\"value\"][\"end\"]\n",
    "#             label_text = annotation[\"value\"][\"text\"]\n",
    "#             label_type = annotation[\"value\"][\"labels\"][0]\n",
    "\n",
    "#             start_idx = None\n",
    "#             end_idx = None\n",
    "\n",
    "#             for i, word in enumerate(words):\n",
    "#                 if label_start >= len(' '.join(words[:i + 1])):\n",
    "#                     start_idx = i\n",
    "#                 if label_end <= len(' '.join(words[:i + 1])):\n",
    "#                     end_idx = i\n",
    "#                     break\n",
    "\n",
    "#             if start_idx is not None and end_idx is not None:\n",
    "#                 for i in range(start_idx, end_idx):\n",
    "#                     if i == start_idx:\n",
    "#                         bilou_labels[i] = 'B_' + label_type\n",
    "#                     else:\n",
    "#                         bilou_labels[i] = 'I_' + label_type\n",
    "\n",
    "#         bilou_data[idx] = {\n",
    "#             \"text\": text,\n",
    "#             \"labels\": bilou_labels\n",
    "#         }\n",
    "\n",
    "#     return bilou_data\n",
    "\n",
    "# # Your JSON data\n",
    "# # Read input data from a JSON file\n",
    "# for i in [\"TRAIN\",\"TEST\"]:\n",
    "  \n",
    "#   with open(f\"D:/Downloads/NER_{i}_JUDGEMENT.json\", 'r') as json_file:\n",
    "#       raw_data = json.load(json_file)\n",
    "\n",
    "#   # Convert to BILOU format\n",
    "#   bilou_data = convert_to_bilou_format(raw_data)\n",
    "\n",
    "#   # Save the output to a JSON file\n",
    "#   with open(f'bilou_data_{i}.json', 'w') as json_file:\n",
    "#       json.dump(bilou_data, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Eym7hCkbtYO",
    "outputId": "00a8ff0b-818a-47ea-f438-005230c5afa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B_COURT', 'I_COURT', 'B_PETITIONER', 'I_PETITIONER', 'B_RESPONDENT', 'I_RESPONDENT', 'B_JUDGE', 'I_JUDGE', 'B_LAWYER', 'I_LAWYER', 'B_DATE', 'I_DATE', 'B_ORG', 'I_ORG', 'B_GPE', 'I_GPE', 'B_STATUTE', 'I_STATUTE', 'B_PROVISION', 'I_PROVISION', 'B_PRECEDENT', 'I_PRECEDENT', 'B_CASE_NUMBER', 'I_CASE_NUMBER', 'B_WITNESS', 'I_WITNESS', 'B_OTHER_PERSON', 'I_OTHER_PERSON', '<START>', '<STOP>', '<PAD>']\n",
      "{'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n"
     ]
    }
   ],
   "source": [
    "named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER', 'DATE', 'ORG', 'GPE', 'STATUTE', 'PROVISION', 'PRECEDENT', 'CASE_NUMBER', 'WITNESS', 'OTHER_PERSON']\n",
    "# named_entities = ['COURT', 'PETITIONER', 'RESPONDENT', 'JUDGE', 'LAWYER']\n",
    "\n",
    "named_entity_combinations = ['O']\n",
    "\n",
    "for entity in named_entities:\n",
    "    b_entity = \"B_\" + entity\n",
    "    i_entity = \"I_\" + entity\n",
    "    named_entity_combinations.extend([b_entity, i_entity])\n",
    "named_entity_combinations.append('<START>')\n",
    "named_entity_combinations.append('<STOP>')\n",
    "named_entity_combinations.append('<PAD>')\n",
    "print(named_entity_combinations)\n",
    "\n",
    "named_entity_encoding = {entity: idx for idx, entity in enumerate(named_entity_combinations)}\n",
    "\n",
    "print(named_entity_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lQkdf-XdEnfJ"
   },
   "outputs": [],
   "source": [
    "# !pip install fasttext\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWR6lMXiEpYS",
    "outputId": "a95c7dbc-6a41-45df-b306-2cf0a3d6a731",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            \n",
    "            return FastText(language='en')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# sentiment_dataset.embedding_model= temp.embedding_model\n",
    "# Accessing a sample from the dataset\n",
    "# sample_text_embeddings, sample_labels, mask,s_len = sentiment_dataset[0]\n",
    "# print(\"Sample Text Embeddings:\", sample_text_embeddings)\n",
    "# print(\"Sample Labels:\", sample_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sentiment_dataset)):\n",
    "#     print(sentiment_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xV1g4_jteXTp"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # Set a seed for reproducibility\n",
    "# torch.manual_seed(42)  # You can choose any seed value\n",
    "\n",
    "# total_size = len(sentiment_dataset)\n",
    "# indices = list(range(total_size))\n",
    "\n",
    "# # Define the split sizes\n",
    "# train_size = int(0.85 * total_size)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# # Use the seed for reproducibility when shuffling\n",
    "# torch.randperm(total_size)\n",
    "\n",
    "# # Split the indices\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "\n",
    "# # Create Subset datasets using the indices\n",
    "# train_dataset = torch.utils.data.Subset(sentiment_dataset, train_indices)\n",
    "# val_dataset = torch.utils.data.Subset(sentiment_dataset, val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "__2DRx7cZCHc"
   },
   "outputs": [],
   "source": [
    "# for i in dataloader:\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QOxk1a5sTXtN"
   },
   "outputs": [],
   "source": [
    "batch_size  = 512\n",
    "json_path = \"NER_train.json\"\n",
    "embedding_type = 'fasttext'\n",
    "sentiment_dataset = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "dataloader = DataLoader(sentiment_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wdA2HAHVqBrT"
   },
   "outputs": [],
   "source": [
    "json_path = \"NER_val.json\"\n",
    "sentiment_dataset_val = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_val.embedding_model = sentiment_dataset.embedding_model\n",
    "dataloader_val = DataLoader(sentiment_dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'NER_test.json'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type,load=False)\n",
    "sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7PRU5YYtEtqs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "    # def predict(self, sentences,mask, sen_lengths):\n",
    "    #     \"\"\"\n",
    "    #     Args:\n",
    "    #         sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "    #                             of the longest sentence\n",
    "    #         sen_lengths (list): sentence lengths\n",
    "    #     Returns:\n",
    "    #         tags (list[list[str]]): predicted tags for the batch\n",
    "    #     \"\"\"\n",
    "    #     batch_size = sentences.shape[0]\n",
    "    #     # w = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)\n",
    "    #     w = mask\n",
    "    #     sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "    #     # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "    #     emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "    #     tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "    #     d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "    #     for i in range(1, sen_lengths[0]):\n",
    "    #         n_unfinished = mask[:, i].sum()\n",
    "    #         d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "    #         emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "    #         new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "    #         d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "    #         max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "    #         tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "    #         d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "    #     d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "    #     _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "    #     max_idx = max_idx.tolist()\n",
    "    #     tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "    #     print(tags,sen_lengths,'((()))')\n",
    "    #     return tags\n",
    "\n",
    "    # def save(self, filepath):\n",
    "    #     params = {\n",
    "    #         'sent_vocab': self.sent_vocab,\n",
    "    #         'tag_vocab': self.tag_vocab,\n",
    "    #         'args': dict(dropout_rate=self.dropout_rate, embed_size=self.embed_size, hidden_size=self.hidden_size),\n",
    "    #         'state_dict': self.state_dict()\n",
    "    #     }\n",
    "    #     torch.save(params, filepath)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     sent_vocab = Vocab.load('./vocab/sent_vocab.json')\n",
    "#     tag_vocab = Vocab.load('./vocab/tag_vocab.json')\n",
    "#     train_data, dev_data = utils.generate_train_dev_dataset('./data/train.txt', sent_vocab, tag_vocab)\n",
    "#     device = torch.device('cpu')\n",
    "#     model = BiLSTMCRF(sent_vocab, tag_vocab)\n",
    "#     model.to(device)\n",
    "#     model.save('./model/model.pth')\n",
    "#     model = model.load('./model/model.pth', device)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "argnny6HH0Tu"
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9  # Optional: You can adjust the momentum term\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oHr2iehwItKL"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Check predictions before training\n",
    "# for epoch in range(300):\n",
    "#     total_loss = 0\n",
    "#     correct_predictions = 0\n",
    "#     total_sentences = 0\n",
    "\n",
    "#     # Wrap your dataloader with tqdm for a progress bar\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         # Move input data to GPU\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         total_sentences += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss for the epoch\n",
    "#     average_loss = total_loss / total_sentences\n",
    "\n",
    "#     # Print loss for each epoch\n",
    "#     print(f'Epoch {epoch + 1}/{300}, Loss: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8465903IIQiP",
    "outputId": "59fc2395-654e-4f03-e9f2-6d821084fef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])==torch.tensor([1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2mAtfLRzkl3",
    "outputId": "c8c91803-9f7b-4d97-8972-dec9ac4651d4"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fed62b3a309a402dba270a79ae613fec",
      "4e627c3c18f7453d843197124428d4e3",
      "a41f20afb91441ebb9d824625a4280e1",
      "126562022a634f218a533eb2d0cb68ce",
      "9dab3d6fa9be463b81add125fc796b1b",
      "f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "0befd16ce747402b8fd074f82ac58bef",
      "5c0c4e0669724ef0a85788b9e1d372b4"
     ]
    },
    "id": "5tA2FjdzzM4R",
    "outputId": "c35f5f15-59c2-4ce8-dc71-731ffef8e94f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanvendra\u001b[0m (\u001b[33miiitd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Manvendra Nema\\Notebooks\\Untitled Folder\\wandb\\run-20240310_012516-jrceellj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/jrceellj' target=\"_blank\">FTT-oo-3</a></strong> to <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/jrceellj' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/jrceellj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64903337 0.01216142 0.00769458 0.         0.00177936 0.\n",
      " 0.00184587 0.00214133 0.00562588 0.         0.         0.0049975\n",
      " 0.         0.00294985 0.01292568 0.00972053 0.         0.00777832\n",
      " 0.01073826 0.01570813 0.01008192 0.00133245 0.04753915 0.00749625\n",
      " 0.01677149 0.00477327 0.00157233 0.01586402 0.02744149 0.49531067\n",
      " 0.53678519 0.31050622]\n",
      "Training Epoch 1/300, Loss: 14.0593, Accuracy: 0.4353, F1: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84914373 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06097561 0.21518987 0.99858557 0.99858557 0.9971831 ]\n",
      "Validation Epoch 1/300, Loss: 3.7638, Accuracy: 0.7570, F1: 0.1373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79474438 0.02005013 0.03216278 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01011378\n",
      " 0.01158749 0.01006149 0.01609058 0.02087683 0.         0.00813835\n",
      " 0.00907258 0.03759398 0.02750741 0.02723735 0.12829132 0.00410678\n",
      " 0.00270088 0.00237248 0.00490196 0.01921757 0.11010682 0.81050211\n",
      " 0.78851024 0.39521932]\n",
      "Training Epoch 2/300, Loss: 4.9228, Accuracy: 0.6127, F1: 0.1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87849492 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.17670683 0.45073079 0.         0.         0.\n",
      " 0.         0.00486618 0.01226994 0.99929329 0.99858557 0.99788584]\n",
      "Validation Epoch 2/300, Loss: 1.9374, Accuracy: 0.7645, F1: 0.1506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85018495 0.04878049 0.04507789 0.01073345 0.         0.\n",
      " 0.         0.         0.         0.03910869 0.02675159 0.04640371\n",
      " 0.04466945 0.05452436 0.         0.02821487 0.04190378 0.23754789\n",
      " 0.13652649 0.06073446 0.3727085  0.         0.05586825 0.01773836\n",
      " 0.01077586 0.04041916 0.15378518 0.8306745  0.82329463 0.5672043 ]\n",
      "Training Epoch 3/300, Loss: 2.0197, Accuracy: 0.6825, F1: 0.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90519044 0.05025126 0.02824859 0.         0.         0.\n",
      " 0.         0.         0.         0.04605263 0.         0.\n",
      " 0.         0.1221374  0.         0.         0.         0.48661234\n",
      " 0.37552389 0.27609428 0.54873055 0.         0.03125    0.\n",
      " 0.         0.05069124 0.07365439 0.99964677 0.99823259 0.99823757]\n",
      "Validation Epoch 3/300, Loss: 0.8599, Accuracy: 0.7964, F1: 0.1997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87549034 0.08387563 0.0600304  0.         0.         0.\n",
      " 0.         0.         0.         0.04658385 0.00459067 0.02618884\n",
      " 0.07439698 0.04542505 0.         0.06852497 0.09240759 0.3229228\n",
      " 0.26783713 0.12692308 0.40627243 0.01343785 0.10378096 0.00531208\n",
      " 0.02316602 0.10640608 0.17531979 0.81993674 0.80637485 0.81878558]\n",
      "Training Epoch 4/300, Loss: 0.9858, Accuracy: 0.7294, F1: 0.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91798801 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06       0.         0.\n",
      " 0.         0.08791209 0.         0.10810811 0.22678397 0.44990893\n",
      " 0.3504218  0.38875878 0.60657155 0.         0.         0.\n",
      " 0.         0.11479029 0.14713896 0.99964677 0.99823259 0.99823757]\n",
      "Validation Epoch 4/300, Loss: 0.5727, Accuracy: 0.8039, F1: 0.2151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89565488 0.13350785 0.09268113 0.         0.01052632 0.\n",
      " 0.         0.         0.         0.         0.12317328 0.01108472\n",
      " 0.05614035 0.12208437 0.06171285 0.         0.08571429 0.14950166\n",
      " 0.39356284 0.34054589 0.28928766 0.58887734 0.0385439  0.2201037\n",
      " 0.00834492 0.02781641 0.17908539 0.20422788 0.91263364 0.91349099\n",
      " 0.91383572]\n",
      "Training Epoch 5/300, Loss: 0.6386, Accuracy: 0.7706, F1: 0.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92786955 0.3785489  0.28853755 0.         0.         0.\n",
      " 0.         0.         0.         0.22560976 0.         0.17624521\n",
      " 0.24971098 0.1443299  0.         0.22343324 0.36700649 0.68944099\n",
      " 0.52883895 0.41148325 0.66592625 0.0397351  0.23774146 0.\n",
      " 0.         0.31755725 0.3633157  0.99964677 0.99823259 0.99823757]\n",
      "Validation Epoch 5/300, Loss: 0.4651, Accuracy: 0.8250, F1: 0.3077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89612047 0.20425532 0.15625    0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23076923 0.03996925\n",
      " 0.06981254 0.11135748 0.07806032 0.         0.176      0.20842311\n",
      " 0.48481408 0.40656484 0.30761671 0.6103512  0.08349515 0.25237939\n",
      " 0.01974612 0.02643172 0.21346663 0.2461336  0.84086982 0.91994997\n",
      " 0.9306402 ]\n",
      "Training Epoch 6/300, Loss: 0.5510, Accuracy: 0.7748, F1: 0.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92971646 0.44047619 0.35826087 0.         0.         0.\n",
      " 0.         0.         0.         0.30267062 0.         0.07207207\n",
      " 0.08064516 0.15916955 0.         0.33604336 0.45146727 0.70628183\n",
      " 0.55968379 0.39344262 0.65815111 0.2300885  0.39218877 0.\n",
      " 0.         0.32911392 0.3800738  0.99964677 0.99823259 0.99823757]\n",
      "Validation Epoch 6/300, Loss: 0.4277, Accuracy: 0.8305, F1: 0.3259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90624961 0.24438903 0.1968625  0.         0.         0.\n",
      " 0.00537634 0.         0.         0.         0.28071834 0.16756757\n",
      " 0.0955297  0.12257406 0.07869249 0.         0.23300048 0.29029571\n",
      " 0.54945055 0.48229569 0.34482759 0.61993569 0.14793468 0.32636656\n",
      " 0.01373626 0.02359882 0.20955574 0.24580298 0.96350553 0.92144693\n",
      " 0.94020304]\n",
      "Training Epoch 7/300, Loss: 0.5124, Accuracy: 0.7948, F1: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9335997  0.45138889 0.36217304 0.         0.         0.\n",
      " 0.         0.         0.         0.35694051 0.04854369 0.06060606\n",
      " 0.05988024 0.1640625  0.         0.4086444  0.50184502 0.69860896\n",
      " 0.58074299 0.41333333 0.65445462 0.08917197 0.27101201 0.\n",
      " 0.         0.3338843  0.4        0.99964677 0.99787986 0.99823757]\n",
      "Validation Epoch 7/300, Loss: 0.3981, Accuracy: 0.8331, F1: 0.3262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90778526 0.29723225 0.2331322  0.         0.         0.\n",
      " 0.         0.         0.         0.31544256 0.25757576 0.12128419\n",
      " 0.12248187 0.09284333 0.         0.2452392  0.31555645 0.57503671\n",
      " 0.4880069  0.36227123 0.62296099 0.17841213 0.35206272 0.01874163\n",
      " 0.02578797 0.22473868 0.25100134 0.97341643 0.92565707 0.94112122]\n",
      "Training Epoch 8/300, Loss: 0.4835, Accuracy: 0.7989, F1: 0.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92282723 0.57425743 0.45833333 0.         0.         0.\n",
      " 0.         0.         0.         0.46612466 0.17040359 0.17712177\n",
      " 0.25531915 0.17333333 0.         0.43514644 0.52239835 0.74706868\n",
      " 0.59377778 0.54434251 0.72295184 0.24731183 0.53088042 0.\n",
      " 0.         0.30981067 0.3706721  0.99964677 0.99717514 0.99823757]\n",
      "Validation Epoch 8/300, Loss: 0.3859, Accuracy: 0.8451, F1: 0.3739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91004808 0.3247549  0.26929982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.42071786 0.3432085\n",
      " 0.14580941 0.16923466 0.10539216 0.         0.25794033 0.30678466\n",
      " 0.59447265 0.50365449 0.38108356 0.62598733 0.17580505 0.38761425\n",
      " 0.04865557 0.05691057 0.24929018 0.28599349 0.97489673 0.92772438\n",
      " 0.9406382 ]\n",
      "Training Epoch 9/300, Loss: 0.4631, Accuracy: 0.8033, F1: 0.3034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93937272 0.55629139 0.47801147 0.         0.         0.\n",
      " 0.         0.         0.         0.63333333 0.4965035  0.04651163\n",
      " 0.04454343 0.2310757  0.         0.5250501  0.61102832 0.76771005\n",
      " 0.63175966 0.38297872 0.61636637 0.28019324 0.46635731 0.\n",
      " 0.         0.3622291  0.40867993 0.99964677 0.99717514 0.99823757]\n",
      "Validation Epoch 9/300, Loss: 0.3561, Accuracy: 0.8424, F1: 0.3824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91393386 0.39004149 0.33198146 0.         0.00552486 0.\n",
      " 0.         0.         0.         0.         0.48267009 0.39337253\n",
      " 0.1440281  0.1969697  0.0974359  0.         0.29483146 0.37087087\n",
      " 0.61128799 0.53356342 0.41133455 0.65120864 0.21880342 0.4116783\n",
      " 0.05191595 0.04793609 0.25529412 0.27884941 0.9769392  0.92613849\n",
      " 0.94343399]\n",
      "Training Epoch 10/300, Loss: 0.4461, Accuracy: 0.8106, F1: 0.3206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94149811 0.66066066 0.58878505 0.         0.         0.\n",
      " 0.         0.         0.         0.6803653  0.62209302 0.125\n",
      " 0.13438735 0.21576763 0.         0.55066079 0.68266667 0.77093207\n",
      " 0.66410453 0.392      0.62960818 0.33333333 0.53546911 0.\n",
      " 0.         0.38438438 0.42582897 0.99964677 0.99717514 0.99823757]\n",
      "Validation Epoch 10/300, Loss: 0.3402, Accuracy: 0.8509, F1: 0.4111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91326681 0.42626728 0.36611278 0.01017812 0.01072386 0.\n",
      " 0.         0.         0.         0.         0.5276488  0.44946026\n",
      " 0.16069364 0.18459152 0.11617162 0.         0.29138475 0.37595159\n",
      " 0.63597369 0.54628999 0.3985137  0.65342557 0.24013722 0.46367561\n",
      " 0.05115713 0.05       0.27152698 0.30026281 0.97636595 0.92743495\n",
      " 0.94373161]\n",
      "Training Epoch 11/300, Loss: 0.4239, Accuracy: 0.8135, F1: 0.3320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93718636 0.7008547  0.60458453 0.         0.         0.\n",
      " 0.         0.         0.         0.69369369 0.61408451 0.22857143\n",
      " 0.27334235 0.1981982  0.         0.55378486 0.63353214 0.76923077\n",
      " 0.64608076 0.45798319 0.64255319 0.30275229 0.5106383  0.\n",
      " 0.         0.3942029  0.4120603  0.99964677 0.99717514 0.99823757]\n",
      "Validation Epoch 11/300, Loss: 0.3378, Accuracy: 0.8434, F1: 0.4189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91403365 0.46678024 0.39988861 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.54742097 0.46376812\n",
      " 0.14590348 0.2002454  0.12557227 0.         0.34098066 0.40235246\n",
      " 0.63418853 0.56798097 0.40226629 0.63719512 0.24555735 0.45993757\n",
      " 0.04878049 0.05506884 0.26235192 0.29289256 0.97762566 0.92492043\n",
      " 0.94278153]\n",
      "Training Epoch 12/300, Loss: 0.4235, Accuracy: 0.8150, F1: 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94333151 0.73837209 0.65605096 0.         0.         0.\n",
      " 0.         0.         0.         0.71304348 0.65384615 0.23272727\n",
      " 0.31222386 0.22222222 0.         0.5511811  0.6048906  0.76589147\n",
      " 0.66976025 0.56763926 0.80386524 0.3943662  0.64770241 0.\n",
      " 0.         0.3953824  0.4551495  0.99964677 0.99717514 0.99823757]\n",
      "Validation Epoch 12/300, Loss: 0.3117, Accuracy: 0.8707, F1: 0.4441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91810407 0.47816349 0.41900648 0.         0.00537634 0.\n",
      " 0.00534759 0.         0.         0.         0.54255765 0.47724006\n",
      " 0.17152859 0.20553145 0.12562189 0.00673401 0.34365186 0.44945214\n",
      " 0.65122927 0.5792734  0.44128788 0.69476338 0.27777778 0.51007723\n",
      " 0.077951   0.09080048 0.28390075 0.29743926 0.97798084 0.92309611\n",
      " 0.94246382]\n",
      "Training Epoch 13/300, Loss: 0.3936, Accuracy: 0.8248, F1: 0.3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94136592 0.76056338 0.69135802 0.         0.         0.\n",
      " 0.         0.         0.         0.71648352 0.70299728 0.27106227\n",
      " 0.36445783 0.2109375  0.         0.58205689 0.71404682 0.79865772\n",
      " 0.69328802 0.55612245 0.76714356 0.4526749  0.62570888 0.\n",
      " 0.         0.37598736 0.44567219 0.99964677 0.99858757 0.9989418 ]\n",
      "Validation Epoch 13/300, Loss: 0.3010, Accuracy: 0.8734, F1: 0.4556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92026553 0.48248588 0.42067039 0.00497512 0.00534759 0.\n",
      " 0.         0.00486618 0.00647249 0.         0.5561139  0.50891566\n",
      " 0.19908467 0.25156917 0.1414914  0.00677966 0.36493739 0.46884273\n",
      " 0.65977606 0.60733854 0.44141176 0.70169847 0.31419458 0.53393502\n",
      " 0.0917226  0.10035842 0.27875587 0.30067114 0.97758303 0.92878097\n",
      " 0.94485772]\n",
      "Training Epoch 14/300, Loss: 0.3876, Accuracy: 0.8288, F1: 0.3621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94183847 0.77053824 0.70479134 0.         0.         0.\n",
      " 0.         0.         0.         0.75471698 0.6745283  0.25454545\n",
      " 0.33087149 0.22137405 0.         0.56540084 0.7015625  0.80333333\n",
      " 0.67504488 0.56281407 0.77750124 0.47619048 0.65968586 0.03448276\n",
      " 0.03636364 0.36666667 0.43921569 0.99964677 0.99858757 0.9989418 ]\n",
      "Validation Epoch 14/300, Loss: 0.2943, Accuracy: 0.8748, F1: 0.4583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91969032 0.53746479 0.4894327  0.00505051 0.00543478 0.\n",
      " 0.         0.00478469 0.00632911 0.         0.57695473 0.54145854\n",
      " 0.21070615 0.27054108 0.15197957 0.         0.38779956 0.48703668\n",
      " 0.66118514 0.59305462 0.45889457 0.69042659 0.29228243 0.52732871\n",
      " 0.08628319 0.0915493  0.28596594 0.3073302  0.97951937 0.92755974\n",
      " 0.94686391]\n",
      "Training Epoch 15/300, Loss: 0.3800, Accuracy: 0.8293, F1: 0.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94315709 0.77653631 0.70889894 0.         0.         0.\n",
      " 0.         0.         0.         0.72727273 0.70415648 0.25925926\n",
      " 0.353125   0.21940928 0.         0.57209302 0.74275023 0.79740681\n",
      " 0.69624573 0.48447205 0.67627084 0.4549763  0.61796407 0.\n",
      " 0.         0.34662045 0.40657084 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 15/300, Loss: 0.2931, Accuracy: 0.8672, F1: 0.4495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92170452 0.54986226 0.52642819 0.01456311 0.02072539 0.\n",
      " 0.         0.00480769 0.         0.         0.57941653 0.56545961\n",
      " 0.22234763 0.29407276 0.14984127 0.01290323 0.41202476 0.52388535\n",
      " 0.68185654 0.60957343 0.47537879 0.71936359 0.32369942 0.55966451\n",
      " 0.08656036 0.0958231  0.30318993 0.32551997 0.97860453 0.93288423\n",
      " 0.94646656]\n",
      "Training Epoch 16/300, Loss: 0.3710, Accuracy: 0.8357, F1: 0.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94230451 0.8189415  0.74164134 0.         0.         0.\n",
      " 0.         0.         0.         0.71929825 0.71584699 0.25482625\n",
      " 0.36867863 0.22764228 0.         0.59913793 0.75456053 0.80696203\n",
      " 0.70815812 0.53240741 0.73593276 0.48372093 0.67764706 0.\n",
      " 0.         0.36453202 0.41538462 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 16/300, Loss: 0.2832, Accuracy: 0.8757, F1: 0.4622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92101335 0.54326396 0.51710207 0.01449275 0.02025316 0.\n",
      " 0.         0.01398601 0.01226994 0.         0.56559767 0.56319077\n",
      " 0.21436588 0.27937916 0.15492958 0.02013423 0.39009288 0.5066251\n",
      " 0.66096379 0.60525429 0.5016982  0.72143496 0.33414044 0.53586895\n",
      " 0.06185567 0.06157635 0.29099443 0.30738655 0.97963069 0.92135953\n",
      " 0.93782596]\n",
      "Training Epoch 17/300, Loss: 0.3646, Accuracy: 0.8332, F1: 0.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9403378  0.76712329 0.71064468 0.         0.         0.\n",
      " 0.         0.         0.         0.69146608 0.72043011 0.28244275\n",
      " 0.37741935 0.24       0.         0.59023355 0.74553191 0.81848185\n",
      " 0.72661217 0.57219251 0.77884615 0.45283019 0.70108043 0.0173913\n",
      " 0.01834862 0.37681159 0.44897959 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 17/300, Loss: 0.2796, Accuracy: 0.8802, F1: 0.4658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92104006 0.54387866 0.52389754 0.02898551 0.02597403 0.\n",
      " 0.         0.0045977  0.00615385 0.         0.58612245 0.60531136\n",
      " 0.2484472  0.3100469  0.15681394 0.05095541 0.40161002 0.51275771\n",
      " 0.67542107 0.60490921 0.4738084  0.69854335 0.34206219 0.55338346\n",
      " 0.08026756 0.0804878  0.30436055 0.33127639 0.98061328 0.92529309\n",
      " 0.94283864]\n",
      "Training Epoch 18/300, Loss: 0.3607, Accuracy: 0.8334, F1: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94862054 0.83557951 0.75801749 0.         0.         0.\n",
      " 0.         0.         0.         0.7601626  0.73015873 0.44198895\n",
      " 0.50592885 0.2704918  0.         0.58468677 0.7270936  0.82926829\n",
      " 0.7469459  0.58247423 0.79271992 0.48341232 0.69902913 0.\n",
      " 0.         0.39484979 0.47839506 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 18/300, Loss: 0.2704, Accuracy: 0.8859, F1: 0.4856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92351343 0.57450242 0.55490716 0.03800475 0.03571429 0.\n",
      " 0.         0.02309469 0.01829268 0.         0.58919804 0.59388235\n",
      " 0.26563365 0.34137668 0.14267016 0.03289474 0.43665059 0.56258679\n",
      " 0.68141097 0.62742561 0.47799337 0.72340229 0.36879433 0.57286059\n",
      " 0.14727855 0.16       0.30281481 0.32066667 0.98072045 0.92528377\n",
      " 0.94349184]\n",
      "Training Epoch 19/300, Loss: 0.3494, Accuracy: 0.8395, F1: 0.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94653207 0.83965015 0.76328502 0.         0.         0.\n",
      " 0.         0.         0.         0.77642276 0.73316708 0.39498433\n",
      " 0.48292683 0.27234043 0.         0.63383298 0.76271186 0.81329114\n",
      " 0.71494607 0.53363229 0.72595201 0.46413502 0.62873674 0.05084746\n",
      " 0.05357143 0.36148649 0.44874275 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 19/300, Loss: 0.2698, Accuracy: 0.8766, F1: 0.4800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92384896 0.55206074 0.55252498 0.02369668 0.01526718 0.\n",
      " 0.         0.01864802 0.01863354 0.         0.58756137 0.58082192\n",
      " 0.26485014 0.356623   0.18181818 0.03703704 0.4359085  0.569049\n",
      " 0.68719977 0.64103828 0.50403417 0.74050159 0.37198068 0.60883097\n",
      " 0.1207076  0.13762486 0.3087886  0.34399478 0.98040956 0.92572498\n",
      " 0.94444444]\n",
      "Training Epoch 20/300, Loss: 0.3466, Accuracy: 0.8421, F1: 0.4011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94737591 0.84615385 0.77380952 0.         0.         0.\n",
      " 0.         0.         0.         0.78629032 0.73       0.42902208\n",
      " 0.52217997 0.29268293 0.         0.62251656 0.77384196 0.83174603\n",
      " 0.75238095 0.59473684 0.81095176 0.4813278  0.69908815 0.03418803\n",
      " 0.03603604 0.40245776 0.49584027 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 20/300, Loss: 0.2591, Accuracy: 0.8895, F1: 0.4954\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92389179 0.58319957 0.56266117 0.03301887 0.03508772 0.01403509\n",
      " 0.01025641 0.01860465 0.01230769 0.         0.59037606 0.58796509\n",
      " 0.27510917 0.35148042 0.21306278 0.06289308 0.45642796 0.57436096\n",
      " 0.68292683 0.63590413 0.49229332 0.71672515 0.38103025 0.60320525\n",
      " 0.12556054 0.12440191 0.30898708 0.3452381  0.98001142 0.92902582\n",
      " 0.94609786]\n",
      "Training Epoch 21/300, Loss: 0.3441, Accuracy: 0.8413, F1: 0.4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95032658 0.848      0.78571429 0.         0.         0.\n",
      " 0.         0.         0.         0.78367347 0.73815461 0.43287671\n",
      " 0.48328558 0.27966102 0.         0.63510848 0.73131014 0.81318681\n",
      " 0.74151436 0.60606061 0.81203008 0.51694915 0.718      0.05042017\n",
      " 0.05309735 0.39032258 0.49029982 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 21/300, Loss: 0.2593, Accuracy: 0.8871, F1: 0.4953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92450013 0.58137045 0.59173127 0.02836879 0.02525253 0.\n",
      " 0.         0.01826484 0.01796407 0.5995106  0.61594867 0.28176796\n",
      " 0.35294118 0.19354839 0.03030303 0.43310463 0.58631922 0.69154651\n",
      " 0.63918206 0.49808795 0.7186259  0.39556962 0.61705717 0.15718718\n",
      " 0.17660044 0.30989203 0.35654074 0.98168684 0.93046461 0.94953693]\n",
      "Training Epoch 22/300, Loss: 0.3419, Accuracy: 0.8427, F1: 0.4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95222707 0.85872576 0.81871345 0.         0.         0.\n",
      " 0.         0.         0.         0.78486056 0.71980676 0.47849462\n",
      " 0.53435115 0.30088496 0.         0.6557377  0.76746097 0.83797054\n",
      " 0.76155938 0.61182519 0.81297516 0.51383399 0.67145422 0.0173913\n",
      " 0.01834862 0.45234708 0.49712644 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 22/300, Loss: 0.2537, Accuracy: 0.8906, F1: 0.5021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92733653 0.59375    0.59324155 0.04977376 0.03365385 0.01408451\n",
      " 0.02040816 0.06021505 0.07323944 0.         0.60678643 0.59755545\n",
      " 0.29855716 0.39862205 0.17877814 0.04692082 0.43722944 0.5905056\n",
      " 0.69277778 0.66612642 0.54232425 0.75837843 0.43243243 0.62936019\n",
      " 0.11725664 0.12750885 0.32212389 0.35568146 0.98188956 0.92951597\n",
      " 0.94761144]\n",
      "Training Epoch 23/300, Loss: 0.3296, Accuracy: 0.8485, F1: 0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95183464 0.86350975 0.79878971 0.         0.         0.\n",
      " 0.         0.         0.         0.78823529 0.72093023 0.45502646\n",
      " 0.51520913 0.28440367 0.         0.66943867 0.78688525 0.84565916\n",
      " 0.77581864 0.59079903 0.78386714 0.51476793 0.68341709 0.03418803\n",
      " 0.03603604 0.4610951  0.50075873 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 23/300, Loss: 0.2498, Accuracy: 0.8887, F1: 0.5020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92663656 0.62829989 0.64207221 0.03240741 0.03491272 0.00680272\n",
      " 0.00496278 0.03603604 0.02431611 0.60876494 0.61803353 0.28415895\n",
      " 0.37364798 0.19808307 0.04334365 0.44989059 0.60224632 0.69921437\n",
      " 0.65231788 0.54232425 0.75866692 0.40440598 0.62523901 0.11751904\n",
      " 0.12383178 0.33767773 0.3716927  0.98124683 0.93159568 0.94776119]\n",
      "Training Epoch 24/300, Loss: 0.3288, Accuracy: 0.8498, F1: 0.4336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95376251 0.8603352  0.8        0.         0.         0.\n",
      " 0.         0.         0.         0.79051383 0.73039216 0.4305949\n",
      " 0.52437703 0.30434783 0.         0.68172485 0.80656304 0.86084142\n",
      " 0.80902778 0.57957245 0.77160206 0.50643777 0.71834061 0.09836066\n",
      " 0.10344828 0.45655376 0.50868878 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 24/300, Loss: 0.2445, Accuracy: 0.8927, F1: 0.5098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92940863 0.6153056  0.63113535 0.04867257 0.04205607 0.02649007\n",
      " 0.0243309  0.0311804  0.02915452 0.61612515 0.61118947 0.29749304\n",
      " 0.38591195 0.20864198 0.07162534 0.48184537 0.61305182 0.71376507\n",
      " 0.66161949 0.54954524 0.76811315 0.39269406 0.60412827 0.11479029\n",
      " 0.12933025 0.32335329 0.36041733 0.98035488 0.92983222 0.94672034]\n",
      "Training Epoch 25/300, Loss: 0.3228, Accuracy: 0.8517, F1: 0.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94328679 0.83835616 0.7537092  0.         0.         0.\n",
      " 0.         0.         0.         0.77137177 0.72636816 0.46666667\n",
      " 0.53249476 0.31128405 0.         0.60411899 0.76728335 0.85855263\n",
      " 0.7831656  0.60773481 0.8098434  0.50717703 0.73333333 0.01724138\n",
      " 0.01818182 0.38499184 0.46998285 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 25/300, Loss: 0.2528, Accuracy: 0.8891, F1: 0.4968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92853631 0.61266874 0.59640103 0.04385965 0.02810304 0.02730375\n",
      " 0.02469136 0.04415011 0.03468208 0.60374288 0.61695229 0.33494884\n",
      " 0.40376266 0.20229008 0.06413994 0.47219846 0.60007728 0.71278942\n",
      " 0.66505869 0.53879518 0.75801999 0.39781591 0.63447501 0.13080169\n",
      " 0.13033708 0.32129964 0.35312697 0.98298222 0.93094629 0.94974456]\n",
      "Training Epoch 26/300, Loss: 0.3197, Accuracy: 0.8506, F1: 0.4382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94294252 0.83908046 0.77971474 0.         0.         0.\n",
      " 0.         0.         0.         0.72651357 0.73878628 0.41216216\n",
      " 0.49157303 0.31578947 0.         0.64908722 0.80737018 0.83410853\n",
      " 0.79159664 0.60989011 0.81473276 0.52914798 0.7545045  0.\n",
      " 0.         0.35852373 0.44399185 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 26/300, Loss: 0.2515, Accuracy: 0.8910, F1: 0.4946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92928753 0.62355415 0.62061856 0.07912088 0.0760095  0.02061856\n",
      " 0.02512563 0.05829596 0.05309735 0.63224782 0.64573991 0.31510558\n",
      " 0.37521347 0.23471279 0.06469003 0.49979106 0.62888552 0.71118531\n",
      " 0.67987756 0.54622642 0.74527231 0.4351145  0.63534676 0.1205074\n",
      " 0.13111111 0.34272161 0.38516672 0.9827248  0.93449782 0.95190476]\n",
      "Training Epoch 27/300, Loss: 0.3187, Accuracy: 0.8522, F1: 0.4495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94419299 0.82816901 0.76407915 0.         0.         0.\n",
      " 0.         0.         0.         0.7734375  0.71502591 0.47813411\n",
      " 0.57345972 0.3030303  0.         0.65806452 0.80823199 0.86173633\n",
      " 0.79858657 0.62535211 0.81692573 0.54954955 0.75806452 0.01709402\n",
      " 0.01801802 0.39937107 0.46319569 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 27/300, Loss: 0.2457, Accuracy: 0.8931, F1: 0.5051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92996921 0.6208     0.6230107  0.07249467 0.08089888 0.02076125\n",
      " 0.02       0.04910714 0.04166667 0.63375796 0.649304   0.33242803\n",
      " 0.40433735 0.23137492 0.05714286 0.52376981 0.63245546 0.71759515\n",
      " 0.68202466 0.55391924 0.76682045 0.41352806 0.63727821 0.11813472\n",
      " 0.12798265 0.33255679 0.37908102 0.98212475 0.93138723 0.95077874]\n",
      "Training Epoch 28/300, Loss: 0.3136, Accuracy: 0.8540, F1: 0.4505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94690515 0.85955056 0.80310078 0.         0.         0.\n",
      " 0.         0.         0.         0.75159236 0.71618037 0.43537415\n",
      " 0.54775281 0.35251799 0.03636364 0.66666667 0.81282496 0.86138614\n",
      " 0.79522498 0.58031088 0.79391282 0.50224215 0.7262181  0.03448276\n",
      " 0.03636364 0.43438914 0.4984127  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 28/300, Loss: 0.2409, Accuracy: 0.8931, F1: 0.5063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93062909 0.64113326 0.6472576  0.08474576 0.08520179 0.\n",
      " 0.         0.01781737 0.02359882 0.62140575 0.62090909 0.32432432\n",
      " 0.40469508 0.22263451 0.08498584 0.48092585 0.64647994 0.71257984\n",
      " 0.68074134 0.5448505  0.75759307 0.43856921 0.65356541 0.07939914\n",
      " 0.09810479 0.34623218 0.37389448 0.98425147 0.93314207 0.95227313]\n",
      "Training Epoch 29/300, Loss: 0.3127, Accuracy: 0.8547, F1: 0.4464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94378155 0.86440678 0.77488515 0.         0.         0.\n",
      " 0.         0.         0.         0.74688797 0.73737374 0.45806452\n",
      " 0.57291667 0.34108527 0.03636364 0.66950959 0.82557078 0.85396825\n",
      " 0.80887372 0.62804878 0.79026577 0.53153153 0.74915636 0.\n",
      " 0.         0.43575419 0.50543478 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 29/300, Loss: 0.2444, Accuracy: 0.8923, F1: 0.5091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92973492 0.62473795 0.63449692 0.05726872 0.05116279 0.00657895\n",
      " 0.00954654 0.03508772 0.02312139 0.63124504 0.64510412 0.35231506\n",
      " 0.43878273 0.22236422 0.09497207 0.49325464 0.63382971 0.69980668\n",
      " 0.67464424 0.54803597 0.76973936 0.43369735 0.63554217 0.12761506\n",
      " 0.14128035 0.33729923 0.36408669 0.98496336 0.93095491 0.94743074]\n",
      "Training Epoch 30/300, Loss: 0.3114, Accuracy: 0.8542, F1: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95225238 0.83606557 0.77448071 0.         0.         0.\n",
      " 0.         0.         0.         0.76985743 0.74093264 0.4695122\n",
      " 0.57212121 0.35856574 0.03703704 0.64770241 0.80602637 0.8448\n",
      " 0.79966471 0.58673469 0.8130719  0.5258216  0.72167488 0.08064516\n",
      " 0.08474576 0.45604396 0.48827586 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 30/300, Loss: 0.2357, Accuracy: 0.8962, F1: 0.5121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93117358 0.62999481 0.64233577 0.04063205 0.03349282 0.02631579\n",
      " 0.02421308 0.05063291 0.06010929 0.63157895 0.6428898  0.34246575\n",
      " 0.43164109 0.21329987 0.04776119 0.49978823 0.64384361 0.7373348\n",
      " 0.69957778 0.54932302 0.77483282 0.4576144  0.67072496 0.13669821\n",
      " 0.13747228 0.33303384 0.36725801 0.98363142 0.93121297 0.94970344]\n",
      "Training Epoch 31/300, Loss: 0.3054, Accuracy: 0.8571, F1: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94653837 0.83573487 0.78164557 0.         0.         0.\n",
      " 0.         0.         0.         0.75362319 0.71317829 0.44736842\n",
      " 0.55890411 0.33870968 0.03703704 0.64935065 0.80555556 0.86774194\n",
      " 0.82415631 0.58575198 0.80368906 0.54222222 0.73526012 0.03389831\n",
      " 0.03571429 0.42965204 0.492891   0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 31/300, Loss: 0.2410, Accuracy: 0.8941, F1: 0.5072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93095954 0.6526537  0.6400209  0.07472527 0.06018519 0.01398601\n",
      " 0.01015228 0.05183585 0.04469274 0.64480443 0.63940193 0.36072351\n",
      " 0.44865865 0.23824451 0.08602151 0.53271812 0.65124417 0.71424665\n",
      " 0.69389716 0.55697446 0.77704064 0.420653   0.65038002 0.14135021\n",
      " 0.15865922 0.35001481 0.3778661  0.98265823 0.92990771 0.94634204]\n",
      "Training Epoch 32/300, Loss: 0.3046, Accuracy: 0.8570, F1: 0.4594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94867573 0.86532951 0.79873217 0.         0.         0.\n",
      " 0.         0.         0.         0.77844311 0.73349633 0.50857143\n",
      " 0.58928571 0.32786885 0.03703704 0.68049793 0.8245614  0.86407767\n",
      " 0.81873374 0.63865546 0.83665339 0.57268722 0.77181208 0.01709402\n",
      " 0.01801802 0.45535714 0.51410658 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 32/300, Loss: 0.2365, Accuracy: 0.8992, F1: 0.5199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93244591 0.60965373 0.65119876 0.07809111 0.06928406 0.01355932\n",
      " 0.01474201 0.05919662 0.05602241 0.64345073 0.66151046 0.34980989\n",
      " 0.44660667 0.25046963 0.09972299 0.5555097  0.67117727 0.72459016\n",
      " 0.70299903 0.57651588 0.79152526 0.44344569 0.67252747 0.16921509\n",
      " 0.15221987 0.36629608 0.38946724 0.98360656 0.92721262 0.94737465]\n",
      "Training Epoch 33/300, Loss: 0.3010, Accuracy: 0.8606, F1: 0.4670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95398971 0.86516854 0.8095952  0.         0.         0.\n",
      " 0.         0.         0.         0.78367347 0.75132275 0.48979592\n",
      " 0.58409091 0.37398374 0.14035088 0.71721311 0.83407276 0.87012987\n",
      " 0.82668977 0.5942029  0.79201731 0.55696203 0.74561404 0.16176471\n",
      " 0.24113475 0.4652568  0.51223491 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 33/300, Loss: 0.2304, Accuracy: 0.8992, F1: 0.5356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9319843  0.64251465 0.6500398  0.09799555 0.0911271  0.02666667\n",
      " 0.02403846 0.09071274 0.05571031 0.62657233 0.64516129 0.3496358\n",
      " 0.44286392 0.23168441 0.09809264 0.52162957 0.64709269 0.73288227\n",
      " 0.69602273 0.56126862 0.77431962 0.45015106 0.65873163 0.1443299\n",
      " 0.14752371 0.35701599 0.38333333 0.98502748 0.93226048 0.95159948]\n",
      "Training Epoch 34/300, Loss: 0.3002, Accuracy: 0.8586, F1: 0.4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95445994 0.86486486 0.82517483 0.         0.         0.\n",
      " 0.         0.         0.         0.788      0.73945409 0.46884273\n",
      " 0.56404494 0.33191489 0.10714286 0.74708171 0.83728536 0.85897436\n",
      " 0.81666667 0.57611241 0.77722889 0.54935622 0.75027503 0.23225806\n",
      " 0.34117647 0.4600939  0.50357143 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 34/300, Loss: 0.2308, Accuracy: 0.8971, F1: 0.5364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92999883 0.63927428 0.63711176 0.07758621 0.06306306 0.02580645\n",
      " 0.0456621  0.03463203 0.03428571 0.         0.63132911 0.65998177\n",
      " 0.36507937 0.46445714 0.24677716 0.08042895 0.54265501 0.67535545\n",
      " 0.72697368 0.68744978 0.57212239 0.77126448 0.48902347 0.67588558\n",
      " 0.12695109 0.13362541 0.36143868 0.38871668 0.98617337 0.92703916\n",
      " 0.94511727]\n",
      "Training Epoch 35/300, Loss: 0.3011, Accuracy: 0.8575, F1: 0.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95447365 0.85633803 0.79569892 0.         0.         0.\n",
      " 0.         0.         0.         0.78642715 0.73631841 0.50531915\n",
      " 0.57392996 0.32340426 0.03703704 0.72727273 0.8171521  0.8635634\n",
      " 0.82292558 0.64210526 0.84912652 0.55462185 0.75962539 0.2\n",
      " 0.25174825 0.45645646 0.51875    0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 35/300, Loss: 0.2289, Accuracy: 0.9018, F1: 0.5344\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93421382 0.65445026 0.66358974 0.11764706 0.09756098 0.0137931\n",
      " 0.01985112 0.08553971 0.06434316 0.63020214 0.64448496 0.36093418\n",
      " 0.45608108 0.27549824 0.07427056 0.54357703 0.69674952 0.73592127\n",
      " 0.69095641 0.56447689 0.79270803 0.45790251 0.66059957 0.17382812\n",
      " 0.18642351 0.37195484 0.40151276 0.98449858 0.93320027 0.95057621]\n",
      "Training Epoch 36/300, Loss: 0.2942, Accuracy: 0.8628, F1: 0.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95347836 0.87709497 0.82352941 0.         0.         0.\n",
      " 0.         0.         0.         0.80632411 0.74634146 0.49329759\n",
      " 0.55935614 0.36144578 0.10714286 0.70315789 0.81718464 0.87868852\n",
      " 0.82331512 0.59459459 0.79158513 0.56521739 0.75057208 0.22377622\n",
      " 0.31788079 0.46969697 0.52333333 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 36/300, Loss: 0.2272, Accuracy: 0.8983, F1: 0.5395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93360028 0.64304325 0.67288306 0.09361702 0.09029345 0.02640264\n",
      " 0.03827751 0.07377049 0.07608696 0.63676412 0.64513109 0.36633139\n",
      " 0.44640726 0.24738462 0.09289617 0.52614245 0.663626   0.71782313\n",
      " 0.69785325 0.57074341 0.78582868 0.45508982 0.67037502 0.16649104\n",
      " 0.18161683 0.37814144 0.39975171 0.98694253 0.92765374 0.94800498]\n",
      "Training Epoch 37/300, Loss: 0.2938, Accuracy: 0.8613, F1: 0.4720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95556191 0.85635359 0.80357143 0.         0.         0.\n",
      " 0.         0.         0.         0.77844311 0.74257426 0.5060241\n",
      " 0.60740741 0.36595745 0.03703704 0.73131313 0.84452297 0.86984127\n",
      " 0.83261803 0.63852243 0.83977606 0.5703125  0.75654704 0.18571429\n",
      " 0.23776224 0.48821082 0.50842697 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 37/300, Loss: 0.2237, Accuracy: 0.9042, F1: 0.5385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93425019 0.65190525 0.67272268 0.09586057 0.06944444 0.01986755\n",
      " 0.01941748 0.03470716 0.03943662 0.63607595 0.66330738 0.37789474\n",
      " 0.4832435  0.28726614 0.10687023 0.52560873 0.67980884 0.73419108\n",
      " 0.71050955 0.58229066 0.80164159 0.4635064  0.67094174 0.15568862\n",
      " 0.1825641  0.37067449 0.40073417 0.98495575 0.92927529 0.94939416]\n",
      "Training Epoch 38/300, Loss: 0.2877, Accuracy: 0.8641, F1: 0.4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95161252 0.8603352  0.80981595 0.         0.         0.\n",
      " 0.         0.         0.         0.7992126  0.74300254 0.50991501\n",
      " 0.5896861  0.34745763 0.07272727 0.73511294 0.83793738 0.87112561\n",
      " 0.82782609 0.58595642 0.78486539 0.55021834 0.74487472 0.05\n",
      " 0.05263158 0.45813586 0.50980392 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 38/300, Loss: 0.2304, Accuracy: 0.8979, F1: 0.5230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9342791  0.64560295 0.66255778 0.09465021 0.07343413 0.03858521\n",
      " 0.04514673 0.08137045 0.07365439 0.61904762 0.64602588 0.38049303\n",
      " 0.48842311 0.28390805 0.10026385 0.56206473 0.67320518 0.7510116\n",
      " 0.71550363 0.5761079  0.79087821 0.47976012 0.6783976  0.17603393\n",
      " 0.20995671 0.3714455  0.4035309  0.98642591 0.92921734 0.94953093]\n",
      "Training Epoch 39/300, Loss: 0.2922, Accuracy: 0.8641, F1: 0.4807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94975323 0.86740331 0.81039755 0.         0.         0.\n",
      " 0.         0.         0.         0.79215686 0.7480916  0.51704545\n",
      " 0.59617548 0.34745763 0.03703704 0.75834971 0.84656085 0.86071987\n",
      " 0.83333333 0.66106443 0.84591105 0.54148472 0.763596   0.\n",
      " 0.         0.43887147 0.49235993 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 39/300, Loss: 0.2295, Accuracy: 0.9021, F1: 0.5235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93534731 0.6566856  0.63620026 0.1125     0.10526316 0.05882353\n",
      " 0.06741573 0.07127883 0.06575342 0.64916468 0.66817975 0.3743428\n",
      " 0.48454349 0.27504446 0.10443864 0.52501033 0.65081252 0.73135135\n",
      " 0.69674345 0.60806916 0.80025476 0.4534712  0.66814078 0.17922607\n",
      " 0.19396552 0.36774194 0.40462428 0.98718515 0.93238523 0.95154866]\n",
      "Training Epoch 40/300, Loss: 0.2862, Accuracy: 0.8642, F1: 0.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95310936 0.87567568 0.82471264 0.         0.         0.\n",
      " 0.         0.         0.         0.80473373 0.72506083 0.53097345\n",
      " 0.6073903  0.384      0.07017544 0.76341948 0.84588441 0.86614173\n",
      " 0.83146067 0.62189055 0.80801001 0.54464286 0.74623407 0.06666667\n",
      " 0.07017544 0.48036254 0.51360544 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 40/300, Loss: 0.2234, Accuracy: 0.9018, F1: 0.5311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93561823 0.66701571 0.68649064 0.08731809 0.09745763 0.01337793\n",
      " 0.01398601 0.09034908 0.08152174 0.64218009 0.67355186 0.40418848\n",
      " 0.47953488 0.28621701 0.0653951  0.54244306 0.67256978 0.73661321\n",
      " 0.70531088 0.58095698 0.79059913 0.43797856 0.66743383 0.1529052\n",
      " 0.17136886 0.3832853  0.41833637 0.98732101 0.93043858 0.94839858]\n",
      "Training Epoch 41/300, Loss: 0.2877, Accuracy: 0.8647, F1: 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95360396 0.88461538 0.81991215 0.1        0.15384615 0.\n",
      " 0.         0.         0.         0.8015873  0.73758865 0.5106383\n",
      " 0.58410733 0.384      0.14035088 0.77756286 0.83533448 0.87220447\n",
      " 0.83375959 0.6557377  0.85009698 0.57377049 0.78089304 0.18705036\n",
      " 0.28965517 0.47432024 0.50434783 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 41/300, Loss: 0.2228, Accuracy: 0.9049, F1: 0.5568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9359006  0.65068842 0.68397844 0.14255765 0.13449024 0.03174603\n",
      " 0.03595506 0.09255533 0.09973753 0.63917526 0.66111111 0.39936776\n",
      " 0.49976156 0.30227001 0.11       0.57438873 0.68456898 0.75020342\n",
      " 0.71518987 0.60328185 0.81059104 0.45919146 0.66829177 0.19075713\n",
      " 0.20808081 0.37771261 0.40705811 0.98706543 0.93278464 0.9494602 ]\n",
      "Training Epoch 42/300, Loss: 0.2844, Accuracy: 0.8671, F1: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94995639 0.86685552 0.80246914 0.         0.         0.\n",
      " 0.         0.         0.         0.8        0.75180723 0.51490515\n",
      " 0.58092176 0.36144578 0.07272727 0.75806452 0.82146161 0.87908497\n",
      " 0.83968113 0.64879357 0.83278509 0.55319149 0.75413451 0.16783217\n",
      " 0.22972973 0.4352     0.4789272  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 42/300, Loss: 0.2262, Accuracy: 0.9007, F1: 0.5366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93562419 0.6632178  0.67486202 0.09421842 0.08791209 0.02614379\n",
      " 0.02358491 0.06625259 0.06989247 0.63974663 0.64764493 0.41562344\n",
      " 0.47990762 0.29130967 0.08022923 0.57361839 0.68708134 0.75652174\n",
      " 0.72204473 0.5620155  0.7872496  0.47232472 0.6830302  0.20222447\n",
      " 0.21599169 0.38348946 0.40237797 0.9858568  0.93269291 0.95308495]\n",
      "Training Epoch 43/300, Loss: 0.2865, Accuracy: 0.8654, F1: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95180267 0.8773842  0.82300885 0.         0.         0.\n",
      " 0.         0.         0.         0.77846791 0.7403599  0.53097345\n",
      " 0.61124122 0.37704918 0.10714286 0.78557875 0.84514003 0.86342229\n",
      " 0.8360515  0.68011527 0.84216726 0.56370656 0.74202899 0.15625\n",
      " 0.208      0.48688047 0.53027823 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 43/300, Loss: 0.2215, Accuracy: 0.9042, F1: 0.5445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93595219 0.65936359 0.6744898  0.07933194 0.07708779 0.03761755\n",
      " 0.04072398 0.10084034 0.09917355 0.64371373 0.68216361 0.3858899\n",
      " 0.47368421 0.28134557 0.09315068 0.56523517 0.68402643 0.75476766\n",
      " 0.72323553 0.58515699 0.78960323 0.46234154 0.67453927 0.20238095\n",
      " 0.22736419 0.37716976 0.4317126  0.98808398 0.93657624 0.95347036]\n",
      "Training Epoch 44/300, Loss: 0.2843, Accuracy: 0.8662, F1: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95644466 0.86792453 0.79551821 0.06896552 0.08163265 0.\n",
      " 0.         0.         0.         0.8        0.73381295 0.51713396\n",
      " 0.60991105 0.41295547 0.13114754 0.78834951 0.84811238 0.87163233\n",
      " 0.83164983 0.59854015 0.8018591  0.53982301 0.73049645 0.08130081\n",
      " 0.10169492 0.49513213 0.5        0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 44/300, Loss: 0.2198, Accuracy: 0.9023, F1: 0.5387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93650436 0.65274151 0.6692367  0.07610994 0.06622517 0.04745763\n",
      " 0.03422983 0.06060606 0.05390836 0.64457594 0.67776778 0.41038697\n",
      " 0.51374451 0.29075927 0.14797136 0.57320099 0.69788868 0.74543502\n",
      " 0.7106631  0.58574181 0.80748184 0.45502646 0.66200378 0.19188922\n",
      " 0.19938962 0.39267016 0.43954051 0.98834058 0.93393225 0.95252863]\n",
      "Training Epoch 45/300, Loss: 0.2823, Accuracy: 0.8676, F1: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95074066 0.86187845 0.79464286 0.03448276 0.08       0.\n",
      " 0.         0.         0.         0.791423   0.73239437 0.51713396\n",
      " 0.61139896 0.416      0.1        0.77623762 0.85663082 0.87220447\n",
      " 0.84264832 0.63185379 0.82917772 0.57641921 0.77267637 0.03418803\n",
      " 0.03603604 0.4375963  0.48918469 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 45/300, Loss: 0.2232, Accuracy: 0.9028, F1: 0.5348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93650416 0.67009779 0.68131326 0.10084034 0.0952381  0.0397351\n",
      " 0.05442177 0.10953347 0.10966057 0.64417419 0.67530147 0.39585492\n",
      " 0.49458314 0.2732175  0.07065217 0.56908569 0.68933359 0.74550409\n",
      " 0.71177703 0.60635697 0.814319   0.50516987 0.69929052 0.19085487\n",
      " 0.23260437 0.37809187 0.40894966 0.98745192 0.92915056 0.94738713]\n",
      "Training Epoch 46/300, Loss: 0.2795, Accuracy: 0.8683, F1: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95420463 0.8839779  0.82142857 0.03508772 0.04166667 0.\n",
      " 0.         0.         0.         0.79919679 0.74109264 0.51873199\n",
      " 0.59930314 0.4063745  0.13793103 0.77227723 0.85365854 0.87459807\n",
      " 0.84       0.66115702 0.85289997 0.575      0.77896996 0.09917355\n",
      " 0.10434783 0.4893617  0.50406504 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 46/300, Loss: 0.2191, Accuracy: 0.9058, F1: 0.5448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93689381 0.68363636 0.67731797 0.13247863 0.125      0.06020067\n",
      " 0.05594406 0.12195122 0.09549072 0.63395012 0.66636072 0.41152263\n",
      " 0.51245552 0.30096536 0.15183246 0.59845717 0.71867252 0.74694874\n",
      " 0.71811024 0.5907781  0.82038305 0.47740964 0.68407407 0.19560878\n",
      " 0.2244489  0.39316734 0.41913992 0.98802169 0.93351628 0.95189331]\n",
      "Training Epoch 47/300, Loss: 0.2772, Accuracy: 0.8700, F1: 0.5009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95174756 0.87534626 0.81288344 0.03448276 0.08       0.\n",
      " 0.         0.         0.         0.79607843 0.75067024 0.52887538\n",
      " 0.62626263 0.424      0.13333333 0.76831683 0.85071942 0.87961477\n",
      " 0.82363474 0.6351706  0.8310992  0.56387665 0.7761194  0.0661157\n",
      " 0.0862069  0.49421965 0.53271028 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 47/300, Loss: 0.2220, Accuracy: 0.9046, F1: 0.5440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93736651 0.69808389 0.70073362 0.14227642 0.11134904 0.07523511\n",
      " 0.06622517 0.132      0.10632911 0.65188119 0.66282165 0.38655462\n",
      " 0.49808795 0.30670554 0.13625304 0.58350264 0.68932412 0.74880763\n",
      " 0.72236181 0.60047962 0.81119296 0.49665428 0.69526041 0.218\n",
      " 0.23862487 0.38000585 0.41917973 0.98732261 0.93290097 0.94905403]\n",
      "Training Epoch 48/300, Loss: 0.2790, Accuracy: 0.8695, F1: 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95513796 0.87671233 0.81437126 0.06779661 0.11764706 0.04444444\n",
      " 0.04705882 0.         0.         0.80239521 0.74242424 0.5433526\n",
      " 0.6265896  0.42857143 0.13333333 0.78362573 0.85992908 0.86071987\n",
      " 0.83262532 0.64935065 0.83566341 0.59915612 0.78587196 0.18045113\n",
      " 0.23880597 0.5065123  0.53736089 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 48/300, Loss: 0.2160, Accuracy: 0.9072, F1: 0.5623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93760059 0.69781615 0.70375031 0.12170385 0.12605042 0.04545455\n",
      " 0.05936073 0.10084034 0.09139785 0.64363354 0.67847411 0.42040816\n",
      " 0.51264368 0.28641371 0.13477089 0.5890128  0.70634299 0.74402364\n",
      " 0.71496212 0.60611855 0.81824033 0.50184502 0.69478639 0.21428571\n",
      " 0.23100304 0.37869822 0.4099142  0.98789713 0.93232708 0.9528403 ]\n",
      "Training Epoch 49/300, Loss: 0.2737, Accuracy: 0.8706, F1: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95367108 0.8815427  0.82768778 0.06779661 0.11764706 0.08510638\n",
      " 0.08888889 0.         0.         0.80715706 0.71058824 0.54178674\n",
      " 0.62485747 0.43846154 0.13333333 0.79615385 0.85395189 0.86942675\n",
      " 0.83701188 0.65454545 0.84419714 0.562249   0.77360406 0.09836066\n",
      " 0.11965812 0.465625   0.49209139 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 49/300, Loss: 0.2186, Accuracy: 0.9060, F1: 0.5548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93755511 0.6780893  0.68356375 0.12765957 0.10526316 0.07006369\n",
      " 0.10300429 0.12109375 0.1164557  0.66047951 0.69301713 0.43072133\n",
      " 0.51314854 0.30778372 0.09230769 0.57926583 0.70660287 0.73661555\n",
      " 0.71309638 0.60268714 0.82250695 0.45827011 0.68471582 0.22813688\n",
      " 0.22439024 0.40368557 0.43244892 0.98929066 0.93520424 0.95269265]\n",
      "Training Epoch 50/300, Loss: 0.2736, Accuracy: 0.8709, F1: 0.5037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95576619 0.88461538 0.82232012 0.06779661 0.11764706 0.125\n",
      " 0.15053763 0.         0.         0.79518072 0.74314214 0.52406417\n",
      " 0.59627329 0.36134454 0.10526316 0.80380952 0.85135135 0.87961477\n",
      " 0.84722222 0.64566929 0.84418666 0.56903766 0.7761194  0.20437956\n",
      " 0.29166667 0.49204052 0.51032448 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 50/300, Loss: 0.2161, Accuracy: 0.9062, F1: 0.5654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93784786 0.67866324 0.6926629  0.16227181 0.14193548 0.03389831\n",
      " 0.03729604 0.12576065 0.12201592 0.65322262 0.67730173 0.43316583\n",
      " 0.51201867 0.30119048 0.13065327 0.58492872 0.70803346 0.74389917\n",
      " 0.72747322 0.60190476 0.81171343 0.5124451  0.70185185 0.22627037\n",
      " 0.23699422 0.38905238 0.42460194 0.98687697 0.9303225  0.95091514]\n",
      "Training Epoch 51/300, Loss: 0.2738, Accuracy: 0.8708, F1: 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95612968 0.87777778 0.81967213 0.16129032 0.22222222 0.19230769\n",
      " 0.18181818 0.         0.         0.80715706 0.73381295 0.54237288\n",
      " 0.61883408 0.43846154 0.1875     0.79223301 0.85560538 0.87440382\n",
      " 0.83942226 0.65789474 0.84478642 0.59414226 0.78964401 0.29139073\n",
      " 0.39759036 0.49854227 0.52913386 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 51/300, Loss: 0.2138, Accuracy: 0.9085, F1: 0.5901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93727141 0.69226777 0.70385604 0.14859438 0.13141684 0.03095975\n",
      " 0.04206501 0.14931238 0.125      0.65835606 0.66757741 0.41991786\n",
      " 0.51650943 0.32354634 0.13592233 0.59127625 0.70017534 0.75658073\n",
      " 0.72698312 0.59506531 0.81696339 0.51991311 0.69971367 0.21285141\n",
      " 0.24041451 0.40411765 0.44188937 0.98738648 0.93328345 0.95188247]\n",
      "Training Epoch 52/300, Loss: 0.2730, Accuracy: 0.8713, F1: 0.5087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95591336 0.86931818 0.80690738 0.06779661 0.08       0.\n",
      " 0.         0.         0.         0.81568627 0.74519231 0.5304878\n",
      " 0.60963855 0.42063492 0.13114754 0.80970149 0.84451718 0.87675507\n",
      " 0.84504657 0.61538462 0.81036168 0.55752212 0.74560375 0.2585034\n",
      " 0.36708861 0.48493976 0.52357724 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 52/300, Loss: 0.2163, Accuracy: 0.9046, F1: 0.5590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9388312  0.70636976 0.70695021 0.14705882 0.13274336 0.03846154\n",
      " 0.0472103  0.12915851 0.13466334 0.         0.6519685  0.68482143\n",
      " 0.43213015 0.54441653 0.30195382 0.10555556 0.59439708 0.70478369\n",
      " 0.76386259 0.73684211 0.61641863 0.81696539 0.50930752 0.7083409\n",
      " 0.21322804 0.23100304 0.39662693 0.42030331 0.9883347  0.93550399\n",
      " 0.95291453]\n",
      "Training Epoch 53/300, Loss: 0.2692, Accuracy: 0.8732, F1: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95769816 0.8707124  0.81502086 0.12903226 0.18518519 0.\n",
      " 0.         0.         0.         0.8172888  0.7398568  0.53481894\n",
      " 0.58735263 0.406639   0.16666667 0.8030888  0.84628975 0.88151659\n",
      " 0.84945332 0.61463415 0.80444767 0.58723404 0.75977654 0.20588235\n",
      " 0.29787234 0.54368932 0.51594203 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 53/300, Loss: 0.2144, Accuracy: 0.9041, F1: 0.5639\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93777104 0.70642202 0.71191631 0.11529933 0.12300683 0.04516129\n",
      " 0.04454343 0.09920635 0.11557789 0.65050821 0.72043011 0.45049764\n",
      " 0.52217936 0.30429733 0.14388489 0.61012862 0.72737842 0.75040431\n",
      " 0.71399209 0.61478218 0.82310616 0.49439881 0.71132674 0.21890547\n",
      " 0.2358871  0.41208633 0.44213032 0.98885039 0.93226048 0.94734348]\n",
      "Training Epoch 54/300, Loss: 0.2697, Accuracy: 0.8732, F1: 0.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95022051 0.88579387 0.82588598 0.13114754 0.18867925 0.\n",
      " 0.         0.         0.         0.77593361 0.75590551 0.54925373\n",
      " 0.62907268 0.45454545 0.13559322 0.79069767 0.85441941 0.87301587\n",
      " 0.83579496 0.68181818 0.83603179 0.57959184 0.77870564 0.03418803\n",
      " 0.03603604 0.47548291 0.51580699 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 54/300, Loss: 0.2194, Accuracy: 0.9051, F1: 0.5524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93787933 0.67528438 0.686884   0.11788618 0.0952381  0.03960396\n",
      " 0.05309735 0.14084507 0.09350649 0.63385354 0.68081181 0.42674834\n",
      " 0.5268991  0.29357798 0.10473815 0.60184813 0.7073955  0.75692964\n",
      " 0.72537549 0.58566682 0.80283341 0.5124451  0.70100143 0.20118343\n",
      " 0.2289767  0.416882   0.46656672 0.98814777 0.9303225  0.9499198 ]\n",
      "Training Epoch 55/300, Loss: 0.2712, Accuracy: 0.8702, F1: 0.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95531704 0.89010989 0.82934132 0.03508772 0.08163265 0.\n",
      " 0.         0.         0.         0.81102362 0.74874372 0.52852853\n",
      " 0.62638718 0.464      0.13333333 0.8219697  0.86347518 0.88782051\n",
      " 0.84986831 0.66111111 0.8582903  0.59414226 0.79512735 0.140625\n",
      " 0.19047619 0.51058201 0.53439153 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 55/300, Loss: 0.2120, Accuracy: 0.9102, F1: 0.5603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93840751 0.68396471 0.6876439  0.11958763 0.12008282 0.03960396\n",
      " 0.03196347 0.1025641  0.11586902 0.62688942 0.64638082 0.44838057\n",
      " 0.52554073 0.31928049 0.10152284 0.62465319 0.71615224 0.75828618\n",
      " 0.72648752 0.60977948 0.8174311  0.51840943 0.70516153 0.21242485\n",
      " 0.23529412 0.41709696 0.44577591 0.98999434 0.93365756 0.95170117]\n",
      "Training Epoch 56/300, Loss: 0.2675, Accuracy: 0.8720, F1: 0.5057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95779142 0.89071038 0.8379562  0.06896552 0.12       0.04347826\n",
      " 0.02298851 0.03030303 0.03636364 0.81451613 0.75810474 0.53107345\n",
      " 0.59188034 0.40495868 0.13333333 0.82899628 0.85738115 0.88467615\n",
      " 0.85265911 0.62531017 0.80962801 0.5785124  0.75884244 0.16666667\n",
      " 0.25757576 0.53887399 0.50754458 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 56/300, Loss: 0.2147, Accuracy: 0.9052, F1: 0.5636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93899884 0.68202765 0.70094653 0.18218623 0.15702479 0.03289474\n",
      " 0.04899777 0.14371257 0.14249364 0.         0.66114398 0.69110416\n",
      " 0.45033113 0.55331141 0.32494279 0.14105793 0.6148841  0.72380952\n",
      " 0.76037483 0.72994098 0.61426492 0.82783256 0.53372869 0.72693863\n",
      " 0.19028741 0.21349446 0.40675991 0.45273632 0.98859555 0.93468089\n",
      " 0.95296572]\n",
      "Training Epoch 57/300, Loss: 0.2679, Accuracy: 0.8758, F1: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95479932 0.87603306 0.8253012  0.06779661 0.11764706 0.\n",
      " 0.         0.02985075 0.03508772 0.79681275 0.76070529 0.54434251\n",
      " 0.64222503 0.45669291 0.10344828 0.80769231 0.86654804 0.87859425\n",
      " 0.84541485 0.65104167 0.83693622 0.5982906  0.78359909 0.24657534\n",
      " 0.32467532 0.49262537 0.51718494 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 57/300, Loss: 0.2136, Accuracy: 0.9091, F1: 0.5686\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93777761 0.68688946 0.69521155 0.12793177 0.15044248 0.04320988\n",
      " 0.06640625 0.1504065  0.13164557 0.62938165 0.67287978 0.42340967\n",
      " 0.52924394 0.28400955 0.10498688 0.629286   0.72142021 0.76164826\n",
      " 0.72865516 0.60143885 0.81146855 0.51813472 0.69587256 0.24813433\n",
      " 0.26882745 0.39091174 0.43807763 0.98916467 0.92577345 0.94795495]\n",
      "Training Epoch 58/300, Loss: 0.2674, Accuracy: 0.8713, F1: 0.5104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95976306 0.89247312 0.85754584 0.09836066 0.1509434  0.\n",
      " 0.         0.05882353 0.06896552 0.80961924 0.75247525 0.53892216\n",
      " 0.6206089  0.44268775 0.16129032 0.8173258  0.85834739 0.88679245\n",
      " 0.85738255 0.65984655 0.84969008 0.58498024 0.78470825 0.19259259\n",
      " 0.25       0.5613577  0.54251012 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 58/300, Loss: 0.2100, Accuracy: 0.9117, F1: 0.5752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93978843 0.69195284 0.69709332 0.15541922 0.14767932 0.05787781\n",
      " 0.06550218 0.1237911  0.11138015 0.6457506  0.67040673 0.45573441\n",
      " 0.54549654 0.30841672 0.13089005 0.60883281 0.71037842 0.76454741\n",
      " 0.73753407 0.62469497 0.83546107 0.53440703 0.73233721 0.21293532\n",
      " 0.23470411 0.41353811 0.4498953  0.98936773 0.93770655 0.95670892]\n",
      "Training Epoch 59/300, Loss: 0.2641, Accuracy: 0.8765, F1: 0.5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95448966 0.88705234 0.82440476 0.06779661 0.11764706 0.04444444\n",
      " 0.04705882 0.03030303 0.03636364 0.81188119 0.76726343 0.55113636\n",
      " 0.64243845 0.45914397 0.10169492 0.81070746 0.87336245 0.87774295\n",
      " 0.84786325 0.68732394 0.85449812 0.60082305 0.79913607 0.19259259\n",
      " 0.24817518 0.48538012 0.5216     0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 59/300, Loss: 0.2117, Accuracy: 0.9103, F1: 0.5714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93974986 0.68127282 0.70271656 0.14376321 0.12581345 0.03785489\n",
      " 0.06465517 0.15354331 0.14778325 0.6528894  0.69630947 0.46146045\n",
      " 0.54752498 0.33352907 0.12834225 0.62916006 0.71945525 0.76456376\n",
      " 0.75176637 0.60164172 0.82473305 0.52432825 0.69785795 0.21875\n",
      " 0.23776224 0.41891117 0.45729697 0.98954265 0.9318281  0.95177423]\n",
      "Training Epoch 60/300, Loss: 0.2624, Accuracy: 0.8756, F1: 0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95664176 0.89010989 0.82717873 0.03448276 0.08       0.\n",
      " 0.         0.03030303 0.03636364 0.8040404  0.76649746 0.54599407\n",
      " 0.64691358 0.46153846 0.1875     0.80077369 0.85416667 0.88566828\n",
      " 0.84021544 0.63157895 0.81848185 0.5814978  0.76997579 0.24113475\n",
      " 0.31724138 0.51502146 0.52877138 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 60/300, Loss: 0.2113, Accuracy: 0.9082, F1: 0.5683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94162089 0.71611253 0.73329985 0.15079365 0.15594542 0.05031447\n",
      " 0.05416667 0.13226453 0.14669927 0.65195112 0.69189189 0.43054844\n",
      " 0.55027933 0.32536443 0.16425121 0.62619048 0.73102119 0.77063727\n",
      " 0.74563473 0.62170088 0.84000813 0.54704595 0.71875579 0.23196881\n",
      " 0.24575425 0.41455786 0.45848161 0.99062598 0.93057202 0.95091514]\n",
      "Training Epoch 61/300, Loss: 0.2627, Accuracy: 0.8783, F1: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95772024 0.89130435 0.84210526 0.21538462 0.3        0.04545455\n",
      " 0.04938272 0.05882353 0.06896552 0.8172888  0.74146341 0.53293413\n",
      " 0.62026862 0.44621514 0.16129032 0.81578947 0.85472973 0.89302326\n",
      " 0.85785536 0.671875   0.8537424  0.59109312 0.79414838 0.27777778\n",
      " 0.38666667 0.5316092  0.5398374  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 61/300, Loss: 0.2088, Accuracy: 0.9124, F1: 0.5938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94030893 0.700409   0.71873405 0.13913043 0.13033708 0.07453416\n",
      " 0.09185804 0.16733068 0.15856777 0.65222529 0.69463239 0.44829343\n",
      " 0.53953702 0.33621186 0.15425532 0.62243286 0.71403543 0.76445623\n",
      " 0.72924996 0.6268081  0.83151955 0.51104566 0.7102526  0.23929961\n",
      " 0.26578699 0.42286699 0.43940768 0.99246326 0.92983222 0.94995548]\n",
      "Training Epoch 62/300, Loss: 0.2624, Accuracy: 0.8762, F1: 0.5232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95290402 0.88022284 0.81230769 0.06779661 0.11764706 0.\n",
      " 0.         0.03030303 0.03636364 0.8039604  0.76190476 0.52599388\n",
      " 0.63451777 0.45081967 0.10169492 0.80228137 0.86132644 0.87381703\n",
      " 0.84622068 0.67574932 0.85293284 0.60728745 0.80555556 0.11290323\n",
      " 0.15       0.50507983 0.5210356  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 62/300, Loss: 0.2141, Accuracy: 0.9088, F1: 0.5596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94075718 0.70546197 0.71571572 0.10460251 0.09243697 0.05555556\n",
      " 0.06008584 0.16374269 0.1784897  0.6609509  0.69777778 0.42621259\n",
      " 0.55036739 0.3406214  0.14705882 0.64271457 0.74440154 0.77280086\n",
      " 0.74580604 0.61685824 0.83127081 0.51539012 0.7113713  0.24055666\n",
      " 0.29327902 0.42071574 0.46177464 0.98865784 0.93426469 0.95434744]\n",
      "Training Epoch 63/300, Loss: 0.2587, Accuracy: 0.8778, F1: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95820917 0.89130435 0.83478261 0.13114754 0.22222222 0.16\n",
      " 0.14285714 0.         0.         0.80478088 0.73584906 0.54867257\n",
      " 0.626109   0.47058824 0.16666667 0.82771536 0.85787234 0.88958991\n",
      " 0.85986159 0.66666667 0.84858213 0.60504202 0.79125683 0.2875817\n",
      " 0.38554217 0.55048409 0.55108359 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 63/300, Loss: 0.2058, Accuracy: 0.9127, F1: 0.5938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94091332 0.725619   0.72886006 0.1557377  0.14736842 0.10179641\n",
      " 0.1002004  0.15686275 0.19559902 0.67177914 0.69920844 0.47177419\n",
      " 0.56358517 0.3580533  0.18045113 0.62544874 0.73917228 0.77659006\n",
      " 0.75067194 0.62608696 0.83364581 0.53633721 0.71216617 0.20178042\n",
      " 0.226      0.4208079  0.45529448 0.99094226 0.93370751 0.9545753 ]\n",
      "Training Epoch 64/300, Loss: 0.2611, Accuracy: 0.8790, F1: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95830459 0.88333333 0.8248062  0.10169492 0.12       0.04545455\n",
      " 0.025      0.         0.         0.81349206 0.74519231 0.56353591\n",
      " 0.63755459 0.45559846 0.16129032 0.81992337 0.85662432 0.89064976\n",
      " 0.85493562 0.67567568 0.85510428 0.60683761 0.80410023 0.29447853\n",
      " 0.33707865 0.55434783 0.55223881 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 64/300, Loss: 0.2063, Accuracy: 0.9126, F1: 0.5812\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94111237 0.71828833 0.72783031 0.13441955 0.13441955 0.10365854\n",
      " 0.10916179 0.19029126 0.25120773 0.         0.66769349 0.7010582\n",
      " 0.45426829 0.55621583 0.35832856 0.11195929 0.63484487 0.74178935\n",
      " 0.76484687 0.73906151 0.60384615 0.82536682 0.52072727 0.70340535\n",
      " 0.24347826 0.26757812 0.41863173 0.45434983 0.99082107 0.93612774\n",
      " 0.95293697]\n",
      "Training Epoch 65/300, Loss: 0.2594, Accuracy: 0.8777, F1: 0.5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95797558 0.8839779  0.81570997 0.19047619 0.25454545 0.\n",
      " 0.         0.08695652 0.10169492 0.82051282 0.7373494  0.54925373\n",
      " 0.63515152 0.48221344 0.1875     0.82962963 0.85932203 0.8832\n",
      " 0.85389326 0.66494845 0.8508749  0.59259259 0.79175705 0.3190184\n",
      " 0.40659341 0.5329429  0.5451505  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 65/300, Loss: 0.2056, Accuracy: 0.9126, F1: 0.5944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93998102 0.71603677 0.72100629 0.1352459  0.13580247 0.06430868\n",
      " 0.0956341  0.17670683 0.18227848 0.65430668 0.68088889 0.45292621\n",
      " 0.54264292 0.3242301  0.17411765 0.62349155 0.72593168 0.76828944\n",
      " 0.74195083 0.65304136 0.84449157 0.54005935 0.72064159 0.22042467\n",
      " 0.22974359 0.4206033  0.47231368 0.99069065 0.93029056 0.95044563]\n",
      "Training Epoch 66/300, Loss: 0.2581, Accuracy: 0.8779, F1: 0.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9569203  0.89071038 0.82962963 0.1        0.15384615 0.08510638\n",
      " 0.06896552 0.02985075 0.03508772 0.81437126 0.75773196 0.53658537\n",
      " 0.63819095 0.48       0.19354839 0.80754717 0.8605852  0.87713841\n",
      " 0.8466052  0.67560322 0.8538961  0.59591837 0.79310345 0.29677419\n",
      " 0.38554217 0.52046784 0.53020134 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 66/300, Loss: 0.2076, Accuracy: 0.9122, F1: 0.5871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94135132 0.7016129  0.72397516 0.12608696 0.11453744 0.06451613\n",
      " 0.0867679  0.19402985 0.18937644 0.66276803 0.68940427 0.45963348\n",
      " 0.55112334 0.35796767 0.15025907 0.62836767 0.7325469  0.767919\n",
      " 0.74058777 0.60933661 0.83347679 0.5266229  0.70647135 0.25047438\n",
      " 0.26590693 0.44063927 0.47027189 0.99094454 0.93045593 0.95210899]\n",
      "Training Epoch 67/300, Loss: 0.2595, Accuracy: 0.8778, F1: 0.5287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95831142 0.87830688 0.83611111 0.21538462 0.3        0.125\n",
      " 0.08791209 0.08695652 0.10169492 0.80645161 0.78835979 0.55393586\n",
      " 0.61843641 0.44444444 0.16666667 0.81121495 0.84802687 0.86309524\n",
      " 0.83413849 0.67724868 0.85546039 0.55652174 0.77740113 0.29268293\n",
      " 0.37433155 0.54261364 0.51864407 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 67/300, Loss: 0.2056, Accuracy: 0.9116, F1: 0.5973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94170554 0.72829995 0.73307985 0.15702479 0.15415822 0.08360129\n",
      " 0.09012876 0.19659735 0.24145786 0.6707645  0.6760181  0.4789447\n",
      " 0.57162566 0.34445769 0.14814815 0.63043478 0.73348433 0.76467449\n",
      " 0.73238095 0.61324376 0.83216853 0.49775112 0.70104634 0.27698185\n",
      " 0.30291262 0.44209322 0.48269581 0.99208543 0.93058068 0.95050565]\n",
      "Training Epoch 68/300, Loss: 0.2559, Accuracy: 0.8791, F1: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95573708 0.89130435 0.83040936 0.18181818 0.27692308 0.08888889\n",
      " 0.09638554 0.11428571 0.13333333 0.8172888  0.76691729 0.56179775\n",
      " 0.64228571 0.46825397 0.19047619 0.8411215  0.87876182 0.88676236\n",
      " 0.85263158 0.65625    0.84171715 0.59574468 0.78677309 0.32926829\n",
      " 0.42458101 0.47819063 0.47540984 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 68/300, Loss: 0.2102, Accuracy: 0.9115, F1: 0.6021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94172658 0.71414441 0.7296369  0.13821138 0.13627255 0.0795107\n",
      " 0.12252964 0.21317829 0.24343675 0.67155538 0.69488536 0.46122027\n",
      " 0.55247572 0.3528729  0.14563107 0.64565044 0.74178958 0.77194861\n",
      " 0.74071773 0.63883495 0.83415452 0.51091703 0.71076432 0.2627451\n",
      " 0.2826087  0.43955416 0.4748721  0.99246515 0.93432296 0.95379479]\n",
      "Training Epoch 69/300, Loss: 0.2580, Accuracy: 0.8796, F1: 0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95217759 0.89256198 0.83486239 0.21875    0.31578947 0.\n",
      " 0.         0.02985075 0.03508772 0.80885312 0.76041667 0.57060519\n",
      " 0.65083135 0.50187266 0.13559322 0.82285714 0.86636771 0.88498403\n",
      " 0.85340314 0.68       0.83212121 0.61206897 0.81703107 0.29333333\n",
      " 0.35294118 0.54469274 0.55483871 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 69/300, Loss: 0.2105, Accuracy: 0.9101, F1: 0.5940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94117548 0.71559633 0.71872631 0.1663286  0.18       0.0877193\n",
      " 0.11218569 0.19771863 0.22843823 0.66460108 0.66938776 0.45987654\n",
      " 0.55484784 0.35537665 0.16326531 0.63549161 0.72835477 0.75207275\n",
      " 0.7351791  0.62597656 0.83409483 0.54545455 0.71609339 0.2578125\n",
      " 0.28294574 0.43567168 0.46072374 0.99094567 0.92964072 0.94983675]\n",
      "Training Epoch 70/300, Loss: 0.2554, Accuracy: 0.8778, F1: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95944718 0.89673913 0.8425656  0.06896552 0.12       0.15686275\n",
      " 0.17475728 0.08695652 0.10169492 0.812749   0.74940334 0.56193353\n",
      " 0.65432099 0.5        0.19672131 0.83955224 0.86632826 0.88854003\n",
      " 0.8556962  0.68096515 0.8697318  0.58677686 0.80176211 0.24489796\n",
      " 0.2962963  0.56708861 0.54133333 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 70/300, Loss: 0.2017, Accuracy: 0.9147, F1: 0.5973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94128582 0.7040404  0.72646405 0.14457831 0.13627255 0.06472492\n",
      " 0.09110629 0.18846154 0.21634615 0.65782286 0.70088496 0.493778\n",
      " 0.58400553 0.34052758 0.23529412 0.63123994 0.74601942 0.76185402\n",
      " 0.73793756 0.63478261 0.8330107  0.52777778 0.71703649 0.27083333\n",
      " 0.28192999 0.42646224 0.46266382 0.99214873 0.92889222 0.94920484]\n",
      "Training Epoch 71/300, Loss: 0.2551, Accuracy: 0.8790, F1: 0.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95930885 0.89373297 0.83679525 0.1875     0.24137931 0.125\n",
      " 0.08791209 0.02985075 0.03508772 0.816      0.76691729 0.54913295\n",
      " 0.63195266 0.4534413  0.16129032 0.82889734 0.87586207 0.89341693\n",
      " 0.86080273 0.64467005 0.83704272 0.5814978  0.77163462 0.29577465\n",
      " 0.38888889 0.56509695 0.53846154 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 71/300, Loss: 0.2062, Accuracy: 0.9133, F1: 0.5952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94180448 0.72929293 0.73743017 0.16393443 0.16907216 0.06918239\n",
      " 0.12072435 0.23765996 0.23326134 0.64397496 0.67193309 0.48217822\n",
      " 0.56404544 0.35125858 0.11548556 0.64600715 0.76096618 0.76426265\n",
      " 0.73747054 0.64762827 0.84234892 0.53715968 0.7288739  0.2393968\n",
      " 0.26179018 0.42885772 0.480413   0.99113375 0.9305053  0.94915053]\n",
      "Training Epoch 72/300, Loss: 0.2519, Accuracy: 0.8801, F1: 0.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95849793 0.90026954 0.83573487 0.22857143 0.30555556 0.08695652\n",
      " 0.06976744 0.13888889 0.15625    0.82213439 0.76426799 0.55774648\n",
      " 0.63217098 0.48031496 0.19354839 0.83615819 0.86643234 0.88467615\n",
      " 0.85689201 0.68085106 0.85265767 0.6147541  0.80345572 0.3452381\n",
      " 0.42553191 0.55102041 0.55008489 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 72/300, Loss: 0.2023, Accuracy: 0.9145, F1: 0.6132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94207341 0.71232877 0.72653681 0.17509728 0.16764133 0.10650888\n",
      " 0.12       0.23836127 0.29680365 0.66074875 0.69580892 0.48027613\n",
      " 0.5836201  0.34869976 0.13471503 0.63111111 0.73633003 0.76935441\n",
      " 0.7396662  0.63341404 0.84738064 0.54927536 0.71237337 0.23495146\n",
      " 0.2560154  0.42189282 0.46887102 0.99158186 0.92883428 0.94744335]\n",
      "Training Epoch 73/300, Loss: 0.2510, Accuracy: 0.8797, F1: 0.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9603649  0.89315068 0.83483483 0.13333333 0.19230769 0.22641509\n",
      " 0.2037037  0.14084507 0.16129032 0.82608696 0.76190476 0.58695652\n",
      " 0.62593783 0.44715447 0.13114754 0.83487941 0.85402685 0.88509317\n",
      " 0.85714286 0.68632708 0.85845737 0.62745098 0.77677678 0.27027027\n",
      " 0.35443038 0.57142857 0.55131965 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 73/300, Loss: 0.2020, Accuracy: 0.9139, F1: 0.6084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94082541 0.71703854 0.72699542 0.176      0.13806706 0.07692308\n",
      " 0.0995671  0.20809249 0.24884793 0.         0.66097087 0.67707855\n",
      " 0.4774323  0.57241857 0.3451895  0.12938005 0.65361566 0.75628627\n",
      " 0.76422334 0.74846626 0.61612747 0.83345188 0.55192447 0.74137616\n",
      " 0.23728814 0.26824458 0.4234957  0.47306651 0.99126391 0.92658891\n",
      " 0.94873012]\n",
      "Training Epoch 74/300, Loss: 0.2526, Accuracy: 0.8795, F1: 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95519146 0.88202247 0.81574803 0.15873016 0.23333333 0.08888889\n",
      " 0.09638554 0.02985075 0.03508772 0.80952381 0.77581864 0.56534954\n",
      " 0.65019506 0.5112782  0.19354839 0.82954545 0.86684073 0.89206349\n",
      " 0.86010363 0.67217631 0.85260116 0.60728745 0.80127524 0.33548387\n",
      " 0.41142857 0.54570637 0.55345912 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 74/300, Loss: 0.2082, Accuracy: 0.9129, F1: 0.6009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94248163 0.72340426 0.73046875 0.15353535 0.1547619  0.05538462\n",
      " 0.06625259 0.25185185 0.29824561 0.67077872 0.71334214 0.48708861\n",
      " 0.57780816 0.36206897 0.16377171 0.66306862 0.74896187 0.7639327\n",
      " 0.73757333 0.64594463 0.83813836 0.5484598  0.72063552 0.25120773\n",
      " 0.28982726 0.44444444 0.49239033 0.99119718 0.93256815 0.95226745]\n",
      "Training Epoch 75/300, Loss: 0.2517, Accuracy: 0.8811, F1: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95977272 0.89373297 0.8452381  0.21917808 0.27848101 0.04545455\n",
      " 0.04938272 0.08695652 0.10169492 0.83070866 0.77261614 0.55131965\n",
      " 0.63170732 0.464      0.19354839 0.83738318 0.85714286 0.88854489\n",
      " 0.86054422 0.67904509 0.85760171 0.62450593 0.79214064 0.31372549\n",
      " 0.37267081 0.55221745 0.55284553 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 75/300, Loss: 0.2034, Accuracy: 0.9152, F1: 0.6037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94291664 0.72312373 0.72979673 0.17283951 0.16977226 0.1097561\n",
      " 0.13518887 0.21400778 0.25700935 0.66666667 0.70123023 0.47916667\n",
      " 0.57798165 0.35205559 0.16377171 0.64259635 0.72309505 0.77709062\n",
      " 0.74815397 0.64134188 0.84241096 0.53868613 0.7275018  0.29104478\n",
      " 0.33930254 0.44671202 0.49970042 0.99119608 0.93120439 0.95009506]\n",
      "Training Epoch 76/300, Loss: 0.2519, Accuracy: 0.8820, F1: 0.5495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95903787 0.88767123 0.83987915 0.10169492 0.15686275 0.125\n",
      " 0.08791209 0.14084507 0.09836066 0.83203125 0.78109453 0.55457227\n",
      " 0.64009662 0.464      0.19354839 0.82264151 0.86036427 0.88714734\n",
      " 0.85763001 0.67741935 0.86180692 0.61016949 0.80721533 0.26027397\n",
      " 0.35761589 0.55927835 0.5315204  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 76/300, Loss: 0.2022, Accuracy: 0.9140, F1: 0.5985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94329292 0.72598584 0.73786893 0.15448852 0.17635271 0.06269592\n",
      " 0.09756098 0.18540434 0.23076923 0.         0.66743649 0.6926873\n",
      " 0.49022556 0.59204096 0.32330383 0.12953368 0.64680175 0.75028681\n",
      " 0.76620931 0.74395674 0.64019139 0.8490311  0.54572056 0.7112101\n",
      " 0.27981221 0.32233742 0.45421451 0.50058685 0.99246326 0.93532897\n",
      " 0.95525954]\n",
      "Training Epoch 77/300, Loss: 0.2479, Accuracy: 0.8828, F1: 0.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96027493 0.90217391 0.84963504 0.15873016 0.23333333 0.16666667\n",
      " 0.13483146 0.11267606 0.16129032 0.82142857 0.75       0.55828221\n",
      " 0.64160401 0.4921875  0.21875    0.85352622 0.8548124  0.89028213\n",
      " 0.85987815 0.67171717 0.85036962 0.6031746  0.77432712 0.27536232\n",
      " 0.37410072 0.57335128 0.5514158  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 77/300, Loss: 0.2033, Accuracy: 0.9146, F1: 0.6097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94262233 0.71517672 0.73090723 0.15324165 0.14653465 0.11550152\n",
      " 0.14       0.20332717 0.19679634 0.66485437 0.69553451 0.49721519\n",
      " 0.57380952 0.37270642 0.16385542 0.64670659 0.75742863 0.79032687\n",
      " 0.76103692 0.65596107 0.85399533 0.52936911 0.72682324 0.27073403\n",
      " 0.31364956 0.46638298 0.50044789 0.99138636 0.93315041 0.95221091]\n",
      "Training Epoch 78/300, Loss: 0.2485, Accuracy: 0.8837, F1: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96048065 0.89247312 0.85955056 0.23529412 0.32352941 0.16666667\n",
      " 0.13483146 0.13513514 0.15151515 0.81908549 0.76213592 0.57777778\n",
      " 0.63963964 0.4743083  0.19047619 0.83206107 0.85866667 0.89622642\n",
      " 0.86406926 0.67352185 0.84985688 0.58974359 0.7912844  0.2987013\n",
      " 0.36585366 0.57692308 0.53605016 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 78/300, Loss: 0.2006, Accuracy: 0.9152, F1: 0.6151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94332303 0.72004028 0.74697007 0.14084507 0.15594542 0.13253012\n",
      " 0.14198783 0.29616088 0.31372549 0.6410055  0.70769231 0.48262165\n",
      " 0.57727167 0.37203928 0.14609572 0.65306122 0.76017931 0.77026302\n",
      " 0.75623921 0.64487805 0.83979132 0.54558611 0.73629604 0.26654064\n",
      " 0.30566038 0.44598099 0.49109031 0.99094681 0.93810831 0.95636581]\n",
      "Training Epoch 79/300, Loss: 0.2460, Accuracy: 0.8832, F1: 0.5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95968417 0.89839572 0.85955056 0.15873016 0.24137931 0.20408163\n",
      " 0.19565217 0.11267606 0.16129032 0.83820663 0.77749361 0.58139535\n",
      " 0.65248227 0.48627451 0.19672131 0.83520599 0.86463621 0.88958009\n",
      " 0.85641461 0.67362924 0.85001313 0.61666667 0.78774617 0.28965517\n",
      " 0.37086093 0.56424581 0.54631083 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 79/300, Loss: 0.2026, Accuracy: 0.9157, F1: 0.6156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94220987 0.72542028 0.73896595 0.15261044 0.14829659 0.0875\n",
      " 0.11864407 0.25235405 0.28637413 0.64766429 0.68258179 0.4847591\n",
      " 0.56433824 0.36171397 0.15665796 0.64554932 0.74228425 0.77000798\n",
      " 0.74544013 0.65053243 0.84266586 0.55097614 0.73431193 0.26666667\n",
      " 0.31779258 0.45346198 0.49650986 0.99138852 0.93345806 0.95386266]\n",
      "Training Epoch 80/300, Loss: 0.2496, Accuracy: 0.8816, F1: 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95138093 0.89863014 0.83586626 0.1        0.15384615 0.125\n",
      " 0.08988764 0.03030303 0.03636364 0.81584158 0.78933333 0.58959538\n",
      " 0.66176471 0.51685393 0.13559322 0.81081081 0.85350318 0.8802589\n",
      " 0.83482944 0.67621777 0.83307904 0.59030837 0.78672986 0.1875\n",
      " 0.25396825 0.54347826 0.55098935 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 80/300, Loss: 0.2119, Accuracy: 0.9092, F1: 0.5843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94272662 0.72919818 0.73420857 0.17142857 0.17731959 0.08860759\n",
      " 0.10505051 0.24074074 0.25168539 0.64215105 0.68213457 0.49435998\n",
      " 0.5817617  0.36373448 0.20235294 0.629659   0.73964724 0.76923077\n",
      " 0.7456546  0.64666021 0.83609614 0.53731343 0.71170349 0.26418787\n",
      " 0.3234714  0.45104196 0.48752969 0.99158503 0.9377495  0.95713088]\n",
      "Training Epoch 81/300, Loss: 0.2489, Accuracy: 0.8811, F1: 0.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96087705 0.89361702 0.84689655 0.24615385 0.34482759 0.14814815\n",
      " 0.1512605  0.13888889 0.21538462 0.82235529 0.74941452 0.62222222\n",
      " 0.6557377  0.44444444 0.25       0.85343228 0.86491079 0.884375\n",
      " 0.85666667 0.69430052 0.85973555 0.6255144  0.7816092  0.19259259\n",
      " 0.27338129 0.59322034 0.5323741  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 81/300, Loss: 0.2045, Accuracy: 0.9139, F1: 0.6167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94227999 0.70756646 0.7327131  0.17479675 0.16666667 0.0875\n",
      " 0.08997955 0.27949183 0.2557652  0.64223798 0.68702966 0.49527598\n",
      " 0.58798486 0.3700831  0.16230366 0.63858805 0.75642787 0.77359491\n",
      " 0.74500476 0.65004794 0.84425694 0.5258427  0.72486772 0.30085147\n",
      " 0.33238905 0.43764302 0.47819549 0.9916431  0.92834425 0.95054096]\n",
      "Training Epoch 82/300, Loss: 0.2490, Accuracy: 0.8815, F1: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95607235 0.87368421 0.82419128 0.19047619 0.30508475 0.17021277\n",
      " 0.13793103 0.08333333 0.09230769 0.83464567 0.77805486 0.58928571\n",
      " 0.66749073 0.50735294 0.18181818 0.82466281 0.85294118 0.88535032\n",
      " 0.85214348 0.67716535 0.84741217 0.59574468 0.79026651 0.37125749\n",
      " 0.45054945 0.50381679 0.51943463 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 82/300, Loss: 0.2069, Accuracy: 0.9127, F1: 0.6120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94278162 0.69720102 0.71715918 0.14736842 0.12970711 0.08459215\n",
      " 0.13465347 0.27573529 0.27853881 0.66047232 0.70243463 0.47855297\n",
      " 0.57640879 0.35044248 0.16103896 0.64420063 0.75946933 0.77190171\n",
      " 0.74980092 0.64908917 0.84712185 0.55817378 0.72576277 0.29007634\n",
      " 0.32195122 0.45385694 0.48927294 0.9922763  0.92951597 0.95102065]\n",
      "Training Epoch 83/300, Loss: 0.2469, Accuracy: 0.8826, F1: 0.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95832041 0.899729   0.84028777 0.16129032 0.27586207 0.23529412\n",
      " 0.22916667 0.13513514 0.12121212 0.816      0.77419355 0.58333333\n",
      " 0.6251298  0.44354839 0.13333333 0.83773585 0.859375   0.89859594\n",
      " 0.85883347 0.67546174 0.86090226 0.60944206 0.80817253 0.26470588\n",
      " 0.34074074 0.53958944 0.52436975 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 83/300, Loss: 0.2059, Accuracy: 0.9143, F1: 0.6103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94416444 0.72810591 0.74364191 0.17821782 0.16833667 0.13450292\n",
      " 0.15929204 0.28624535 0.29698376 0.66793893 0.71216884 0.476\n",
      " 0.57195829 0.34710744 0.16230366 0.65558195 0.75906835 0.78556263\n",
      " 0.76015686 0.65596107 0.85370314 0.55217391 0.72998073 0.29059829\n",
      " 0.33646617 0.4725306  0.51672092 0.99290602 0.93280928 0.95309613]\n",
      "Training Epoch 84/300, Loss: 0.2471, Accuracy: 0.8851, F1: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9582448  0.89238845 0.84583902 0.23880597 0.33846154 0.28571429\n",
      " 0.33082707 0.18421053 0.14705882 0.81927711 0.76328502 0.58789625\n",
      " 0.65339578 0.50965251 0.21875    0.8038835  0.848      0.86862442\n",
      " 0.82930631 0.70165746 0.85484335 0.62745098 0.78651685 0.36363636\n",
      " 0.43386243 0.57102672 0.56716418 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 84/300, Loss: 0.2013, Accuracy: 0.9137, F1: 0.6343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.943372   0.73309965 0.74374374 0.17213115 0.19472617 0.1257485\n",
      " 0.12550607 0.24814815 0.27555556 0.66743649 0.69615728 0.50704225\n",
      " 0.59667992 0.37336369 0.14851485 0.64100486 0.75454013 0.7700053\n",
      " 0.74066002 0.67184466 0.85075541 0.55266955 0.74199823 0.32363636\n",
      " 0.37096774 0.4533107  0.48958648 0.99259259 0.92929293 0.94927107]\n",
      "Training Epoch 85/300, Loss: 0.2456, Accuracy: 0.8839, F1: 0.5594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95750291 0.90860215 0.85298399 0.19047619 0.28571429 0.24\n",
      " 0.23913043 0.1369863  0.0952381  0.82745098 0.77372263 0.57817109\n",
      " 0.66750314 0.50574713 0.13793103 0.84171322 0.86672399 0.88235294\n",
      " 0.86101695 0.69189189 0.85666759 0.61538462 0.80694143 0.28571429\n",
      " 0.38297872 0.53846154 0.53565769 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 85/300, Loss: 0.2017, Accuracy: 0.9156, F1: 0.6187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94379143 0.72211155 0.74418605 0.18106996 0.18989899 0.09876543\n",
      " 0.13752456 0.29867675 0.32183908 0.         0.64796523 0.69879518\n",
      " 0.4955045  0.58817967 0.38600328 0.16751269 0.68730408 0.77129187\n",
      " 0.78529568 0.76784015 0.6557377  0.84979579 0.56034483 0.73432836\n",
      " 0.30929791 0.36241611 0.44350759 0.48571429 0.99328606 0.92580122\n",
      " 0.94622893]\n",
      "Training Epoch 86/300, Loss: 0.2444, Accuracy: 0.8842, F1: 0.5452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96144619 0.89066667 0.84582744 0.21875    0.33333333 0.12765957\n",
      " 0.09195402 0.18918919 0.20895522 0.81362725 0.75742574 0.592\n",
      " 0.61618257 0.42105263 0.16393443 0.85662432 0.86048454 0.88235294\n",
      " 0.85326548 0.70801034 0.85877466 0.63076923 0.78543307 0.34355828\n",
      " 0.4137931  0.57446809 0.54864865 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 86/300, Loss: 0.2024, Accuracy: 0.9142, F1: 0.6182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94269404 0.72699069 0.7305726  0.164      0.17751479 0.0872093\n",
      " 0.12035398 0.27188082 0.25617978 0.65351895 0.69237589 0.50664043\n",
      " 0.58601048 0.35534775 0.16931217 0.65582871 0.75283708 0.77242481\n",
      " 0.75125628 0.64851726 0.84118004 0.53724928 0.72824771 0.28434198\n",
      " 0.32818533 0.45116681 0.50165215 0.99360261 0.9373246  0.95641256]\n",
      "Training Epoch 87/300, Loss: 0.2465, Accuracy: 0.8829, F1: 0.5527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95920407 0.88709677 0.83381089 0.19047619 0.28571429 0.08695652\n",
      " 0.04705882 0.16438356 0.15625    0.8359375  0.785      0.6017192\n",
      " 0.66903915 0.4921875  0.19047619 0.84528302 0.87165775 0.88679245\n",
      " 0.86523605 0.7107438  0.86323064 0.62857143 0.81425486 0.2875817\n",
      " 0.35087719 0.56657963 0.53696498 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 87/300, Loss: 0.2007, Accuracy: 0.9161, F1: 0.6137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94535799 0.73621461 0.74717722 0.17373737 0.16901408 0.13411079\n",
      " 0.19101124 0.29963899 0.32786885 0.66564535 0.70833333 0.4941654\n",
      " 0.58862876 0.3788996  0.17955112 0.65795724 0.77474337 0.79421053\n",
      " 0.76700968 0.63715953 0.85119561 0.56074766 0.74927326 0.29166667\n",
      " 0.32952381 0.46506365 0.5177818  0.99195778 0.93776503 0.95730283]\n",
      "Training Epoch 88/300, Loss: 0.2421, Accuracy: 0.8876, F1: 0.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95973138 0.9        0.84210526 0.1875     0.29032258 0.20408163\n",
      " 0.19565217 0.16       0.14925373 0.828125   0.76442308 0.59942363\n",
      " 0.67228916 0.5037594  0.16393443 0.83175803 0.86585366 0.89130435\n",
      " 0.86125212 0.68783069 0.85830619 0.62240664 0.81359649 0.32894737\n",
      " 0.4125     0.56100982 0.55379747 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 88/300, Loss: 0.1993, Accuracy: 0.9171, F1: 0.6236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94483488 0.73366834 0.73794654 0.20392157 0.18595825 0.09259259\n",
      " 0.09341826 0.25138632 0.26222222 0.64571207 0.67639015 0.50849151\n",
      " 0.61290323 0.38324022 0.1563981  0.65401344 0.77724757 0.78376227\n",
      " 0.76175598 0.66346154 0.84682139 0.55759354 0.73983447 0.28704567\n",
      " 0.30483271 0.45931386 0.50614693 0.99196182 0.93757406 0.9562201 ]\n",
      "Training Epoch 89/300, Loss: 0.2434, Accuracy: 0.8858, F1: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95728321 0.90163934 0.83832335 0.16129032 0.25454545 0.19230769\n",
      " 0.23076923 0.16216216 0.15384615 0.80722892 0.76772616 0.6039886\n",
      " 0.6729634  0.49618321 0.16393443 0.83553875 0.869869   0.89481947\n",
      " 0.86156492 0.6866485  0.87027637 0.60251046 0.82039911 0.30555556\n",
      " 0.36942675 0.55524862 0.55076923 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 89/300, Loss: 0.2020, Accuracy: 0.9164, F1: 0.6195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94375181 0.73547094 0.75505618 0.14457831 0.11717172 0.11111111\n",
      " 0.0960334  0.27472527 0.2972973  0.65742574 0.72559367 0.51785714\n",
      " 0.59297184 0.3701263  0.14775726 0.66004766 0.76661574 0.76919019\n",
      " 0.75954496 0.68802366 0.86068683 0.56022808 0.75168499 0.27606178\n",
      " 0.31330049 0.46114432 0.50194903 0.99284369 0.92908376 0.95029727]\n",
      "Training Epoch 90/300, Loss: 0.2419, Accuracy: 0.8861, F1: 0.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95904453 0.89182058 0.84195804 0.21538462 0.32786885 0.13043478\n",
      " 0.0952381  0.20512821 0.21917808 0.82376238 0.77641278 0.60818713\n",
      " 0.67692308 0.50566038 0.19354839 0.85027726 0.86993243 0.88682171\n",
      " 0.86744966 0.68834688 0.87307369 0.62295082 0.81209503 0.34666667\n",
      " 0.4        0.55211268 0.54573643 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 90/300, Loss: 0.1993, Accuracy: 0.9177, F1: 0.6261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94453676 0.75916749 0.76881322 0.14403292 0.13926499 0.14634146\n",
      " 0.21465077 0.24632353 0.23027719 0.66666667 0.68121874 0.51482213\n",
      " 0.59309066 0.36342321 0.205      0.66560636 0.77128483 0.77497371\n",
      " 0.7553979  0.66537342 0.85566067 0.55182482 0.71895672 0.32368897\n",
      " 0.35850773 0.46956032 0.51029056 0.99227435 0.93221079 0.95061508]\n",
      "Training Epoch 91/300, Loss: 0.2400, Accuracy: 0.8862, F1: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96097001 0.89893617 0.85106383 0.26865672 0.38095238 0.16666667\n",
      " 0.19565217 0.16216216 0.15384615 0.82677165 0.76442308 0.62427746\n",
      " 0.67615658 0.50557621 0.26470588 0.85185185 0.85958904 0.88923557\n",
      " 0.86643836 0.69148936 0.8746888  0.63070539 0.81546961 0.36144578\n",
      " 0.41666667 0.58244681 0.56527977 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 91/300, Loss: 0.1966, Accuracy: 0.9190, F1: 0.6368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94430022 0.72377091 0.72989378 0.17928287 0.18473896 0.11515152\n",
      " 0.14861996 0.2754717  0.3245614  0.68204159 0.71010057 0.50148957\n",
      " 0.59711225 0.38370119 0.15189873 0.6563981  0.76453432 0.78187119\n",
      " 0.7588697  0.64457253 0.84294534 0.56058394 0.74057567 0.32052484\n",
      " 0.33555767 0.46013667 0.51193714 0.99284279 0.93662675 0.9551152 ]\n",
      "Training Epoch 92/300, Loss: 0.2391, Accuracy: 0.8856, F1: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95597722 0.89315068 0.84580153 0.16129032 0.25454545 0.24489796\n",
      " 0.22222222 0.20512821 0.25714286 0.8111332  0.79187817 0.57926829\n",
      " 0.65671642 0.52631579 0.21875    0.82551595 0.85789015 0.88819876\n",
      " 0.86177474 0.66838046 0.84123159 0.6        0.80407701 0.36129032\n",
      " 0.4625     0.51592357 0.49392713 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 92/300, Loss: 0.2079, Accuracy: 0.9144, F1: 0.6268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94269872 0.72800402 0.73095945 0.16733068 0.18461538 0.16528926\n",
      " 0.21694915 0.3003663  0.30237581 0.         0.66382649 0.69792606\n",
      " 0.48244734 0.56787808 0.35665138 0.14871795 0.66799522 0.7699334\n",
      " 0.77900844 0.75331979 0.63609756 0.84647938 0.51274581 0.71766445\n",
      " 0.30869972 0.36536632 0.44475841 0.48879594 0.99271906 0.93344976\n",
      " 0.95331783]\n",
      "Training Epoch 93/300, Loss: 0.2419, Accuracy: 0.8826, F1: 0.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96110572 0.88888889 0.84965517 0.18461538 0.26666667 0.27118644\n",
      " 0.30555556 0.2278481  0.28947368 0.81980198 0.75650118 0.625\n",
      " 0.63190184 0.46473029 0.19354839 0.83918669 0.86264657 0.88217523\n",
      " 0.84335443 0.68894602 0.86105372 0.625      0.79257642 0.36809816\n",
      " 0.45086705 0.57844475 0.55161787 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 93/300, Loss: 0.2011, Accuracy: 0.9150, F1: 0.6360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94471961 0.72141058 0.74361542 0.12863071 0.11740042 0.13690476\n",
      " 0.17786561 0.26666667 0.29464286 0.65239794 0.69364162 0.51151396\n",
      " 0.59858995 0.38885855 0.21800948 0.67422761 0.76511359 0.7862214\n",
      " 0.75998761 0.67217096 0.85513779 0.56531049 0.7451261  0.29934518\n",
      " 0.35150376 0.46527386 0.50748951 0.99252935 0.93638518 0.95596582]\n",
      "Training Epoch 94/300, Loss: 0.2415, Accuracy: 0.8867, F1: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96031498 0.89709763 0.85399449 0.16129032 0.25454545 0.12244898\n",
      " 0.1443299  0.16216216 0.15384615 0.82329317 0.75829384 0.63157895\n",
      " 0.66217733 0.49606299 0.18461538 0.85504587 0.86075949 0.89028213\n",
      " 0.86643836 0.70491803 0.86787126 0.6374502  0.79127726 0.27777778\n",
      " 0.34013605 0.58895706 0.555      0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 94/300, Loss: 0.1985, Accuracy: 0.9163, F1: 0.6167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9445787  0.75188727 0.75445197 0.17373737 0.18181818 0.12827988\n",
      " 0.18587361 0.32363636 0.31330472 0.65150347 0.68832952 0.52033317\n",
      " 0.61890315 0.37929029 0.16751269 0.66719368 0.76680304 0.78322785\n",
      " 0.75698587 0.67781604 0.86175684 0.60185847 0.76036618 0.3040153\n",
      " 0.35576923 0.46522235 0.51718984 0.9930342  0.93695042 0.95579978]\n",
      "Training Epoch 95/300, Loss: 0.2392, Accuracy: 0.8884, F1: 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95566479 0.8852459  0.83358321 0.21875    0.33333333 0.13043478\n",
      " 0.0952381  0.15789474 0.23188406 0.81746032 0.80102041 0.57060519\n",
      " 0.64500602 0.51320755 0.1875     0.81538462 0.84036697 0.8896\n",
      " 0.85664028 0.68478261 0.8637138  0.61603376 0.8143982  0.37908497\n",
      " 0.45882353 0.56066946 0.55799373 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 95/300, Loss: 0.2054, Accuracy: 0.9144, F1: 0.6238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9448848  0.71646341 0.74930713 0.16216216 0.14522822 0.14246575\n",
      " 0.1862069  0.29390681 0.31625835 0.66285714 0.68454545 0.50619118\n",
      " 0.60441347 0.37528868 0.15458937 0.66272656 0.75415473 0.79566482\n",
      " 0.76533501 0.65377176 0.85833249 0.56709957 0.73697773 0.31761309\n",
      " 0.37725118 0.4752755  0.51779359 0.99354029 0.93744153 0.95745827]\n",
      "Training Epoch 96/300, Loss: 0.2387, Accuracy: 0.8875, F1: 0.5672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95933914 0.88297872 0.84299859 0.25714286 0.41558442 0.24\n",
      " 0.21276596 0.20779221 0.27777778 0.81673307 0.76699029 0.61994609\n",
      " 0.66439135 0.50592885 0.16129032 0.84427767 0.86015831 0.88818898\n",
      " 0.86137751 0.69189189 0.86912468 0.61410788 0.81808159 0.35064935\n",
      " 0.44827586 0.58206897 0.55784469 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 96/300, Loss: 0.1984, Accuracy: 0.9179, F1: 0.6405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94545073 0.75249501 0.77205154 0.18913481 0.20229008 0.12426036\n",
      " 0.19272727 0.31910946 0.37802198 0.65585443 0.71292517 0.5109127\n",
      " 0.60424755 0.38592633 0.17721519 0.69032761 0.76444096 0.77305152\n",
      " 0.75228203 0.67119961 0.86128851 0.57243816 0.74125113 0.33863424\n",
      " 0.37348273 0.48762447 0.53050239 0.99347635 0.93295079 0.95293205]\n",
      "Training Epoch 97/300, Loss: 0.2371, Accuracy: 0.8886, F1: 0.5786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95926632 0.88126649 0.84180791 0.22222222 0.35714286 0.20833333\n",
      " 0.18181818 0.19753086 0.28571429 0.83365949 0.76960784 0.60410557\n",
      " 0.67896679 0.51320755 0.23188406 0.83798883 0.86101695 0.89028213\n",
      " 0.85714286 0.67894737 0.85854189 0.60425532 0.80229885 0.36363636\n",
      " 0.47777778 0.56093979 0.53793103 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 97/300, Loss: 0.1994, Accuracy: 0.9169, F1: 0.6365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94427576 0.72662961 0.73501658 0.19838057 0.21747573 0.12650602\n",
      " 0.16216216 0.30965392 0.29777778 0.66743119 0.69889135 0.52109181\n",
      " 0.60855416 0.36614853 0.16176471 0.65232975 0.76472868 0.7682991\n",
      " 0.75415437 0.67428571 0.85778894 0.55971223 0.72516982 0.32799246\n",
      " 0.37057728 0.4744898  0.51764706 0.99360181 0.92826846 0.94720626]\n",
      "Training Epoch 98/300, Loss: 0.2378, Accuracy: 0.8861, F1: 0.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96005543 0.88586957 0.82615156 0.13114754 0.22222222 0.16\n",
      " 0.12631579 0.17948718 0.17142857 0.82772277 0.79       0.60623229\n",
      " 0.66819747 0.49811321 0.21212121 0.85082873 0.8597973  0.88923077\n",
      " 0.86241611 0.69892473 0.86885706 0.62809917 0.82288229 0.34394904\n",
      " 0.42045455 0.57943925 0.56381487 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 98/300, Loss: 0.1976, Accuracy: 0.9172, F1: 0.6217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94555831 0.73556231 0.7581864  0.2        0.18563923 0.16326531\n",
      " 0.26739927 0.32072072 0.33189655 0.68104777 0.70941337 0.52041318\n",
      " 0.60618749 0.41355932 0.19069767 0.66666667 0.73942857 0.77313591\n",
      " 0.75278257 0.68911664 0.87067377 0.55157279 0.73451804 0.32618826\n",
      " 0.38297872 0.47694935 0.5198556  0.99423197 0.93576151 0.95483871]\n",
      "Training Epoch 99/300, Loss: 0.2358, Accuracy: 0.8889, F1: 0.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96052727 0.89893617 0.86357243 0.21875    0.31578947 0.125\n",
      " 0.08791209 0.16438356 0.15625    0.82164329 0.77669903 0.62631579\n",
      " 0.62839879 0.48221344 0.19047619 0.85608856 0.85886403 0.88854962\n",
      " 0.86737185 0.71428571 0.87241867 0.65873016 0.8        0.35\n",
      " 0.38674033 0.58453473 0.55302013 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 99/300, Loss: 0.1982, Accuracy: 0.9166, F1: 0.6235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94451527 0.74772957 0.75596421 0.16498994 0.18918919 0.1396648\n",
      " 0.21917808 0.34920635 0.36477987 0.67099237 0.70953237 0.51118846\n",
      " 0.60787992 0.39663866 0.19664269 0.67143994 0.76644081 0.78550493\n",
      " 0.7571406  0.6472332  0.84239186 0.57245337 0.73350649 0.34980989\n",
      " 0.3780135  0.4750634  0.50211225 0.99240188 0.93126248 0.95054096]\n",
      "Training Epoch 100/300, Loss: 0.2368, Accuracy: 0.8862, F1: 0.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95886572 0.88533333 0.83544304 0.23529412 0.4109589  0.26923077\n",
      " 0.31067961 0.20779221 0.28169014 0.8247012  0.76997579 0.62295082\n",
      " 0.66819222 0.5204461  0.22222222 0.83773585 0.85198556 0.88503937\n",
      " 0.86132644 0.70555556 0.85604946 0.62348178 0.81168831 0.39520958\n",
      " 0.45360825 0.59945504 0.58582677 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 100/300, Loss: 0.1971, Accuracy: 0.9172, F1: 0.6496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94576762 0.72911392 0.7629332  0.13580247 0.15057915 0.14857143\n",
      " 0.17843866 0.29032258 0.35443038 0.66718028 0.70246085 0.51844565\n",
      " 0.61250293 0.40914286 0.18666667 0.68108533 0.76958175 0.80359029\n",
      " 0.77252816 0.67217096 0.86002857 0.55954089 0.7361575  0.35672515\n",
      " 0.41788144 0.48423423 0.52956752 0.99309739 0.92815268 0.95003861]\n",
      "Training Epoch 101/300, Loss: 0.2343, Accuracy: 0.8890, F1: 0.5769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95859994 0.89008043 0.83918129 0.20895522 0.3943662  0.33962264\n",
      " 0.45045045 0.28235294 0.32098765 0.82840237 0.76738609 0.61346633\n",
      " 0.6252505  0.48648649 0.16393443 0.85451197 0.85542169 0.89028213\n",
      " 0.86911891 0.69209809 0.86095346 0.62903226 0.78986272 0.47311828\n",
      " 0.50909091 0.52365931 0.52190476 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 101/300, Loss: 0.2019, Accuracy: 0.9155, F1: 0.6546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94693181 0.75591344 0.76317781 0.16699029 0.19734345 0.12429379\n",
      " 0.2047532  0.36298932 0.360587   0.67224335 0.69986661 0.54177215\n",
      " 0.63783784 0.3988604  0.20833333 0.68660194 0.77056444 0.79320414\n",
      " 0.75994385 0.67084942 0.86610793 0.57532281 0.75973107 0.36578708\n",
      " 0.38560886 0.48084398 0.52842415 0.99385349 0.93076347 0.95145747]\n",
      "Training Epoch 102/300, Loss: 0.2346, Accuracy: 0.8911, F1: 0.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96194686 0.88654354 0.85041551 0.28169014 0.44155844 0.30188679\n",
      " 0.38938053 0.25882353 0.31707317 0.81746032 0.76076555 0.63687151\n",
      " 0.67812142 0.53183521 0.30555556 0.86956522 0.86473029 0.89580093\n",
      " 0.86792453 0.70496084 0.86638161 0.61538462 0.79368421 0.40236686\n",
      " 0.50549451 0.57979502 0.57335582 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 102/300, Loss: 0.1964, Accuracy: 0.9202, F1: 0.6653\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94634412 0.7513702  0.75257991 0.16633663 0.19593346 0.15116279\n",
      " 0.18761726 0.33333333 0.33596838 0.68042813 0.71572212 0.54935194\n",
      " 0.63686088 0.41904762 0.22377622 0.66268894 0.76523791 0.79176564\n",
      " 0.77245041 0.67627281 0.8706276  0.58064516 0.75241277 0.31784387\n",
      " 0.35501859 0.4663626  0.50884028 0.99448345 0.93992139 0.95718819]\n",
      "Training Epoch 103/300, Loss: 0.2332, Accuracy: 0.8915, F1: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95771911 0.89373297 0.84638554 0.21212121 0.3125     0.30769231\n",
      " 0.35514019 0.2        0.26315789 0.82677165 0.78802993 0.62809917\n",
      " 0.66055046 0.51587302 0.1875     0.84758364 0.85459411 0.89099526\n",
      " 0.86742757 0.6972973  0.8557555  0.62857143 0.82011173 0.3625\n",
      " 0.42696629 0.56069364 0.56443719 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 103/300, Loss: 0.2010, Accuracy: 0.9169, F1: 0.6443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94643239 0.75941738 0.77050414 0.1640625  0.23172906 0.15882353\n",
      " 0.24952741 0.36173913 0.34661355 0.66793748 0.69275753 0.54938575\n",
      " 0.63102097 0.38365494 0.21957041 0.65241489 0.76809911 0.79863481\n",
      " 0.78115739 0.66374696 0.86090072 0.59580622 0.74725275 0.34572491\n",
      " 0.36923077 0.48293089 0.52211622 0.99372805 0.93113772 0.95318185]\n",
      "Training Epoch 104/300, Loss: 0.2334, Accuracy: 0.8904, F1: 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96147412 0.8847185  0.83573487 0.28985507 0.3880597  0.2962963\n",
      " 0.36363636 0.20779221 0.27777778 0.83300589 0.78606965 0.63509749\n",
      " 0.68197474 0.5177305  0.28571429 0.84870849 0.85520745 0.89130435\n",
      " 0.86564626 0.69892473 0.86941775 0.6302521  0.81655481 0.37267081\n",
      " 0.43820225 0.59517426 0.59150805 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 104/300, Loss: 0.1956, Accuracy: 0.9200, F1: 0.6572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94702891 0.74974671 0.76449823 0.18323587 0.20522388 0.21052632\n",
      " 0.23134328 0.36173913 0.40236686 0.67148839 0.70489634 0.54201068\n",
      " 0.62204724 0.41666667 0.23671498 0.67266328 0.77004941 0.78834034\n",
      " 0.76720489 0.66699219 0.86245582 0.54676259 0.73562798 0.36312849\n",
      " 0.4180791  0.51061453 0.54130885 0.99195576 0.93463074 0.95403875]\n",
      "Training Epoch 105/300, Loss: 0.2331, Accuracy: 0.8908, F1: 0.5924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96042669 0.89182058 0.84539007 0.1875     0.27118644 0.26415094\n",
      " 0.29906542 0.18666667 0.23880597 0.82703777 0.78217822 0.62322946\n",
      " 0.67768595 0.51937984 0.21538462 0.86029412 0.86626402 0.89302326\n",
      " 0.86993971 0.70391061 0.8646136  0.62948207 0.80167891 0.375\n",
      " 0.42222222 0.592      0.57185185 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 105/300, Loss: 0.1954, Accuracy: 0.9189, F1: 0.6413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94720935 0.74987469 0.7629278  0.15757576 0.176      0.15384615\n",
      " 0.24100719 0.34119782 0.30196937 0.68009119 0.70510563 0.5336008\n",
      " 0.63128749 0.3877203  0.20902613 0.66928824 0.76076463 0.78184713\n",
      " 0.76942474 0.67182962 0.86888076 0.60129776 0.75480681 0.37294333\n",
      " 0.44007156 0.4768063  0.51568569 0.99322204 0.93550399 0.95651134]\n",
      "Training Epoch 106/300, Loss: 0.2320, Accuracy: 0.8916, F1: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96086209 0.89544236 0.85755814 0.21875    0.31578947 0.16326531\n",
      " 0.18556701 0.27160494 0.26666667 0.83137255 0.76811594 0.61994609\n",
      " 0.66742338 0.49372385 0.2        0.85501859 0.85508551 0.90171607\n",
      " 0.875      0.72131148 0.86991176 0.632      0.78488982 0.4047619\n",
      " 0.44791667 0.59895833 0.55978261 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 106/300, Loss: 0.1966, Accuracy: 0.9186, F1: 0.6407\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94662711 0.73572511 0.75916749 0.19066148 0.20729367 0.1920904\n",
      " 0.28822496 0.32212389 0.3326226  0.69325153 0.7116451  0.52567976\n",
      " 0.61733615 0.42105263 0.21800948 0.67687475 0.76490958 0.78192328\n",
      " 0.75939966 0.68337349 0.86329844 0.58393113 0.74949827 0.34733894\n",
      " 0.40260951 0.48173131 0.53521957 0.99353786 0.93838863 0.95724451]\n",
      "Training Epoch 107/300, Loss: 0.2316, Accuracy: 0.8909, F1: 0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96130668 0.88770053 0.84028777 0.28985507 0.3880597  0.2\n",
      " 0.2244898  0.25       0.24657534 0.8247012  0.78908189 0.64088398\n",
      " 0.6766055  0.50769231 0.16129032 0.85137615 0.86333333 0.89060092\n",
      " 0.8680203  0.70391061 0.86475529 0.6459144  0.78427419 0.37804878\n",
      " 0.44198895 0.59109312 0.58028169 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 107/300, Loss: 0.1967, Accuracy: 0.9185, F1: 0.6450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94604729 0.73746898 0.757087   0.18604651 0.20900901 0.15882353\n",
      " 0.16135084 0.30236794 0.29805616 0.67394696 0.72943247 0.53914767\n",
      " 0.63399907 0.40374037 0.22897196 0.64807541 0.76550388 0.78548896\n",
      " 0.7605198  0.68624572 0.86927637 0.55251799 0.72497209 0.34733894\n",
      " 0.41334569 0.49099099 0.52471709 0.99341156 0.93151198 0.9523923 ]\n",
      "Training Epoch 108/300, Loss: 0.2307, Accuracy: 0.8896, F1: 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96040358 0.89008043 0.83936324 0.28985507 0.45070423 0.2\n",
      " 0.2244898  0.16       0.20895522 0.83003953 0.79187817 0.63865546\n",
      " 0.68009479 0.52307692 0.19672131 0.86238532 0.86254296 0.89269051\n",
      " 0.87192536 0.69832402 0.85689098 0.63709677 0.8111588  0.32467532\n",
      " 0.38823529 0.60077022 0.57142857 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 108/300, Loss: 0.1969, Accuracy: 0.9185, F1: 0.6420\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94744178 0.73541247 0.75758335 0.22970297 0.20715631 0.17699115\n",
      " 0.26037736 0.30985915 0.34836066 0.66484161 0.70993733 0.54439024\n",
      " 0.63356009 0.4178783  0.21428571 0.67504912 0.78012279 0.79142403\n",
      " 0.77913534 0.6627451  0.87006571 0.58865757 0.75887574 0.31379962\n",
      " 0.3646833  0.4860179  0.5240928  0.99379194 0.9359526  0.95567503]\n",
      "Training Epoch 109/300, Loss: 0.2315, Accuracy: 0.8923, F1: 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96043097 0.88654354 0.84571429 0.21212121 0.29508197 0.25925926\n",
      " 0.27826087 0.20253165 0.26666667 0.81763527 0.78132678 0.62643678\n",
      " 0.68536585 0.53076923 0.19672131 0.85082873 0.86531987 0.88509317\n",
      " 0.85981308 0.70810811 0.86790332 0.63967611 0.81276596 0.35220126\n",
      " 0.41142857 0.57746479 0.56369427 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 109/300, Loss: 0.1984, Accuracy: 0.9191, F1: 0.6412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94696932 0.7548677  0.76386139 0.1703854  0.16666667 0.15384615\n",
      " 0.21886792 0.34690265 0.35802469 0.67138922 0.71953405 0.52815147\n",
      " 0.63062223 0.39541234 0.15158924 0.671875   0.76723315 0.7843034\n",
      " 0.76966825 0.67449829 0.87078046 0.57000711 0.74743104 0.33976125\n",
      " 0.39219331 0.48740907 0.53727879 0.99498872 0.93244339 0.95251713]\n",
      "Training Epoch 110/300, Loss: 0.2322, Accuracy: 0.8913, F1: 0.5823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96240893 0.8806366  0.84582744 0.23880597 0.32258065 0.31034483\n",
      " 0.44117647 0.34090909 0.35555556 0.82772277 0.78325123 0.62146893\n",
      " 0.65581395 0.52140078 0.30136986 0.8381295  0.84609186 0.87841945\n",
      " 0.85214626 0.69172932 0.85582586 0.65612648 0.81875    0.45026178\n",
      " 0.5        0.56547619 0.54937163 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 110/300, Loss: 0.1990, Accuracy: 0.9180, F1: 0.6637\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94721756 0.7403599  0.74765882 0.17726397 0.20530973 0.16477273\n",
      " 0.23616236 0.26865672 0.25454545 0.65593087 0.69604317 0.52330827\n",
      " 0.62371134 0.40280778 0.2200489  0.67270579 0.76845573 0.79884454\n",
      " 0.7675     0.68892114 0.8782983  0.59814418 0.76697504 0.34269663\n",
      " 0.37258687 0.48822388 0.52878966 0.99341238 0.93624454 0.95401133]\n",
      "Training Epoch 111/300, Loss: 0.2320, Accuracy: 0.8915, F1: 0.5807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96019116 0.89247312 0.84179971 0.23188406 0.30985915 0.20408163\n",
      " 0.1978022  0.24390244 0.33333333 0.81656805 0.75829384 0.65945946\n",
      " 0.69061414 0.51538462 0.16666667 0.8440367  0.85548173 0.88923077\n",
      " 0.85525227 0.70053476 0.875      0.63598326 0.81725312 0.43274854\n",
      " 0.49494949 0.59634318 0.57       0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 111/300, Loss: 0.1973, Accuracy: 0.9196, F1: 0.6462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94799316 0.73148615 0.758      0.19569472 0.22627737 0.22096317\n",
      " 0.28469751 0.30769231 0.33196721 0.66796723 0.70260393 0.54217455\n",
      " 0.62782728 0.39311494 0.17811705 0.68100078 0.78593509 0.78441695\n",
      " 0.76896389 0.67250608 0.87204131 0.57571429 0.74406239 0.35489834\n",
      " 0.39069767 0.50359315 0.54435831 0.99322459 0.93631884 0.95564854]\n",
      "Training Epoch 112/300, Loss: 0.2298, Accuracy: 0.8922, F1: 0.5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96353176 0.8994709  0.86158192 0.1875     0.27118644 0.24561404\n",
      " 0.27118644 0.27160494 0.33333333 0.82306163 0.75714286 0.64623955\n",
      " 0.67118644 0.504      0.21212121 0.85714286 0.86284722 0.89751553\n",
      " 0.87352445 0.70833333 0.87384949 0.63636364 0.81619256 0.39520958\n",
      " 0.42622951 0.62238622 0.57417582 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 112/300, Loss: 0.1945, Accuracy: 0.9210, F1: 0.6487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94672375 0.74136229 0.7608378  0.15537849 0.17288802 0.16860465\n",
      " 0.22745098 0.31956912 0.31896552 0.68130204 0.70982143 0.54933069\n",
      " 0.63767442 0.40203275 0.19306931 0.6648265  0.77027289 0.77994723\n",
      " 0.76290932 0.69735553 0.87142489 0.57995736 0.74898284 0.35700935\n",
      " 0.39962652 0.49026155 0.52772013 0.99353948 0.93700886 0.95653214]\n",
      "Training Epoch 113/300, Loss: 0.2264, Accuracy: 0.8917, F1: 0.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9611326  0.896      0.85014409 0.1        0.18867925 0.18518519\n",
      " 0.20754717 0.24096386 0.28947368 0.82703777 0.76699029 0.65608466\n",
      " 0.67982456 0.52       0.16666667 0.85397412 0.86387435 0.890625\n",
      " 0.86724138 0.71978022 0.87672018 0.64227642 0.80522307 0.31081081\n",
      " 0.38410596 0.60869565 0.57417582 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 113/300, Loss: 0.1945, Accuracy: 0.9197, F1: 0.6310\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94618955 0.76204819 0.7706192  0.20116054 0.19065421 0.17094017\n",
      " 0.21955403 0.33515483 0.31168831 0.65913518 0.72081669 0.51724138\n",
      " 0.61006585 0.4022409  0.21287129 0.66876228 0.7794971  0.78433448\n",
      " 0.75752823 0.67616708 0.86909277 0.58156028 0.75022413 0.32179607\n",
      " 0.37796771 0.47269625 0.5308568  0.99341321 0.92914172 0.94894931]\n",
      "Training Epoch 114/300, Loss: 0.2280, Accuracy: 0.8901, F1: 0.5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96418773 0.89839572 0.85962373 0.28169014 0.36111111 0.23076923\n",
      " 0.2745098  0.30232558 0.38554217 0.83070866 0.7654321  0.63636364\n",
      " 0.67980296 0.53584906 0.1875     0.85714286 0.86912752 0.89164087\n",
      " 0.86146096 0.69521411 0.85259373 0.68525896 0.8292159  0.43113772\n",
      " 0.50588235 0.60445682 0.5856     0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 114/300, Loss: 0.1944, Accuracy: 0.9219, F1: 0.6620\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94742103 0.73965691 0.76162506 0.20392157 0.21032505 0.18075802\n",
      " 0.25142857 0.34920635 0.39085239 0.67970848 0.73614191 0.5466081\n",
      " 0.64180479 0.43163097 0.20759494 0.68517794 0.78239042 0.78360741\n",
      " 0.77348916 0.67153996 0.86789729 0.55097614 0.74515486 0.37070524\n",
      " 0.40291705 0.48361582 0.52669683 0.99448552 0.93388224 0.95378553]\n",
      "Training Epoch 115/300, Loss: 0.2269, Accuracy: 0.8923, F1: 0.5935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95916384 0.89373297 0.8445122  0.19047619 0.28571429 0.12765957\n",
      " 0.11494253 0.25       0.25352113 0.81980198 0.78987342 0.6416185\n",
      " 0.68930818 0.53488372 0.19354839 0.84770642 0.8628821  0.88958991\n",
      " 0.86614173 0.69918699 0.87068227 0.63673469 0.82102908 0.3566879\n",
      " 0.41618497 0.59151194 0.55952381 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 115/300, Loss: 0.2001, Accuracy: 0.9190, F1: 0.6335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94677881 0.74698795 0.76923077 0.22524272 0.19813084 0.17366947\n",
      " 0.21129326 0.35666667 0.38549618 0.69506219 0.7264614  0.54213898\n",
      " 0.63961039 0.42251951 0.23444976 0.66535122 0.764637   0.78432418\n",
      " 0.77410163 0.66957787 0.86881742 0.60283688 0.75589197 0.3480715\n",
      " 0.38636364 0.48564997 0.52420801 0.99322204 0.92881652 0.95170032]\n",
      "Training Epoch 116/300, Loss: 0.2266, Accuracy: 0.8916, F1: 0.5926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96182911 0.89008043 0.85714286 0.24615385 0.36065574 0.12244898\n",
      " 0.16666667 0.27848101 0.35135135 0.82306163 0.77073171 0.64498645\n",
      " 0.6622807  0.48979592 0.1875     0.85923218 0.86005089 0.89302326\n",
      " 0.86786019 0.67857143 0.86329047 0.63865546 0.81413911 0.36942675\n",
      " 0.43209877 0.61234568 0.54906832 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 116/300, Loss: 0.1989, Accuracy: 0.9180, F1: 0.6416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94812536 0.741      0.75465995 0.19729207 0.19047619 0.2183908\n",
      " 0.30202578 0.33030853 0.37130802 0.67152724 0.70114416 0.57157058\n",
      " 0.64606608 0.41434263 0.23809524 0.67524366 0.7786728  0.78571429\n",
      " 0.76466013 0.69506941 0.87192795 0.57962697 0.74345736 0.34558824\n",
      " 0.38567493 0.49392265 0.53202264 0.99385503 0.93294242 0.95103231]\n",
      "Training Epoch 117/300, Loss: 0.2272, Accuracy: 0.8927, F1: 0.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96059266 0.88770053 0.84892086 0.20588235 0.29850746 0.26923077\n",
      " 0.28       0.2962963  0.30985915 0.828125   0.77832512 0.63456091\n",
      " 0.68796069 0.54545455 0.20779221 0.84972171 0.85714286 0.89240506\n",
      " 0.86873921 0.67341772 0.84823067 0.58008658 0.76505313 0.38216561\n",
      " 0.47204969 0.60196906 0.58054226 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 117/300, Loss: 0.1966, Accuracy: 0.9181, F1: 0.6470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94771977 0.74937718 0.75862069 0.18032787 0.20564516 0.16338028\n",
      " 0.24444444 0.32116788 0.37259101 0.65103766 0.69893428 0.54572127\n",
      " 0.64685396 0.41541039 0.1754386  0.69602494 0.77986447 0.79190751\n",
      " 0.77215387 0.68217054 0.8711356  0.60492041 0.74804154 0.35996327\n",
      " 0.41636364 0.50156383 0.53758268 0.99429574 0.93282605 0.95506692]\n",
      "Training Epoch 118/300, Loss: 0.2253, Accuracy: 0.8931, F1: 0.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9596152  0.89487871 0.84457478 0.24242424 0.35483871 0.2\n",
      " 0.2244898  0.28235294 0.30769231 0.80645161 0.79187817 0.63535912\n",
      " 0.67141163 0.52075472 0.19354839 0.8587156  0.86375779 0.88818898\n",
      " 0.86759582 0.69473684 0.86125727 0.64166667 0.82126697 0.33766234\n",
      " 0.4        0.58855586 0.55800294 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 118/300, Loss: 0.1981, Accuracy: 0.9183, F1: 0.6437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94821411 0.7478611  0.76842105 0.20634921 0.19066148 0.17045455\n",
      " 0.24455611 0.36678201 0.40080972 0.64655172 0.70121676 0.55768287\n",
      " 0.63759468 0.4371831  0.21463415 0.68296469 0.78661568 0.78610892\n",
      " 0.76515745 0.67799903 0.8780036  0.59440559 0.74503546 0.37625571\n",
      " 0.42307692 0.50818308 0.54268114 0.9953034  0.93339985 0.95289704]\n",
      "Training Epoch 119/300, Loss: 0.2270, Accuracy: 0.8934, F1: 0.5962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9624089  0.88020833 0.84782609 0.24242424 0.34920635 0.15686275\n",
      " 0.17307692 0.3255814  0.35897436 0.82306163 0.77832512 0.64150943\n",
      " 0.66230937 0.52509653 0.19354839 0.8603352  0.8639576  0.89481947\n",
      " 0.87285223 0.7107438  0.86273364 0.62809917 0.80968097 0.42168675\n",
      " 0.45086705 0.62291169 0.5631769  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 119/300, Loss: 0.1951, Accuracy: 0.9190, F1: 0.6494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94743298 0.74748491 0.76271611 0.18146718 0.19927536 0.13173653\n",
      " 0.20164609 0.36551724 0.34907598 0.68562761 0.70656028 0.55996084\n",
      " 0.63501484 0.41325098 0.23587224 0.70519783 0.78693564 0.79014933\n",
      " 0.77526865 0.67669903 0.86401716 0.59296482 0.73836042 0.36875568\n",
      " 0.40368664 0.49560034 0.52570733 0.99347799 0.93006426 0.95121225]\n",
      "Training Epoch 120/300, Loss: 0.2265, Accuracy: 0.8922, F1: 0.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95909069 0.89839572 0.85799701 0.20895522 0.3030303  0.20408163\n",
      " 0.19565217 0.225      0.27027027 0.82445759 0.76213592 0.63768116\n",
      " 0.67435897 0.54873646 0.25       0.85343228 0.86719437 0.88924051\n",
      " 0.86561955 0.69754768 0.85969977 0.60833333 0.80773606 0.44186047\n",
      " 0.48421053 0.60477454 0.58345428 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 120/300, Loss: 0.1983, Accuracy: 0.9183, F1: 0.6460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94873208 0.7541312  0.77108434 0.24482109 0.23809524 0.20207254\n",
      " 0.26018809 0.30434783 0.325      0.         0.6867838  0.70630631\n",
      " 0.56204732 0.63520871 0.3984109  0.1703163  0.68220668 0.76979247\n",
      " 0.78821075 0.76791277 0.68490474 0.87295585 0.58765082 0.75303355\n",
      " 0.39810427 0.43227666 0.49972268 0.54121759 0.99448483 0.93624454\n",
      " 0.95533632]\n",
      "Training Epoch 121/300, Loss: 0.2260, Accuracy: 0.8936, F1: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96253298 0.89295039 0.84487535 0.26470588 0.36923077 0.12244898\n",
      " 0.14736842 0.2278481  0.24657534 0.83070866 0.78894472 0.6568915\n",
      " 0.69287469 0.57251908 0.2739726  0.86080586 0.86599665 0.88549618\n",
      " 0.86212625 0.71122995 0.87297146 0.63900415 0.82458101 0.32679739\n",
      " 0.39240506 0.61957869 0.55667506 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 121/300, Loss: 0.1950, Accuracy: 0.9209, F1: 0.6437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94824852 0.74393264 0.76620825 0.24015009 0.25089606 0.18232044\n",
      " 0.2543554  0.33566434 0.36978131 0.67543201 0.71492007 0.52434825\n",
      " 0.63341761 0.41671372 0.20608899 0.68962818 0.78701748 0.77892507\n",
      " 0.76168004 0.688878   0.8741516  0.58883249 0.75735702 0.39276018\n",
      " 0.42228212 0.48648649 0.5399449  0.99549211 0.93495479 0.95608007]\n",
      "Training Epoch 122/300, Loss: 0.2249, Accuracy: 0.8936, F1: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96193556 0.90425532 0.86695279 0.30985915 0.47222222 0.26415094\n",
      " 0.3047619  0.32183908 0.35714286 0.8297456  0.78024691 0.65263158\n",
      " 0.6761488  0.52419355 0.16129032 0.83712121 0.85863874 0.89814815\n",
      " 0.86677909 0.69656992 0.8713034  0.64754098 0.81949059 0.41509434\n",
      " 0.47457627 0.61329715 0.59006211 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 122/300, Loss: 0.1935, Accuracy: 0.9216, F1: 0.6658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94899763 0.76298862 0.77586207 0.23106061 0.24444444 0.1744186\n",
      " 0.32188065 0.38421955 0.4260355  0.67628083 0.7258996  0.55708661\n",
      " 0.64899746 0.41208791 0.20095694 0.66980392 0.78510802 0.80678851\n",
      " 0.78962803 0.67735666 0.87604903 0.58732394 0.75690999 0.37231057\n",
      " 0.4076555  0.50508475 0.55401328 0.99555389 0.93637725 0.95634493]\n",
      "Training Epoch 123/300, Loss: 0.2238, Accuracy: 0.8956, F1: 0.6056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95917592 0.88770053 0.83918129 0.21538462 0.32786885 0.26923077\n",
      " 0.34545455 0.30952381 0.33766234 0.81673307 0.785      0.65217391\n",
      " 0.67349261 0.51145038 0.16129032 0.85294118 0.8576481  0.89064976\n",
      " 0.86225403 0.70844687 0.86708861 0.63636364 0.81848929 0.3875\n",
      " 0.44827586 0.58984911 0.57763975 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 123/300, Loss: 0.1977, Accuracy: 0.9190, F1: 0.6529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94874647 0.760181   0.7740481  0.20889749 0.23728814 0.18028169\n",
      " 0.28125    0.33975482 0.37681159 0.67560322 0.7308204  0.56611166\n",
      " 0.65321271 0.45272825 0.21662469 0.67647059 0.78574181 0.80042072\n",
      " 0.77347894 0.68538238 0.8814674  0.57081545 0.76266174 0.36037736\n",
      " 0.39842983 0.50364964 0.55912062 0.99473816 0.93955461 0.95505081]\n",
      "Training Epoch 124/300, Loss: 0.2240, Accuracy: 0.8963, F1: 0.6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96146771 0.90133333 0.85962373 0.24242424 0.34375    0.22641509\n",
      " 0.22       0.30232558 0.35       0.79837067 0.76699029 0.64415584\n",
      " 0.67248908 0.51711027 0.19354839 0.85553471 0.85509839 0.89795918\n",
      " 0.86911891 0.70810811 0.8678925  0.64754098 0.81637168 0.45810056\n",
      " 0.48275862 0.61803714 0.5873494  0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 124/300, Loss: 0.1954, Accuracy: 0.9202, F1: 0.6554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94886932 0.74353877 0.75889328 0.21568627 0.24904215 0.18384401\n",
      " 0.23280423 0.34948097 0.37704918 0.67888507 0.72111913 0.55306428\n",
      " 0.63738318 0.43542019 0.24651163 0.68197742 0.77771461 0.78795881\n",
      " 0.76369376 0.67378641 0.87341965 0.59886202 0.76422764 0.38552036\n",
      " 0.43963964 0.51355127 0.5705951  0.99599449 0.93295079 0.95309613]\n",
      "Training Epoch 125/300, Loss: 0.2233, Accuracy: 0.8946, F1: 0.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96236649 0.88541667 0.85070423 0.32876712 0.47368421 0.26415094\n",
      " 0.2745098  0.3255814  0.35897436 0.83757339 0.7979798  0.65306122\n",
      " 0.70485679 0.56617647 0.24615385 0.86972477 0.8728223  0.89580093\n",
      " 0.87607573 0.69312169 0.87217631 0.6446281  0.82114736 0.46783626\n",
      " 0.49197861 0.61333333 0.58470765 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 125/300, Loss: 0.1923, Accuracy: 0.9232, F1: 0.6744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94889369 0.77134446 0.7801661  0.18540434 0.18382353 0.17679558\n",
      " 0.26395939 0.35602094 0.35123967 0.69485714 0.73168579 0.54303984\n",
      " 0.63678373 0.43198223 0.24355972 0.69055877 0.78187404 0.78081835\n",
      " 0.76356889 0.66505558 0.86081919 0.59770115 0.75199703 0.36912156\n",
      " 0.39115044 0.51418938 0.55162154 0.99542807 0.92856697 0.95100899]\n",
      "Training Epoch 126/300, Loss: 0.2210, Accuracy: 0.8934, F1: 0.5964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96069765 0.89473684 0.86894587 0.24615385 0.34482759 0.12765957\n",
      " 0.11494253 0.23376623 0.23880597 0.82539683 0.77915633 0.65536723\n",
      " 0.69276394 0.52       0.16949153 0.8702011  0.87266553 0.89197531\n",
      " 0.86890756 0.7        0.8636891  0.65354331 0.8164557  0.29530201\n",
      " 0.37419355 0.605      0.54637865 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 126/300, Loss: 0.1967, Accuracy: 0.9192, F1: 0.6343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94834119 0.7394297  0.75418588 0.20702403 0.23036649 0.19767442\n",
      " 0.28007181 0.38394415 0.40501044 0.68250377 0.71408903 0.54599407\n",
      " 0.64433812 0.4109589  0.19143577 0.66375546 0.78472222 0.78787879\n",
      " 0.76341387 0.68731849 0.87510837 0.5873129  0.74947589 0.375\n",
      " 0.40540541 0.50748752 0.55336666 0.99435949 0.93374922 0.95500986]\n",
      "Training Epoch 127/300, Loss: 0.2238, Accuracy: 0.8932, F1: 0.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95989362 0.89709763 0.86330935 0.21538462 0.31034483 0.16666667\n",
      " 0.19354839 0.33333333 0.34146341 0.83003953 0.77261614 0.63865546\n",
      " 0.67788462 0.54330709 0.19672131 0.84962406 0.86491228 0.89783282\n",
      " 0.86877076 0.69467787 0.85518065 0.64516129 0.80301399 0.46511628\n",
      " 0.47619048 0.61558785 0.58461538 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 127/300, Loss: 0.1976, Accuracy: 0.9194, F1: 0.6520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94899119 0.76441352 0.77708281 0.21538462 0.23172906 0.14749263\n",
      " 0.21631879 0.32111693 0.35918367 0.67859863 0.71555556 0.56752804\n",
      " 0.65038381 0.42003415 0.17821782 0.68886247 0.77838047 0.78640021\n",
      " 0.76837725 0.69324259 0.8795082  0.58881812 0.76720506 0.38077969\n",
      " 0.4265233  0.50635008 0.55732946 0.99486537 0.93255974 0.95278407]\n",
      "Training Epoch 128/300, Loss: 0.2229, Accuracy: 0.8947, F1: 0.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96214534 0.89709763 0.86162625 0.26470588 0.36363636 0.29090909\n",
      " 0.37931034 0.34090909 0.34146341 0.83300589 0.78696742 0.64265928\n",
      " 0.67592593 0.55430712 0.23529412 0.86556169 0.86919105 0.89622642\n",
      " 0.87188306 0.68229167 0.86473299 0.66115702 0.81797753 0.45744681\n",
      " 0.49777778 0.61212976 0.58389262 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 128/300, Loss: 0.1933, Accuracy: 0.9219, F1: 0.6703\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94865633 0.74701195 0.75810844 0.22222222 0.24858757 0.18857143\n",
      " 0.23853211 0.35897436 0.36686391 0.67925983 0.71804009 0.58016774\n",
      " 0.64207331 0.41944293 0.19158879 0.6858949  0.77849211 0.781947\n",
      " 0.77061376 0.71020803 0.88623062 0.58714286 0.75813193 0.40724763\n",
      " 0.44560487 0.49915302 0.55201699 0.99549268 0.9333167  0.95290892]\n",
      "Training Epoch 129/300, Loss: 0.2216, Accuracy: 0.8949, F1: 0.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95984558 0.89361702 0.85217391 0.23880597 0.33846154 0.30188679\n",
      " 0.35514019 0.26829268 0.30136986 0.82445759 0.77073171 0.6557377\n",
      " 0.69039146 0.52830189 0.19354839 0.86861314 0.87352445 0.89201878\n",
      " 0.86724138 0.67532468 0.85358593 0.6302521  0.81506849 0.43478261\n",
      " 0.54761905 0.57185629 0.56227758 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 129/300, Loss: 0.1995, Accuracy: 0.9198, F1: 0.6588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94938713 0.76176176 0.76180802 0.20856611 0.1981982  0.23756906\n",
      " 0.31118881 0.36363636 0.35294118 0.66377953 0.71686204 0.57426726\n",
      " 0.65654206 0.42071882 0.27765727 0.68447542 0.76619609 0.79201245\n",
      " 0.76415389 0.69126214 0.87881916 0.59701493 0.75139514 0.39781022\n",
      " 0.4432133  0.49860257 0.56759976 0.99524048 0.93499688 0.95608472]\n",
      "Training Epoch 130/300, Loss: 0.2210, Accuracy: 0.8954, F1: 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95868709 0.89238845 0.85509326 0.23529412 0.3943662  0.26923077\n",
      " 0.28       0.32183908 0.34567901 0.82376238 0.79093199 0.63483146\n",
      " 0.67821782 0.55474453 0.23880597 0.84916201 0.85971223 0.88357257\n",
      " 0.8625     0.69705094 0.8674221  0.63598326 0.81278539 0.375\n",
      " 0.44067797 0.56859972 0.56568779 0.99964677 0.99929379 0.99929428]\n",
      "Validation Epoch 130/300, Loss: 0.1972, Accuracy: 0.9187, F1: 0.6563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project='NLP_AS2-Q3-P2', name='FTT-oo-3', config={'epoch': 130, 'batch_size': batch_size})\n",
    "\n",
    "# Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / sum(sen_lengths)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "\n",
    "# WandB Config\n",
    "config = wandb.config\n",
    "\n",
    "# Watch the model\n",
    "wandb.watch(model)\n",
    "\n",
    "for epoch in range(config.epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    correct_predictions_train = 0\n",
    "    total_sentences_train = 0\n",
    "    predictions_q = []\n",
    "    traget_q = []\n",
    "\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss = torch.sum(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print('loss ',loss)\n",
    "        # Accumulate loss for the epoch\n",
    "        total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "        # Prediction\n",
    "        predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "        temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "#         print(temp_pred)\n",
    "#         print(temp_trag)\n",
    "#         print(\"$$$$\")\n",
    "        predictions_q.extend(temp_pred)\n",
    "        traget_q.extend(temp_trag)\n",
    "\n",
    "        # Update total sentences count\n",
    "        # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for training\n",
    "    average_loss_train = total_loss_train / len(dataloader)\n",
    "    accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "    f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "    print(f1_score(traget_q, predictions_q, average=None))\n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Train Loss': average_loss_train, 'Train Accuracy': accuracy_train, 'Train F1': f1_Score}, step=epoch)\n",
    "    print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    correct_predictions_val = 0\n",
    "    total_sentences_val = 0\n",
    "    predictions_p = []\n",
    "    traget_p = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{config.epoch}', leave=False):\n",
    "            sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "            total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "            # Prediction\n",
    "            predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "            correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "            predictions_p.extend(temp_pred)\n",
    "            traget_p.extend(temp_trag)\n",
    "\n",
    "            # Update total sentences count\n",
    "            # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy for validation\n",
    "    average_loss_val = total_loss_val / len(dataloader_val)\n",
    "    accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "    f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "    print(f1_score(traget_p, predictions_p, average=None))\n",
    "    \n",
    "    # Log metrics to WandB\n",
    "    wandb.log({'Validation Loss': average_loss_val, 'Validation Accuracy': accuracy_val, 'Validation F1': f1_Score}, step=epoch)\n",
    "    print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len([0.95128599,0.20926244,0.13918377 ,   0.    ,              0.    ,             0.       ,             0.     ,         0.      ,   0.   ,        0.99964677 ,     1.        ]))\n",
    "# print(len({'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "#     # Print cumulative value counts after each batch\n",
    "#     print(\"Cumulative Value Counts:\")\n",
    "#     print(cumulative_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Mapping from numeric values to labels\n",
    "# numeric_to_labels = {\n",
    "#     0: 'O', 1: 'B_COURT', 2: 'I_COURT', 3: 'B_PETITIONER', 4: 'I_PETITIONER',\n",
    "#     5: 'B_RESPONDENT', 6: 'I_RESPONDENT', 7: 'B_JUDGE', 8: 'I_JUDGE',\n",
    "#     9: 'B_LAWYER', 10: 'I_LAWYER', 11: 'B_DATE', 12: 'I_DATE',\n",
    "#     13: 'B_ORG', 14: 'I_ORG', 15: 'B_GPE', 16: 'I_GPE',\n",
    "#     17: 'B_STATUTE', 18: 'I_STATUTE', 19: 'B_PROVISION', 20: 'I_PROVISION',\n",
    "#     21: 'B_PRECEDENT', 22: 'I_PRECEDENT', 23: 'B_CASE_NUMBER', 24: 'I_CASE_NUMBER',\n",
    "#     25: 'B_WITNESS', 26: 'I_WITNESS', 27: 'B_OTHER_PERSON', 28: 'I_OTHER_PERSON',\n",
    "#     29: '<START>', 30: '<STOP>', 31: '<PAD>'\n",
    "# }\n",
    "\n",
    "# # Initialize an empty Counter to store cumulative counts\n",
    "# cumulative_counts = Counter()\n",
    "\n",
    "# # Assuming dataloader is an instance of your DataLoader\n",
    "# for sentence_in, targets, mask, sen_lengths in dataloader:\n",
    "#     # Reshape the tensor to (b * d * l) and convert it to a list\n",
    "#     tensor_list = targets.view(-1).tolist()\n",
    "\n",
    "#     # Use Counter to count occurrences for the current batch\n",
    "#     batch_counts = Counter(tensor_list)\n",
    "\n",
    "#     # Update cumulative counts with batch counts\n",
    "#     cumulative_counts.update(batch_counts)\n",
    "\n",
    "# # Convert numeric values to labels in the cumulative counts\n",
    "# cumulative_counts_labels = {numeric_to_labels[key]: value for key, value in cumulative_counts.items()}\n",
    "\n",
    "# # Remove <PAD> from the counts\n",
    "# cumulative_counts_labels.pop('<PAD>', None)\n",
    "# cumulative_counts_labels.pop('O', None)\n",
    "# # Plot the final cumulative counts with labels (excluding <PAD>) and add count on top of each bar\n",
    "# labels, values = zip(*cumulative_counts_labels.items())\n",
    "# plt.bar(labels, values)\n",
    "# plt.xlabel('Label')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Final Cumulative Value Counts (Excluding <PAD>)')\n",
    "# plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "\n",
    "# # Add count on top of each bar\n",
    "# for label, value in zip(labels, values):\n",
    "#     plt.text(label, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn import metrics\n",
    "# import numpy as np\n",
    "\n",
    "# # Example\n",
    "# cm = confusion_matrix(traget_p, predictions_p, labels=range(12))\n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# # Plot confusion matrix with heat map\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(cm, annot=True, cmap=\"Blues\",)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(traget_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# # Plot confusion matrix using imshow\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# # sns.set(font_scale=1.2)\n",
    "# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# plt.title('Normalized Confusion Matrix')\n",
    "# plt.colorbar()\n",
    "\n",
    "# classes = range(13)\n",
    "# tick_marks = np.arange(len(classes))\n",
    "# plt.xticks(tick_marks, classes, rotation=45)\n",
    "# plt.yticks(tick_marks, classes)\n",
    "\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(29),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(11),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(23),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(0),\n",
       " tensor(17),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(29),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(0),\n",
       " tensor(27),\n",
       " tensor(0),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jsluZV6ArICu"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Assuming you have a BiLSTM_CRF model, a train_dataloader, a val_dataloader, and an optimizer\n",
    "# # Also assuming you have defined the necessary variables (e.g., vocab_size, tag_to_ix, etc.)\n",
    "\n",
    "# # Move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Function to calculate accuracy\n",
    "# import torch\n",
    "\n",
    "# def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         acc += torch.sum(prex == trex)\n",
    "\n",
    "#     # Move the division outside the loop to calculate the average accuracy\n",
    "#     acc = acc.float() / sum(sen_lengths)\n",
    "#     # print(acc)\n",
    "#     return acc\n",
    "\n",
    "# def aggregater(predictions, targets, sen_lengths):\n",
    "#     ranges = targets.shape[0]\n",
    "#     target = targets.cpu()\n",
    "#     predictions = torch.tensor(predictions).cpu()\n",
    "#     acc = 0\n",
    "#     aggr_pred = []\n",
    "#     aggr_targ = []\n",
    "#     for i in range(ranges):\n",
    "#         prex = predictions[i][:sen_lengths[i]]\n",
    "#         trex = target[i][:sen_lengths[i]]\n",
    "#         aggr_pred.extend(prex)\n",
    "#         aggr_targ.extend(trex)\n",
    "#     return aggr_pred,aggr_targ\n",
    "\n",
    "\n",
    "# for epoch in range(300):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss_train = 0\n",
    "#     correct_predictions_train = 0\n",
    "#     total_sentences_train = 0\n",
    "#     predictions_q = []\n",
    "#     traget_q = []\n",
    "\n",
    "#     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "#         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss = torch.sum(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print('loss ',loss)\n",
    "#         # Accumulate loss for the epoch\n",
    "#         total_loss_train += (loss.item()/torch.sum(sen_lengths))\n",
    "\n",
    "#         # Prediction\n",
    "#         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "#         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         temp_pred,temp_trag = aggregater(predictions_train, targets, sen_lengths)\n",
    "\n",
    "#         predictions_q.extend(temp_pred)\n",
    "#         traget_q.extend(temp_trag)\n",
    "\n",
    "#         # Update total sentences count\n",
    "#         # total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for training\n",
    "\n",
    "#     average_loss_train = total_loss_train / len(dataloader)\n",
    "#     accuracy_train = correct_predictions_train / len(dataloader)  # Average over all sentences, not just batches\n",
    "#     f1_Score= f1_score(traget_q, predictions_q, average=\"macro\")\n",
    "#     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}, F1: {f1_Score :.4f}')\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     total_loss_val = 0\n",
    "#     correct_predictions_val = 0\n",
    "#     total_sentences_val = 0\n",
    "#     predictions_p = []\n",
    "#     traget_p = []\n",
    "#     with torch.no_grad():\n",
    "#         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "#             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "#             total_loss_val += (torch.sum(loss_val).item()/torch.sum(sen_lengths))\n",
    "\n",
    "#             # Prediction\n",
    "#             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "#             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "\n",
    "#             temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "\n",
    "#             predictions_p.extend(temp_pred)\n",
    "#             traget_p.extend(temp_trag)\n",
    "\n",
    "#             # Update total sentences count\n",
    "#             # total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "#     # Calculate average loss and accuracy for validation\n",
    "#     average_loss_val = total_loss_val / len(dataloader_val)\n",
    "#     accuracy_val = correct_predictions_val / len(dataloader_val)  # Average over all sentences, not just batches\n",
    "#     f1_Score = f1_score(traget_p, predictions_p, average=\"macro\")\n",
    "#     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}, F1: {f1_Score:.4f}')\n",
    "\n",
    "#     print()\n",
    "\n",
    "# # # Training and validation loop\n",
    "# # for epoch in range(300):\n",
    "# #     # Training\n",
    "# #     model.train()\n",
    "# #     total_loss_train = 0\n",
    "# #     correct_predictions_train = 0\n",
    "# #     total_sentences_train = 0\n",
    "\n",
    "# #     for sentence_in, targets, mask, sen_lengths in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #         sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #         model.zero_grad()\n",
    "\n",
    "# #         # Forward pass\n",
    "# #         loss = model(sentence_in, mask, targets, sen_lengths)\n",
    "\n",
    "# #         # Backward pass and optimization\n",
    "# #         loss = torch.sum(loss)\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "\n",
    "# #         # Accumulate loss for the epoch\n",
    "# #         total_loss_train += loss.item()\n",
    "\n",
    "# #         # Prediction\n",
    "# #         predictions_train = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #         print()\n",
    "# #         # print(len(predictions_train[0]),'predi_len')\n",
    "# #         # print(sen_lengths[0],'sen_len')\n",
    "# #         # print(targets[0][:sen_lengths[0]].shape,'targets_len')\n",
    "# #         correct_predictions_train += calculate_accuracy(predictions_train, targets, sen_lengths)\n",
    "\n",
    "# #         # Update total sentences count\n",
    "# #         total_sentences_train += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for training\n",
    "# #     average_loss_train = total_loss_train / total_sentences_train\n",
    "# #     accuracy_train = correct_predictions_train / len(dataloader)\n",
    "\n",
    "# #     print(f'Training Epoch {epoch + 1}/{300}, Loss: {average_loss_train:.4f}, Accuracy: {accuracy_train:.4f}')\n",
    "\n",
    "# #     # Validation\n",
    "# #     model.eval()\n",
    "# #     total_loss_val = 0\n",
    "# #     correct_predictions_val = 0\n",
    "# #     total_sentences_val = 0\n",
    "\n",
    "# #     with torch.no_grad():\n",
    "# #         for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_val, desc=f'Validation Epoch {epoch + 1}/{300}', leave=False):\n",
    "# #             sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "# #             # Forward pass\n",
    "# #             loss_val = model(sentence_in, mask, targets, sen_lengths)\n",
    "# #             total_loss_val += torch.sum(loss_val).item()\n",
    "\n",
    "# #             # Prediction\n",
    "# #             predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "# #             correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "\n",
    "# #             # Update total sentences count\n",
    "# #             total_sentences_val += sentence_in.size(0)\n",
    "\n",
    "# #     # Calculate average loss and accuracy for validation\n",
    "# #     average_loss_val = total_loss_val / total_sentences_val\n",
    "# #     accuracy_val = correct_predictions_val / len(dataloader_val)\n",
    "\n",
    "# #     print(f'Validation Epoch {epoch + 1}/{300}, Loss: {average_loss_val:.4f}, Accuracy: {accuracy_val:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wQB_sic2fKxK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: pytorch save model code\n",
    "\n",
    "torch.save(model.state_dict(), 't1_model4_Fasttext.pt')\n",
    "\n",
    "# Save the model to W&B\n",
    "wandb.save('t1_model4_Fasttext.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manvendra\n",
      "[nltk_data]     Nema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMCRF(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): LSTM(300, 256, bidirectional=True)\n",
       "  (hidden2emit_score): Linear(in_features=512, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import gensim.downloader as api\n",
    "from torchtext.vocab import GloVe,FastText\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import fasttext.util\n",
    "import json\n",
    "\n",
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, json_path, embedding_type='word2vec',load=True):\n",
    "        with open(json_path, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "        if load:\n",
    "          self.embedding_model =self.load_embedding_model()\n",
    "        else:\n",
    "          self.embedding_model = None\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Download the pre-trained Word2Vec model\n",
    "            return api.load('word2vec-google-news-300')\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # Download the pre-trained GloVe model (6B tokens, 300d)\n",
    "            return GloVe(name='6B', dim=300)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # Load the pre-trained FastText model\n",
    "            \n",
    "            return FastText(language='en')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "\n",
    "    def text_to_embeddings(self, text):\n",
    "        maxlen = 100\n",
    "        if self.embedding_type == 'word2vec':\n",
    "            # Word2Vec embeddings\n",
    "            embeddings = [self.embedding_model[word] if word in self.embedding_model else torch.zeros(self.embedding_model.vector_size) for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((self.embedding_model.vector_size,),-1.0))\n",
    "\n",
    "\n",
    "        elif self.embedding_type == 'glove':\n",
    "            # GloVe embeddings\n",
    "            \n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            \n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "            \n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "            \n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "            \n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            # FastText embeddings\n",
    "            embeddings = [self.embedding_model[word] for word in text.split() ]\n",
    "            # print(np.stack(embeddings).shape)\n",
    "            embeddings = [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1000.0)] + embeddings + [torch.full((sentiment_dataset.embedding_model['a'].shape[0],),+1000.0)]\n",
    "\n",
    "            # print('##',np.stack([torch.full((self.embedding_model.vector_size,),-1000.0)] + embeddings + [torch.full((self.embedding_model.vector_size,),+1000.0)]  ).shape)\n",
    "\n",
    "            for i in range(100-len(embeddings)):\n",
    "              embeddings.append(torch.full((sentiment_dataset.embedding_model['a'].shape[0],),-1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "        # print()\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        index = str(index)\n",
    "        text = self.data[index][\"text\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        \n",
    "        text,labels = preprocess_text(text,labels)\n",
    "        # Convert text to embeddings\n",
    "        text_embeddings = torch.tensor(self.text_to_embeddings(text))\n",
    "        \n",
    "        # print(text_embeddings.shape)\n",
    "        # torch.stack([torch.full((1,text_embeddings.shape[1]),-1000),text_embeddings, [torch.full((1,text_embeddings.shape[1]),1000)])\n",
    "        current_length = len(labels)\n",
    "#         print(labels)\n",
    "        labels = ['<START>'] + labels + ['<STOP>']\n",
    "#         print(labels)\n",
    "#         mask = torch.hstack([torch.full((len(labels),),True),torch.full((max(0,100-len(labels)),),False)])\n",
    "        sent_lengths =torch.tensor(len(labels))\n",
    "        max_length = 100\n",
    "        labels = labels + ['<PAD>'] * (max_length - (current_length+2))\n",
    "        \n",
    "        # Convert labels to numerical format if needed\n",
    "        label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "#         label_mapping = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10,  '<START>': 11, '<STOP>': 12, '<PAD>': 13}\n",
    "        numerical_labels = [label_mapping[label] for label in labels ]\n",
    "#         print(numerical_labels)\n",
    "\n",
    "        # Pad the sequence to the maximum length\n",
    "\n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(numerical_labels)\n",
    "        mask = torch.hstack([torch.full((text_embeddings.shape[0],),True),torch.full((100-text_embeddings.shape[0],),False)])\n",
    "        # print(labels_tensor.shape,text_embeddings.shape,mask.shape)\n",
    "        return text_embeddings, labels_tensor, mask,sent_lengths\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256):\n",
    "        \"\"\" Initialize the model\n",
    "        Args:\n",
    "            sent_vocab (Vocab): vocabulary of words\n",
    "            tag_vocab (Vocab): vocabulary of tags\n",
    "            embed_size (int): embedding size\n",
    "            hidden_size (int): hidden state size\n",
    "        \"\"\"\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.sent_vocab = sent_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        # self.embedding = nn.Embedding(len(sent_vocab), embed_size) print\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, bidirectional=True)\n",
    "        self.hidden2emit_score = nn.Linear(hidden_size * 2, len(self.tag_vocab))\n",
    "        self.transition = nn.Parameter(torch.randn(len(self.tag_vocab), len(self.tag_vocab)))  # shape: (K, K)\n",
    "\n",
    "    def forward(self, sentences,mask, tags, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            tags (tensor): corresponding tags, shape (b, len)\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            loss (tensor): loss on the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        # mask = (sentences != self.sent_vocab[self.sent_vocab.PAD])  # shape: (b, len)                        #$$$$$$$$$$$$$$$$$$$__________________\n",
    "        sentences = sentences.transpose(0, 1)  # shape: (len, b)\n",
    "        # print(\"forword--1\",sentences.shape)\n",
    "        # sentences = self.embedding(sentences)  # shape: (len, b, e)\n",
    "        emit_score = self.encode(sentences, sen_lengths)  # shape: (b, len, K)\n",
    "        # print(\"forword--2\",sentences.shape)\n",
    "        loss = self.cal_loss(tags, mask, emit_score)  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "    def encode(self, sentences, sent_lengths):\n",
    "        \"\"\" BiLSTM Encoder\n",
    "        Args:\n",
    "            sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "            sent_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            emit_score (tensor): emit score, shape (b, len, K)\n",
    "        \"\"\"\n",
    "        # padded_sentences = pack_padded_sequence(sentences, sent_lengths)\n",
    "        hidden_states, _ = self.encoder(sentences)\n",
    "        # print(hidden_states.shape,\"(((())))\")\n",
    "        hidden_states = hidden_states.permute(1,0,2)\n",
    "        # hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "        # print(hidden_states.shape)\n",
    "        emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "        emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "        return emit_score\n",
    "\n",
    "    # def encode(self, sentences, sent_lengths):\n",
    "    #   \"\"\" BiLSTM Encoder\n",
    "    #   Args:\n",
    "    #       sentences (tensor): sentences with word embeddings, shape (len, b, e)\n",
    "    #       sent_lengths (list): sentence lengths\n",
    "    #   Returns:\n",
    "    #       emit_score (tensor): emit score, shape (b, len, K)\n",
    "    #   \"\"\"\n",
    "    #   sorted_lengths, sorted_idx = torch.sort(sent_lengths, descending=True)\n",
    "    #   sorted_sentences = sentences[:, sorted_idx, :]  # Sort the sentences based on lengths\n",
    "    #   packed_sentences = pack_padded_sequence(sorted_sentences, sorted_lengths)\n",
    "    #   hidden_states, _ = self.encoder(packed_sentences)\n",
    "    #   hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True)  # shape: (b, len, 2h)\n",
    "    #   emit_score = self.hidden2emit_score(hidden_states)  # shape: (b, len, K)\n",
    "    #   emit_score = self.dropout(emit_score)  # shape: (b, len, K)\n",
    "    #   return emit_score\n",
    "\n",
    "    def cal_loss(self, tags, mask, emit_score):\n",
    "        \"\"\" Calculate CRF loss\n",
    "        Args:\n",
    "            tags (tensor): a batch of tags, shape (b, len)\n",
    "            mask (tensor): mask for the tags, shape (b, len), values in PAD position is 0\n",
    "            emit_score (tensor): emit matrix, shape (b, len, K)\n",
    "        Returns:\n",
    "            loss (tensor): loss of the batch, shape (b,)\n",
    "        \"\"\"\n",
    "        batch_size, sent_len = tags.shape\n",
    "        # calculate score for the tags\n",
    "        score = torch.gather(emit_score, dim=2, index=tags.unsqueeze(dim=2)).squeeze(dim=2)  # shape: (b, len)\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "        total_score = (score * mask.type(torch.float)).sum(dim=1)  # shape: (b,)\n",
    "        # calculate the scaling factor\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "        fix_length = 100\n",
    "        for i in range(1, fix_length):\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "            emit_and_transition = emit_score[: n_unfinished, i].unsqueeze(dim=1) + self.transition  # shape: (uf, K, K)\n",
    "            log_sum = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "            max_v = log_sum.max(dim=1)[0].unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            log_sum = log_sum - max_v  # shape: (uf, K, K)\n",
    "            d_uf = max_v + torch.logsumexp(log_sum, dim=1).unsqueeze(dim=1)  # shape: (uf, 1, K)\n",
    "            d = torch.cat((d_uf, d[n_unfinished:]), dim=0)\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "        max_d = d.max(dim=-1)[0]  # shape: (b,)\n",
    "        d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=1), dim=1)  # shape: (b,)\n",
    "        llk = total_score - d  # shape: (b,)\n",
    "        loss = -llk  # shape: (b,)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def predict(self, sentences, mask, sen_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentences (tensor): sentences, shape (b, len). Lengths are in decreasing order, len is the length\n",
    "                                of the longest sentence\n",
    "            sen_lengths (list): sentence lengths\n",
    "        Returns:\n",
    "            tags (list[list[str]]): predicted tags for the batch\n",
    "        \"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "\n",
    "        w = mask\n",
    "        sentences = sentences.transpose(0, 1)\n",
    "\n",
    "        emit_score = self.encode(sentences, sen_lengths)\n",
    "\n",
    "        # Initialize the tags with all possible tag indices for each sentence in the batch\n",
    "        tags = [[[i] for i in range(len(self.tag_vocab))]] * batch_size  # list, shape: (b, K, 1)\n",
    "\n",
    "        # Initialize the first column of the dynamic programming matrix\n",
    "        d = torch.unsqueeze(emit_score[:, 0], dim=1)  # shape: (b, 1, K)\n",
    "\n",
    "        # Use a fixed length (e.g., 100) instead of max(sen_lengths)\n",
    "        fixed_length = 100\n",
    "\n",
    "        # Iterate over the remaining columns of the dynamic programming matrix\n",
    "        for i in range(1, fixed_length):\n",
    "            # Calculate the number of unfinished sentences at the current position\n",
    "            n_unfinished = mask[:, i].sum()\n",
    "\n",
    "            # Slice the dynamic programming matrix for the unfinished sentences\n",
    "            d_uf = d[: n_unfinished]  # shape: (uf, 1, K)\n",
    "\n",
    "            # Compute emission and transition scores for the current position\n",
    "            emit_and_transition = self.transition + emit_score[: n_unfinished, i].unsqueeze(dim=1)  # shape: (uf, K, K)\n",
    "\n",
    "            # Compute the new values for the dynamic programming matrix\n",
    "            new_d_uf = d_uf.transpose(1, 2) + emit_and_transition  # shape: (uf, K, K)\n",
    "\n",
    "            # Update the dynamic programming matrix and get the indices of maximum values\n",
    "            d_uf, max_idx = torch.max(new_d_uf, dim=1)\n",
    "            max_idx = max_idx.tolist()  # list, shape: (nf, K)\n",
    "\n",
    "            # Update the tags for the unfinished sentences\n",
    "            tags[: n_unfinished] = [[tags[b][k] + [j] for j, k in enumerate(max_idx[b])] for b in range(n_unfinished)]\n",
    "\n",
    "            # Concatenate the new values to the dynamic programming matrix\n",
    "            d = torch.cat((torch.unsqueeze(d_uf, dim=1), d[n_unfinished:]), dim=0)  # shape: (b, 1, K)\n",
    "\n",
    "        # Remove the singleton dimension to get the final dynamic programming matrix\n",
    "        d = d.squeeze(dim=1)  # shape: (b, K)\n",
    "\n",
    "        # Get the indices of the maximum values in the final column of the matrix\n",
    "        _, max_idx = torch.max(d, dim=1)  # shape: (b,)\n",
    "        max_idx = max_idx.tolist()\n",
    "\n",
    "        # Extract the predicted tags based on the maximum indices\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_idx)]\n",
    "\n",
    "        # Print the predicted tags and sentence lengths for debugging\n",
    "        # print(tags, sen_lengths, '((()))')\n",
    "\n",
    "        return tags\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]+1]\n",
    "        trex = target[i][:sen_lengths[i]+1]\n",
    "        acc += torch.sum(prex == trex)\n",
    "\n",
    "    # Move the division outside the loop to calculate the average accuracy\n",
    "    acc = acc.float() / (sum(sen_lengths)+10)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def aggregater(predictions, targets, sen_lengths):\n",
    "    ranges = targets.shape[0]\n",
    "    target = targets.cpu()\n",
    "    predictions = torch.tensor(predictions).cpu()\n",
    "    acc = 0\n",
    "    aggr_pred = []\n",
    "    aggr_targ = []\n",
    "    for i in range(ranges):\n",
    "        prex = predictions[i][:sen_lengths[i]]\n",
    "        trex = target[i][:sen_lengths[i]]\n",
    "        aggr_pred.extend(prex)\n",
    "        aggr_targ.extend(trex)\n",
    "    return aggr_pred,aggr_targ\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text,label):\n",
    "    # Remove punctuation\n",
    "    text_no_punct = ''\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            text_no_punct += char\n",
    "\n",
    "    # Check if the text length is zero after removing punctuation\n",
    "    if len(text_no_punct.strip()) == 0:\n",
    "        return text\n",
    "\n",
    "    # Lowercase the text\n",
    "    text_lower = text_no_punct.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text_lower.split()\n",
    "    \n",
    "    text_no_stopwords = ''\n",
    "    labels =[]\n",
    "    for word in range(len(tokens)):\n",
    "        if not(tokens[word].lower() in stop_words and label[word]== 'O'):\n",
    "            text_no_stopwords += tokens[word] + ' '\n",
    "            labels.append(label[word])\n",
    "\n",
    "    return text_no_stopwords.strip(),labels\n",
    "\n",
    "tag_to_ix = {'O': 0, 'B_COURT': 1, 'I_COURT': 2, 'B_PETITIONER': 3, 'I_PETITIONER': 4, 'B_RESPONDENT': 5, 'I_RESPONDENT': 6, 'B_JUDGE': 7, 'I_JUDGE': 8, 'B_LAWYER': 9, 'I_LAWYER': 10, 'B_DATE': 11, 'I_DATE': 12, 'B_ORG': 13, 'I_ORG': 14, 'B_GPE': 15, 'I_GPE': 16, 'B_STATUTE': 17, 'I_STATUTE': 18, 'B_PROVISION': 19, 'I_PROVISION': 20, 'B_PRECEDENT': 21, 'I_PRECEDENT': 22, 'B_CASE_NUMBER': 23, 'I_CASE_NUMBER': 24, 'B_WITNESS': 25, 'I_WITNESS': 26, 'B_OTHER_PERSON': 27, 'I_OTHER_PERSON': 28, '<START>': 29, '<STOP>': 30, '<PAD>': 31}\n",
    "# tag_vocab, dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "model  = BiLSTMCRF(tag_to_ix,dropout_rate=0.5, embed_size=300, hidden_size=256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load('t1_model4_fasttext.pt')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "json_path = 'NER_test.json'\n",
    "embedding_type = 'fasttext'\n",
    "sentiment_dataset_test = SentimentAnalysisDataset(json_path, embedding_type)\n",
    "sentiment_dataset =sentiment_dataset_test\n",
    "# sentiment_dataset_test.embedding_model = sentiment_dataset.embedding_model\n",
    "batch_size  = 512\n",
    "dataloader_test = DataLoader(sentiment_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LtLXbDKMZ1bG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9641\n",
      "Test F1:  0.6743593325786298\n",
      "[0.95782214 0.87761194 0.85298869 0.61538462 0.77777778 0.\n",
      " 0.         0.4        0.57142857 0.83211679 0.79452055 0.67148014\n",
      " 0.68292683 0.5620438  0.38554217 0.81313131 0.84903226 0.86767896\n",
      " 0.8592233  0.71473354 0.87587822 0.67       0.79884226 0.41025641\n",
      " 0.43037975 0.62937063 0.65625    1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "model.eval()\n",
    "correct_predictions_val = 0\n",
    "total_sentences_val = 0\n",
    "predictions_r = []\n",
    "traget_r = []\n",
    "epoch=1\n",
    "device='cuda'\n",
    "with torch.no_grad():\n",
    "    for sentence_in, targets, mask, sen_lengths in tqdm(dataloader_test, desc=f'Test Epoch {epoch + 1}/{300}', leave=False):\n",
    "        sentence_in, targets, mask, sen_lengths = sentence_in.to(device), targets.to(device), mask.to(device), sen_lengths.to(device)\n",
    "\n",
    "        # Prediction\n",
    "        predictions_val = model.predict(sentence_in, mask, sen_lengths)\n",
    "        correct_predictions_val += calculate_accuracy(predictions_val, targets, sen_lengths)\n",
    "        temp_pred,temp_trag = aggregater(predictions_val, targets, sen_lengths)\n",
    "        predictions_r.extend(temp_pred)\n",
    "        traget_r.extend(temp_trag)\n",
    "\n",
    "accuracy_val = correct_predictions_val / len(dataloader_test)  # Average over all sentences, not just batches\n",
    "print()\n",
    "print(f'Test Accuracy: {accuracy_val:.4f}')\n",
    "print(f'Test F1:  {f1_score(traget_r, predictions_r, average=\"macro\")}')\n",
    "print(f1_score(traget_r, predictions_r, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6O3vYN9J-BBQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>Train F1</td><td>▁▂▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>Train Loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇███████████████</td></tr><tr><td>Validation F1</td><td>▁▂▄▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇███████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.89536</td></tr><tr><td>Train F1</td><td>0.60579</td></tr><tr><td>Train Loss</td><td>0.22102</td></tr><tr><td>Validation Accuracy</td><td>0.9187</td></tr><tr><td>Validation F1</td><td>0.65634</td></tr><tr><td>Validation Loss</td><td>0.19723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FTT-oo-3</strong> at: <a href='https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/jrceellj' target=\"_blank\">https://wandb.ai/iiitd/NLP_AS2-Q3-P2/runs/jrceellj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240310_012516-jrceellj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0befd16ce747402b8fd074f82ac58bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "126562022a634f218a533eb2d0cb68ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e627c3c18f7453d843197124428d4e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dab3d6fa9be463b81add125fc796b1b",
      "placeholder": "​",
      "style": "IPY_MODEL_f97c3e9cd95c4f97a253dda0a8f9b9b9",
      "value": "0.013 MB of 0.013 MB uploaded\r"
     }
    },
    "5c0c4e0669724ef0a85788b9e1d372b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dab3d6fa9be463b81add125fc796b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a41f20afb91441ebb9d824625a4280e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0befd16ce747402b8fd074f82ac58bef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c0c4e0669724ef0a85788b9e1d372b4",
      "value": 1
     }
    },
    "f97c3e9cd95c4f97a253dda0a8f9b9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fed62b3a309a402dba270a79ae613fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e627c3c18f7453d843197124428d4e3",
       "IPY_MODEL_a41f20afb91441ebb9d824625a4280e1"
      ],
      "layout": "IPY_MODEL_126562022a634f218a533eb2d0cb68ce"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
